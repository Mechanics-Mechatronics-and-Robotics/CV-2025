{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/Mechanics-Mechatronics-and-Robotics/CV-2025/blob/main/Assignment_01/UQ_CIFAR-10N_Ensembling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github"}},{"cell_type":"markdown","source":"#Uncertainty Quantification with CIFAR-10N and Ensembling\nBy *First name* *Second name*.\n\n*Month, Day, 2025.*","metadata":{"id":"dviRg5xn5mza"}},{"cell_type":"markdown","source":"## Problem Statement","metadata":{"id":"fS8QkXU47uNl"}},{"cell_type":"markdown","source":"Re-annotated versions of the CIFAR-10 and CIFAR-100 data which contains real-world human annotation errors. We show how these noise patterns deviate from the classically assumed ones and what the new challenges are. The website of CIFAR-N is available at [cifar-10-100n\n](https://github.com/UCSC-REAL/cifar-10-100n/tree/main) project.","metadata":{"id":"EvP6IWSB5s_c"}},{"cell_type":"markdown","source":"# Preparation of simulation models","metadata":{"id":"kN9yU_U6766c"}},{"cell_type":"markdown","source":"## Import and Install Libraries","metadata":{"id":"9mpwlpoX5TI3"}},{"cell_type":"code","source":"!pip install -q pytorch-lightning clearml","metadata":{"id":"xMPnV0nV4_-I","trusted":true,"execution":{"iopub.status.busy":"2025-03-17T02:45:24.402074Z","iopub.execute_input":"2025-03-17T02:45:24.402391Z","iopub.status.idle":"2025-03-17T02:45:27.939268Z","shell.execute_reply.started":"2025-03-17T02:45:24.402370Z","shell.execute_reply":"2025-03-17T02:45:27.938149Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"#Pytorch modules\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader, random_split, TensorDataset\nfrom torchvision.datasets import CIFAR10\nfrom torchvision import datasets, transforms, models\n#scipy\nfrom scipy.stats import mode\n#sklearn\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\n#Numpy\nimport numpy as np\n#Pandas\nimport pandas as pd\n#Lightning & logging\nimport pytorch_lightning as pl\nfrom pytorch_lightning import Trainer\nfrom pytorch_lightning.callbacks import ModelCheckpoint\n#Data observation\nimport os\nimport sys\nimport pickle\nimport requests\nfrom pathlib import Path\n#Plotting\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n#Logging\nfrom clearml import Task\n# Warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"id":"fDHrafErmo43","trusted":true,"execution":{"iopub.status.busy":"2025-03-17T02:45:27.941136Z","iopub.execute_input":"2025-03-17T02:45:27.941451Z","iopub.status.idle":"2025-03-17T02:45:27.948613Z","shell.execute_reply.started":"2025-03-17T02:45:27.941421Z","shell.execute_reply":"2025-03-17T02:45:27.947678Z"}},"outputs":[],"execution_count":60},{"cell_type":"markdown","source":"## Set the Models","metadata":{"id":"ealb85K93wDT"}},{"cell_type":"markdown","source":"### Simulation Settings","metadata":{"id":"GHIKBWI93-zD"}},{"cell_type":"markdown","source":"Check the current directory","metadata":{"id":"kiYPAzh54gjM"}},{"cell_type":"code","source":"os.getcwd() #returns the current working directory","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"phE7U1vu31BR","outputId":"f3f9c4e4-9e15-4d41-b5f7-3c5ad3ae131f","trusted":true,"execution":{"iopub.status.busy":"2025-03-17T02:45:27.950461Z","iopub.execute_input":"2025-03-17T02:45:27.950680Z","iopub.status.idle":"2025-03-17T02:45:27.966069Z","shell.execute_reply.started":"2025-03-17T02:45:27.950662Z","shell.execute_reply":"2025-03-17T02:45:27.965306Z"}},"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working'"},"metadata":{}}],"execution_count":61},{"cell_type":"code","source":"# Path to the folder where the pretrained models are saved\nCHECKPOINT_PATH = os.environ.get(\"PATH_CHECKPOINT\", \"saved_models/\")\nprint(f'CHECKPOINT_PATH: {CHECKPOINT_PATH}')\n\nos.makedirs(CHECKPOINT_PATH, exist_ok=True)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7EVwTLDiNYyc","outputId":"61804a12-1e8f-4ced-b494-6391bfc1176b","trusted":true,"execution":{"iopub.status.busy":"2025-03-17T02:45:27.967162Z","iopub.execute_input":"2025-03-17T02:45:27.967350Z","iopub.status.idle":"2025-03-17T02:45:27.980999Z","shell.execute_reply.started":"2025-03-17T02:45:27.967333Z","shell.execute_reply":"2025-03-17T02:45:27.980258Z"}},"outputs":[{"name":"stdout","text":"CHECKPOINT_PATH: saved_models/\n","output_type":"stream"}],"execution_count":62},{"cell_type":"markdown","source":"Set the reproducibility options","metadata":{"id":"3WK77wcO6sfb"}},{"cell_type":"code","source":"# Function for setting the seed to implement parallel tests\nSEEDS =  [42, 0, 17, 9, 3, 16, 2]\nSEED = 42 # random seed by default\npl.seed_everything(SEED)\n\n# Determine the device (GPU if available, otherwise CPU)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Prioritizes speed but may reduce precision\ntorch.set_float32_matmul_precision('high')\n\n# # Ensure that all operations are deterministic on GPU (if used) for reproducibility\n# torch.backends.cudnn.deterministic = True\n# torch.backends.cudnn.benchmark = False\n# torch.use_deterministic_algorithms(True)\n\n# torch.manual_seed(SEED)\n# np.random.seed(SEED)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2YX7JeP93-TZ","outputId":"51b65e84-6759-42ea-a04c-48a3a1bd7586","trusted":true,"execution":{"iopub.status.busy":"2025-03-17T02:45:27.981722Z","iopub.execute_input":"2025-03-17T02:45:27.981957Z","iopub.status.idle":"2025-03-17T02:45:27.997831Z","shell.execute_reply.started":"2025-03-17T02:45:27.981927Z","shell.execute_reply":"2025-03-17T02:45:27.997225Z"}},"outputs":[],"execution_count":63},{"cell_type":"markdown","source":"### Logging","metadata":{"id":"_7ULmzow4jSg"}},{"cell_type":"markdown","source":"To configure ClearML in your Colab environment, follow these steps:\n\n---\n\n*Step 1: Create a ClearML Account*\n1. Go to the [ClearML website](https://clear.ml/).\n2. Sign up for a free account if you don’t already have one.\n3. Once registered, log in to your ClearML account.\n\n---\n\n*Step 2: Get Your ClearML Credentials*\n1. After logging in, navigate to the **Settings** page (click on your profile icon in the top-right corner and select **Settings**).\n2. Under the **Workspace** section, find your **+ Create new credentials**.\n3. Copy these credentials for a Jupiter notebook into the code cell below.\n\n---\n\n*Step 3: Accessing the ClearML Dashboard*\n1. Go to your ClearML dashboard (https://app.clear.ml).\n2. Navigate to the **Projects** section to see your experiments.\n3. Click on the experiment (e.g., `Lab_1`) to view detailed metrics, logs, and artifacts.\n\n---","metadata":{"id":"C97DLT0gK37A"}},{"cell_type":"code","source":"#Enter your code here to implement Step 2 of the logging instruction as it is shown below\n%env CLEARML_WEB_HOST=https://app.clear.ml/\n%env CLEARML_API_HOST=https://api.clear.ml\n%env CLEARML_FILES_HOST=https://files.clear.ml\n# cv_assigment_1\n%env CLEARML_API_ACCESS_KEY=R0N975GNTCABSQL9704N8SAJFI38UC\n%env CLEARML_API_SECRET_KEY=uei3ZuufRCHh8ucWUVDyAnZ3_VR-_Q0vMgRqpGNJYotCHp7zfoGpPAnqj2Z8EGnmwf4","metadata":{"id":"lTXMGNya32_3","colab":{"base_uri":"https://localhost:8080/"},"outputId":"4aad4dff-7484-49a7-d2c7-d509c4e4e13a","trusted":true,"execution":{"iopub.status.busy":"2025-03-17T02:45:27.998727Z","iopub.execute_input":"2025-03-17T02:45:27.998979Z","iopub.status.idle":"2025-03-17T02:45:28.017395Z","shell.execute_reply.started":"2025-03-17T02:45:27.998935Z","shell.execute_reply":"2025-03-17T02:45:28.016630Z"}},"outputs":[{"name":"stdout","text":"env: CLEARML_WEB_HOST=https://app.clear.ml/\nenv: CLEARML_API_HOST=https://api.clear.ml\nenv: CLEARML_FILES_HOST=https://files.clear.ml\nenv: CLEARML_API_ACCESS_KEY=R0N975GNTCABSQL9704N8SAJFI38UC\nenv: CLEARML_API_SECRET_KEY=uei3ZuufRCHh8ucWUVDyAnZ3_VR-_Q0vMgRqpGNJYotCHp7zfoGpPAnqj2Z8EGnmwf4\n","output_type":"stream"}],"execution_count":64},{"cell_type":"markdown","source":"### Dataset","metadata":{"id":"BujHK4sw7cA7"}},{"cell_type":"markdown","source":"Summary","metadata":{"id":"Wb0uJtxz-E--"}},{"cell_type":"code","source":"DATASET = 'CIFAR10N' # dataset with the real-world noise\n# Can be 'clean_label', 'worse_label', 'aggre_label', 'random_label1', 'random_label2', 'random_label3'\nNOISE_TYPE = 'clean_label'\nLS = 0.4\n\nNS = {\n    'train': 45000,\n    'val': 5000,\n    'test': 10000\n} # for MNIST\n\nSIZE = 32 #image size 32 is original size, but a ViT needs 224\nNUM_CLASSES = 10\nCLASS_NAMES = ['plane', 'car', 'bird', 'cat',\n               'deer', 'dog', 'frog', 'horse', 'ship', 'truck']","metadata":{"id":"hWRDBJbO7k_u","trusted":true,"execution":{"iopub.status.busy":"2025-03-17T02:45:28.018227Z","iopub.execute_input":"2025-03-17T02:45:28.018442Z","iopub.status.idle":"2025-03-17T02:45:28.035871Z","shell.execute_reply.started":"2025-03-17T02:45:28.018413Z","shell.execute_reply":"2025-03-17T02:45:28.035022Z"}},"outputs":[],"execution_count":65},{"cell_type":"markdown","source":"### Collect parameters","metadata":{"id":"GwaBDKEvD5ya"}},{"cell_type":"code","source":"#Model parameters\nLOSS_FUN = 'CE' # 'CE', 'N', 'B', etc.\nARCHITECTURE = 'ResNet50' # 'CNN', 'ResNet50', 'ViT', etc.\n\n#Collect the parameters (hyperparams and others)\nim_size = SIZE if ARCHITECTURE == 'CNN' else 224\nhparams = {\n    \"seed\": SEED,\n    \"lr\": 0.001,\n    'weight_decay': 0.0,\n    \"dropout\": 0.0,\n    \"bs\": 128,\n    \"num_workers\": 2,\n    \"num_epochs\": 20,\n    \"criterion\": LOSS_FUN,\n    \"architecture\": ARCHITECTURE,\n    'freeze': True,\n    \"num_samples\": NS,\n    \"im_size\": im_size,\n    \"mean\": np.array([0.4914, 0.4822, 0.4465]),\n    \"std\": np.array([0.2470, 0.2435, 0.2616]),\n    'randResCrop': {'size': (im_size, im_size), 'scale': (0.8, 1.0), 'ratio': (0.9, 1.1)},\n    'label_smoothing': LS,\n    \"n_classes\": NUM_CLASSES,\n    \"noise_path\": './data/CIFAR-10_human_kaggle.pt',\n    \"noise_type\": NOISE_TYPE  # Can be 'clean_label', 'worse_label', 'aggre_label', etc.\n}\n\n#Visualization\nvis_params = {\n    'fig_size': 5,\n    'num_samples': 5,\n    'num_bins': 50,\n}","metadata":{"id":"NSyUzYCSD0v3","trusted":true,"execution":{"iopub.status.busy":"2025-03-17T02:45:28.038600Z","iopub.execute_input":"2025-03-17T02:45:28.038791Z","iopub.status.idle":"2025-03-17T02:45:28.051205Z","shell.execute_reply.started":"2025-03-17T02:45:28.038775Z","shell.execute_reply":"2025-03-17T02:45:28.050477Z"}},"outputs":[],"execution_count":66},{"cell_type":"markdown","source":"## Functions","metadata":{"id":"OQsu5FcbFfwx"}},{"cell_type":"markdown","source":"### Lightning","metadata":{"id":"ZAOMnXlqFofC"}},{"cell_type":"markdown","source":"Data module","metadata":{"id":"2N2vslXcUvGT"}},{"cell_type":"code","source":"def download_file(url, save_path):\n    \"\"\"Download a file from a URL and save it to the specified path.\"\"\"\n    response = requests.get(url, stream=True)\n    if response.status_code == 200:\n        os.makedirs(os.path.dirname(save_path), exist_ok=True)  # Ensure directory exists\n        with open(save_path, 'wb') as f:\n            for chunk in response.iter_content(chunk_size=8192):\n                f.write(chunk)\n        print(f\"File downloaded and saved to {save_path}\")\n    else:\n        raise Exception(f\"Failed to download file from {url}. Status code: {response.status_code}\")","metadata":{"id":"l4LT-NyRgAWZ","trusted":true,"execution":{"iopub.status.busy":"2025-03-17T02:45:28.052669Z","iopub.execute_input":"2025-03-17T02:45:28.052930Z","iopub.status.idle":"2025-03-17T02:45:28.071742Z","shell.execute_reply.started":"2025-03-17T02:45:28.052909Z","shell.execute_reply":"2025-03-17T02:45:28.070995Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"class CIFAR10(datasets.CIFAR10):\n    \"\"\"CIFAR10 dataset with noisy labels.\"\"\"\n    def __init__(self, root, train=True, transform=None, target_transform=None,\n                 download=False, noise_type=None, noise_path=None, is_human=True):\n        super().__init__(root, train=train, transform=transform,\n                         target_transform=target_transform, download=download)\n        self.noise_type = noise_type\n        self.noise_path = noise_path\n        self.is_human = is_human\n\n        if self.train and self.noise_type is not None:\n            self.load_noisy_labels()\n\n    def load_noisy_labels(self):\n        noise_file = torch.load(self.noise_path)\n        if isinstance(noise_file, dict):\n            if \"clean_label\" in noise_file.keys():\n                clean_label = torch.tensor(noise_file['clean_label'])\n                assert torch.sum(torch.tensor(self.targets) - clean_label) == 0\n                print(f'Loaded {self.noise_type} from {self.noise_path}.')\n                print(f'The overall noise rate is {1 - np.mean(clean_label.numpy() == noise_file[self.noise_type])}')\n            self.noisy_labels = noise_file[self.noise_type].reshape(-1)\n        else:\n            raise Exception('Input Error')\n\n    def __getitem__(self, index):\n        img, target = super().__getitem__(index)\n        if self.train and self.noise_type is not None:\n            target = self.noisy_labels[index]\n        return img, target, index","metadata":{"id":"_3lxFLivgJIn","trusted":true,"execution":{"iopub.status.busy":"2025-03-17T02:45:28.072601Z","iopub.execute_input":"2025-03-17T02:45:28.072897Z","iopub.status.idle":"2025-03-17T02:45:28.090131Z","shell.execute_reply.started":"2025-03-17T02:45:28.072864Z","shell.execute_reply":"2025-03-17T02:45:28.089335Z"}},"outputs":[],"execution_count":68},{"cell_type":"code","source":"class CIFAR10DataModule(pl.LightningDataModule):\n    def __init__(self, params):\n        super().__init__()\n        self.seed = params['seed']\n        self.batch_size = params['bs']\n        self.num_workers = params['num_workers']\n        self.mean = params['mean']\n        self.std = params['std']\n        self.ns = params['num_samples']\n        self.rand_res_crop = params['randResCrop']\n        self.noise_path = params.get('noise_path', './data/CIFAR-10_human.pt')\n        self.noise_type = params.get('noise_type', 'worse_label')  # Default to 'worse_label'\n\n        # Ensure the data directory exists\n        os.makedirs(os.path.dirname(self.noise_path), exist_ok=True)\n\n        # Download the CIFAR-10_human.pt file if it doesn't exist\n        if not os.path.exists(self.noise_path):\n            print(f\"Downloading CIFAR-10_human.pt from GitHub...\")\n            download_file(\n                url=\"https://github.com/UCSC-REAL/cifar-10-100n/raw/main/data/CIFAR-10_human.pt\",\n                save_path=self.noise_path\n            )\n\n        self.transform = transforms.Compose([\n            transforms.RandomResizedCrop(size=self.rand_res_crop['size'],\n                                         scale=self.rand_res_crop['scale'],\n                                         ratio=self.rand_res_crop['ratio']),\n            transforms.ToTensor(),\n            transforms.Normalize(self.mean, self.std)\n        ])\n\n    def prepare_data(self):\n        # Download CIFAR-10 dataset\n        datasets.CIFAR10(root='./data', train=True, download=True)\n        datasets.CIFAR10(root='./data', train=False, download=True)\n\n    def setup(self, stage=None):\n        # Load noisy labels\n        noise_file = torch.load(self.noise_path)\n        clean_label = noise_file['clean_label']\n        noisy_label = noise_file[self.noise_type]\n\n        # Split dataset into train and validation sets\n        cifar10_full = CIFAR10(root='./data', train=True, transform=self.transform,\n                               noise_type=self.noise_type, noise_path=self.noise_path, is_human=True)\n        pl.seed_everything(self.seed)\n        self.cifar10_train, self.cifar10_val = random_split(cifar10_full,\n                                                            [self.ns['train'],\n                                                             self.ns['val']])\n        self.cifar10_test = CIFAR10(root='./data', train=False, transform=self.transform)\n\n    def train_dataloader(self):\n        return DataLoader(self.cifar10_train, batch_size=self.batch_size,\n                          num_workers=self.num_workers, shuffle=True)\n\n    def val_dataloader(self):\n        return DataLoader(self.cifar10_val, batch_size=self.batch_size,\n                          num_workers=self.num_workers)\n\n    def test_dataloader(self):\n        return DataLoader(self.cifar10_test, batch_size=self.batch_size,\n                          shuffle=False)","metadata":{"id":"7WcQVIXnfiX3","trusted":true,"execution":{"iopub.status.busy":"2025-03-17T02:45:28.090824Z","iopub.execute_input":"2025-03-17T02:45:28.091092Z","iopub.status.idle":"2025-03-17T02:45:28.114114Z","shell.execute_reply.started":"2025-03-17T02:45:28.091073Z","shell.execute_reply":"2025-03-17T02:45:28.113290Z"}},"outputs":[],"execution_count":69},{"cell_type":"markdown","source":"Training module","metadata":{"id":"JBWSuYApFu7X"}},{"cell_type":"code","source":"class train_model(pl.LightningModule):\n    def __init__(self, model=None, loss=None, hparams=hparams):\n        super().__init__()\n        self.save_hyperparameters(hparams)\n        self.model = model\n        self.loss_fn = loss\n        self.nc = hparams['n_classes']\n        self.lr = hparams['lr']\n        self.wd = hparams['weight_decay']\n\n    def forward(self, x):\n        return self.model(x)\n\n    def training_step(self, batch, batch_idx):\n        x, y, _ = batch  # Unpack batch (ignore indices for now)\n        logits = self(x)\n        loss = self.loss_fn(logits, y)\n\n        # Log training loss and accuracy\n        # preds = torch.argmax(logits[:, :self.nc], dim=1)\n        # acc = (preds == y).float().mean()\n        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n        # self.log('train_acc', acc, on_step=True, on_epoch=True, prog_bar=True)\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        x, y, _ = batch  # Unpack batch (ignore indices for now)\n        logits = self(x)\n        loss = self.loss_fn(logits, y)\n\n        # Log validation loss and accuracy\n        # preds = torch.argmax(logits[:, :self.nc], dim=1)\n        # acc = (preds == y).float().mean()\n        self.log('val_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n        # self.log('val_acc', acc, on_step=True, on_epoch=True, prog_bar=True)\n        return loss\n\n    def test_step(self, batch, batch_idx):\n        x, y, _ = batch  # Unpack batch (ignore indices for now)\n        logits = self(x)\n        loss = self.loss_fn(logits, y)\n\n        # Log test loss and accuracy\n        preds = torch.argmax(logits[:, :self.nc], dim=1)\n        acc = (preds == y).float().mean()\n        self.log('test_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n        self.log('test_acc', acc, on_step=True, on_epoch=True, prog_bar=True)\n        return {'loss': loss, 'preds': preds, 'y': y}\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.wd)\n\n        # Optionally, add a learning rate scheduler\n        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=1.0)\n        return [optimizer], [scheduler]","metadata":{"id":"g-uYzVgj2f-6","trusted":true,"execution":{"iopub.status.busy":"2025-03-17T02:45:28.114857Z","iopub.execute_input":"2025-03-17T02:45:28.115123Z","iopub.status.idle":"2025-03-17T02:45:28.135953Z","shell.execute_reply.started":"2025-03-17T02:45:28.115094Z","shell.execute_reply":"2025-03-17T02:45:28.135218Z"}},"outputs":[],"execution_count":70},{"cell_type":"markdown","source":"### Models","metadata":{"id":"SpGtoJicGCJC"}},{"cell_type":"markdown","source":"CNN from paper by [Xia](https://arxiv.org/abs/2106.00445)","metadata":{"id":"aA10MARCuTL_"}},{"cell_type":"code","source":"def call_bn(bn, x):\n    return bn(x)\n\nclass CNN(nn.Module):\n    def __init__(self, input_channel=3, n_outputs=10, dropout_rate=0.25, top_bn=False):\n        self.dropout_rate = dropout_rate\n        self.top_bn = top_bn\n        super(CNN, self).__init__()\n        self.c1=nn.Conv2d(input_channel,128,kernel_size=3,stride=1, padding=1)\n        self.c2=nn.Conv2d(128,128,kernel_size=3,stride=1, padding=1)\n        self.c3=nn.Conv2d(128,128,kernel_size=3,stride=1, padding=1)\n        self.c4=nn.Conv2d(128,256,kernel_size=3,stride=1, padding=1)\n        self.c5=nn.Conv2d(256,256,kernel_size=3,stride=1, padding=1)\n        self.c6=nn.Conv2d(256,256,kernel_size=3,stride=1, padding=1)\n        self.c7=nn.Conv2d(256,512,kernel_size=3,stride=1, padding=0)\n        self.c8=nn.Conv2d(512,256,kernel_size=3,stride=1, padding=0)\n        self.c9=nn.Conv2d(256,128,kernel_size=3,stride=1, padding=0)\n        self.l_c1=nn.Linear(128,n_outputs)\n        self.bn1=nn.BatchNorm2d(128)\n        self.bn2=nn.BatchNorm2d(128)\n        self.bn3=nn.BatchNorm2d(128)\n        self.bn4=nn.BatchNorm2d(256)\n        self.bn5=nn.BatchNorm2d(256)\n        self.bn6=nn.BatchNorm2d(256)\n        self.bn7=nn.BatchNorm2d(512)\n        self.bn8=nn.BatchNorm2d(256)\n        self.bn9=nn.BatchNorm2d(128)\n\n    def forward(self, x,):\n        h=x\n        h=self.c1(h)\n        h=F.leaky_relu(call_bn(self.bn1, h), negative_slope=0.01)\n        h=self.c2(h)\n        h=F.leaky_relu(call_bn(self.bn2, h), negative_slope=0.01)\n        h=self.c3(h)\n        h=F.leaky_relu(call_bn(self.bn3, h), negative_slope=0.01)\n        h=F.max_pool2d(h, kernel_size=2, stride=2)\n        h=F.dropout2d(h, p=self.dropout_rate)\n\n        h=self.c4(h)\n        h=F.leaky_relu(call_bn(self.bn4, h), negative_slope=0.01)\n        h=self.c5(h)\n        h=F.leaky_relu(call_bn(self.bn5, h), negative_slope=0.01)\n        h=self.c6(h)\n        h=F.leaky_relu(call_bn(self.bn6, h), negative_slope=0.01)\n        h=F.max_pool2d(h, kernel_size=2, stride=2)\n        h=F.dropout2d(h, p=self.dropout_rate)\n\n        h=self.c7(h)\n        h=F.leaky_relu(call_bn(self.bn7, h), negative_slope=0.01)\n        h=self.c8(h)\n        h=F.leaky_relu(call_bn(self.bn8, h), negative_slope=0.01)\n        h=self.c9(h)\n        h=F.leaky_relu(call_bn(self.bn9, h), negative_slope=0.01)\n        h=F.avg_pool2d(h, kernel_size=h.data.shape[2])\n\n        h = h.view(h.size(0), h.size(1))\n        logit=self.l_c1(h)\n        if self.top_bn:\n            logit=call_bn(self.bn_c1, logit)\n        return logit","metadata":{"id":"oA84H5z_t4oY","trusted":true,"execution":{"iopub.status.busy":"2025-03-17T02:45:28.136779Z","iopub.execute_input":"2025-03-17T02:45:28.137050Z","iopub.status.idle":"2025-03-17T02:45:28.156830Z","shell.execute_reply.started":"2025-03-17T02:45:28.137029Z","shell.execute_reply":"2025-03-17T02:45:28.156110Z"}},"outputs":[],"execution_count":71},{"cell_type":"markdown","source":"ResNet50","metadata":{"id":"vOCLuzMRdgrK"}},{"cell_type":"code","source":"class ResNet50(nn.Module):\n    def __init__(self, n_outputs, freeze=False):\n        \"\"\"\n        Args:\n            n_outputs (int): Number of output classes.\n            freeze (bool): If True, freeze all layers except the head.\n        \"\"\"\n        super(ResNet50, self).__init__()\n        self.n_outputs = n_outputs\n        self.freeze = freeze\n\n        # Load the pre-trained ResNet50 model\n        self.resnet50 = models.resnet50(pretrained=True)\n\n        # Modify the final layer to match the number of outputs\n        self.resnet50.fc = nn.Linear(self.resnet50.fc.in_features, n_outputs)\n\n        # Freeze all layers except the head if freeze=True\n        if self.freeze:\n            self._freeze_layers()\n\n    def _freeze_layers(self):\n        \"\"\"\n        Freeze all layers except the head.\n        \"\"\"\n        # Freeze all parameters in the model\n        for param in self.resnet50.parameters():\n            param.requires_grad = False\n\n        # Unfreeze the final classification layer (head)\n        for param in self.resnet50.fc.parameters():\n            param.requires_grad = True\n\n    def forward(self, x):\n        return self.resnet50(x)\n\ndef count_trainable_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\n# # Example usage\n# model_frozen = ResNet50(n_outputs=10, freeze=True)\n# print(f\"Trainable parameters (freeze=True): {count_trainable_parameters(model_frozen)}\")\n\n# model_unfrozen = ResNet50(n_outputs=10, freeze=False)\n# print(f\"Trainable parameters (freeze=False): {count_trainable_parameters(model_unfrozen)}\")","metadata":{"id":"jzeV5ga6df-q","trusted":true,"execution":{"iopub.status.busy":"2025-03-17T02:45:28.157566Z","iopub.execute_input":"2025-03-17T02:45:28.157751Z","iopub.status.idle":"2025-03-17T02:45:28.175790Z","shell.execute_reply.started":"2025-03-17T02:45:28.157734Z","shell.execute_reply":"2025-03-17T02:45:28.174867Z"}},"outputs":[],"execution_count":72},{"cell_type":"markdown","source":"ViT","metadata":{"id":"eAY6gv8RdffZ"}},{"cell_type":"code","source":"class ViT(nn.Module):\n    def __init__(self, n_outputs, freeze=False):\n        \"\"\"\n        Args:\n            n_outputs (int): Number of output classes.\n            freeze (bool): If True, freeze all layers except the head.\n        \"\"\"\n        super(ViT, self).__init__()\n        self.n_outputs = n_outputs\n        self.freeze = freeze\n\n        # Load the pre-trained ViT model\n        self.vit = models.vit_b_16(pretrained=True)\n\n        # Modify the final layer to match the number of outputs\n        self.vit.heads.head = nn.Linear(self.vit.heads.head.in_features, n_outputs)\n\n        # Freeze all layers except the head if freeze=True\n        if self.freeze:\n            self._freeze_layers()\n\n    def _freeze_layers(self):\n        \"\"\"\n        Freeze all layers except the head.\n        \"\"\"\n        # Freeze all parameters in the model\n        for param in self.vit.parameters():\n            param.requires_grad = False\n\n        # Unfreeze the head (final classification layer)\n        for param in self.vit.heads.head.parameters():\n            param.requires_grad = True\n\n    def forward(self, x):\n        return self.vit(x)\n\ndef count_trainable_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\n# # Example usage\n# model_frozen = ViT(n_outputs=10, freeze=True)\n# print(f\"Trainable parameters (freeze=True): {count_trainable_parameters(model_frozen)}\")\n\n# model_unfrozen = ViT(n_outputs=10, freeze=False)\n# print(f\"Trainable parameters (freeze=False): {count_trainable_parameters(model_unfrozen)}\")\n\n# class ViT(nn.Module):\n#     def __init__(self, n_outputs):\n#         super(ViT, self).__init__()\n#         self.n_outputs = n_outputs\n#         # Load the pre-trained ViT model\n#         self.vit = models.vit_b_16(pretrained=True)\n\n#         # Modify the final layer to match the number of outputs\n#         self.vit.heads.head = nn.Linear(self.vit.heads.head.in_features, n_outputs)\n\n#     def forward(self, x):\n#         return self.vit(x)","metadata":{"id":"EC11nnWZdfF4","trusted":true,"execution":{"iopub.status.busy":"2025-03-17T02:45:28.176656Z","iopub.execute_input":"2025-03-17T02:45:28.176915Z","iopub.status.idle":"2025-03-17T02:45:28.193276Z","shell.execute_reply.started":"2025-03-17T02:45:28.176883Z","shell.execute_reply":"2025-03-17T02:45:28.192600Z"}},"outputs":[],"execution_count":73},{"cell_type":"markdown","source":"### Loss functions","metadata":{"id":"rHm8wnbnGEnA"}},{"cell_type":"markdown","source":"Create a loss function class, or use a standart one.","metadata":{"id":"8z05aQ7cQTm0"}},{"cell_type":"code","source":"# Cross entropy loss maden from scratch (just in case)\nclass CELoss(nn.Module):\n    def __init__(self, params=hparams):\n        super(CELoss, self).__init__()\n        self.smoothing = params.get('label_smoothing', 0.0)  # Default smoothing value\n        self.num_classes = params.get('n_classes', 10)\n        self.inv_smoothing = 1.0 - self.smoothing  # Probability for the correct class\n\n    def forward(self, x, y):\n        \"\"\"\n        x: Model output (logits)\n            - Shape: (batch_size, num_classes)\n        y: Labels\n            - Shape: (batch_size,)\n        \"\"\"\n        # Apply label smoothing to the one-hot encoded labels\n        with torch.no_grad():\n            yoh = torch.zeros_like(x)  # Create a one-hot encoded version of y\n            yoh.fill_(self.smoothing / (self.num_classes - 1))  # Fill with smoothed values\n            yoh.scatter_(1, y.unsqueeze(1), self.inv_smoothing)  # Set correct class to 1 - smoothing\n\n        # Compute the cross-entropy loss between logits and smoothed labels\n        log_probs = F.log_softmax(x, dim=1)  # Log probabilities\n        loss = -(yoh * log_probs).sum(dim=1).mean()  # Sum over classes and mean over batch\n\n        return loss","metadata":{"id":"8auVRUCKGEG2","trusted":true,"execution":{"iopub.status.busy":"2025-03-17T02:45:28.194108Z","iopub.execute_input":"2025-03-17T02:45:28.194319Z","iopub.status.idle":"2025-03-17T02:45:28.213389Z","shell.execute_reply.started":"2025-03-17T02:45:28.194302Z","shell.execute_reply":"2025-03-17T02:45:28.212733Z"}},"outputs":[],"execution_count":74},{"cell_type":"code","source":"class NLoss(nn.Module):\n    def __init__(self, params=hparams):\n        super(NLoss, self).__init__()\n        self.smoothing =   params.get('label_smoothing', 0.0)\n        self.num_classes = params.get('n_classes', 10)\n        self.inv_smoothing = 1.0 - self.smoothing  # Probability for the correct class\n\n    def forward(self, x, y):\n        \"\"\"\n        x: Model output (logits + log variance)\n            - x[:, :self.num_classes]: Logits for class probabilities (h)\n            - x[:, self.num_classes:]: Logarithmic variance (s)\n        y: Labels\n        \"\"\"\n        # Split the model output into predictions (h) and log variance (s)\n        logits = x[:, :self.num_classes]  # Predictions (h)\n        log_var = x[:, self.num_classes:]  # Logarithmic variance (s)\n\n        # Apply label smoothing to the one-hot encoded labels\n        with torch.no_grad():\n            yoh = torch.zeros_like(logits)\n            yoh.fill_(self.smoothing / (self.num_classes - 1))\n            yoh.scatter_(1, y.data.unsqueeze(1), self.inv_smoothing)\n\n        # Compute the squared differences between predictions and smoothed labels\n        squared_diff = torch.pow(yoh - logits, 2)  # (y_k - h_k)^2\n\n        # Compute the exponential of the negative log variance (e^{-s})\n        exp_neg_log_var = torch.exp(-log_var)\n\n        # Compute the first term of the loss: e^{-s} * sum((y_k - h_k)^2)\n        term1 = exp_neg_log_var * squared_diff.sum(dim=1)\n\n        # Compute the second term of the loss: N * s\n        term2 = self.num_classes * log_var\n\n        # Combine the terms and compute the mean over the batch\n        loss = (term1 + term2).mean()\n\n        return loss","metadata":{"id":"An6Q9DUNK3SE","trusted":true,"execution":{"iopub.status.busy":"2025-03-17T02:45:28.214137Z","iopub.execute_input":"2025-03-17T02:45:28.214363Z","iopub.status.idle":"2025-03-17T02:45:28.232083Z","shell.execute_reply.started":"2025-03-17T02:45:28.214342Z","shell.execute_reply":"2025-03-17T02:45:28.231454Z"}},"outputs":[],"execution_count":75},{"cell_type":"code","source":"class BLoss(nn.Module):\n    def __init__(self, params=hparams):\n        super(BLoss, self).__init__()\n        self.smoothing =   params.get('label_smoothing', 0.0)\n        self.num_classes = params.get('n_classes', 10)\n        self.inv_smoothing = 1.0 - self.smoothing  # Probability for the correct class\n\n\n    def forward(self, x, y):\n        # Extract certainty and probabilities from the model output\n        certainty = torch.sigmoid(x[:, self.num_classes:])  # Certainty values\n        logits = x[:, :self.num_classes]  # Logits for class probabilities\n        prob = F.softmax(logits, dim=1)  # Softmax probabilities\n\n        # Compute cosine similarity between predictions and labels\n        cos = nn.CosineSimilarity(dim=1)\n\n        # Apply label smoothing to the one-hot encoded labels\n        with torch.no_grad():\n            yoh = torch.zeros_like(logits)\n            yoh.fill_(self.smoothing / (self.num_classes - 1))\n            yoh.scatter_(1, y.data.unsqueeze(1), self.inv_smoothing)\n\n\n        # Compute the terms of the loss\n        cosyh = cos(yoh, prob)\n        delta = yoh * prob  # Element-wise product of one-hot labels and probabilities\n        entropy_term = delta * torch.log(delta + 1e-10)  # Entropy term (avoid log(0))\n\n        # Loss terms\n        loss0 = -cosyh * torch.log(certainty / self.num_classes + 1e-10)  # First term\n        loss1 = -(self.num_classes - 1) * (1 - cosyh) * torch.log((1 - certainty) / self.num_classes + 1e-10)  # Second term\n\n        # Combine the terms and compute the mean over the batch\n        loss = (entropy_term.sum(dim=1) + loss0 + loss1).mean()\n\n        return loss","metadata":{"id":"99a0Eh3AK5wT","trusted":true,"execution":{"iopub.status.busy":"2025-03-17T02:45:28.232894Z","iopub.execute_input":"2025-03-17T02:45:28.233179Z","iopub.status.idle":"2025-03-17T02:45:28.251758Z","shell.execute_reply.started":"2025-03-17T02:45:28.233154Z","shell.execute_reply":"2025-03-17T02:45:28.251120Z"}},"outputs":[],"execution_count":76},{"cell_type":"markdown","source":"### Models zoo","metadata":{"id":"ZHSuQd99s_Ou"}},{"cell_type":"markdown","source":"Architectures and loss functions","metadata":{"id":"T0QP_le1tPL1"}},{"cell_type":"code","source":"def get_arch_and_loss(hparams):\n    \"\"\"\n    Returns the architecture and loss function based on the provided hparams.\n\n    Args:\n        hparams (dict): Hyperparameters dictionary, including 'ARCHITECTURE' and 'criterion'.\n\n    Returns:\n        arch: The model architecture.\n        loss: The loss function.\n    \"\"\"\n    # Determine the number of outputs based on the loss function\n    if hparams['criterion'] in ['B', 'N']:\n        n_outputs = hparams['n_classes'] + 1  # Add 1 output neuron for BLoss or NLoss\n    else:\n        n_outputs = hparams['n_classes']  # Default number of outputs\n\n    # Define the architectures\n    architectures = {\n        'CNN': CNN(n_outputs=n_outputs),\n        'ResNet50': ResNet50(n_outputs=n_outputs, freeze=hparams.get('freeze', False)),\n        'ViT': ViT(n_outputs=n_outputs, freeze=hparams.get('freeze', False)),\n    }\n\n    # Define the loss functions\n    losses = {\n        'CE':CELoss(),\n        'B': BLoss(),\n        'N': NLoss(),\n    }\n\n    # Get the architecture and loss based on hparams\n    arch = architectures.get(hparams['architecture'])\n    loss = losses.get(hparams['criterion'])\n\n    if arch is None:\n        raise ValueError(f\"Architecture '{hparams['ARCHITECTURE']}' is not supported.\")\n    if loss is None:\n        raise ValueError(f\"Loss function '{hparams['criterion']}' is not supported.\")\n\n    return arch, loss\n","metadata":{"id":"WfLgyavidUcW","trusted":true,"execution":{"iopub.status.busy":"2025-03-17T02:45:28.252553Z","iopub.execute_input":"2025-03-17T02:45:28.252749Z","iopub.status.idle":"2025-03-17T02:45:28.268602Z","shell.execute_reply.started":"2025-03-17T02:45:28.252730Z","shell.execute_reply":"2025-03-17T02:45:28.267780Z"}},"outputs":[],"execution_count":77},{"cell_type":"markdown","source":"### Metrics","metadata":{"id":"CWrc-f3sWDDm"}},{"cell_type":"code","source":"def metrics(dataloader,model,hparams=hparams,loss_fn_red=None):\n    # Collect images, predictions, and losses\n    # images = []\n    preds  = []\n    labels = []\n    losses = []\n    correct= 0\n    total  = 0\n    for batch in dataloader:\n        x, y, _ = batch\n        with torch.no_grad():\n            logits = model(x)\n            # loss = loss_fn_red(h,y)\n            pred = torch.argmax(logits[:,:hparams['n_classes']], dim=1)\n        correct += (pred == y).sum().item()  # Number of correct predictions\n        total += y.size(0)  # Total number of samples\n\n        # images.extend(x.cpu())\n        preds.extend(pred.cpu().numpy())\n        labels.extend(y.cpu().numpy())\n        # losses.extend(loss.cpu().numpy())\n    acc = correct / total\n    return preds, labels, acc","metadata":{"id":"7793mMFKWFYS","trusted":true,"execution":{"iopub.status.busy":"2025-03-17T02:45:28.269600Z","iopub.execute_input":"2025-03-17T02:45:28.269877Z","iopub.status.idle":"2025-03-17T02:45:28.285544Z","shell.execute_reply.started":"2025-03-17T02:45:28.269850Z","shell.execute_reply":"2025-03-17T02:45:28.284845Z"}},"outputs":[],"execution_count":78},{"cell_type":"markdown","source":"### Visualization\n","metadata":{"id":"HAPUCxThGgsQ"}},{"cell_type":"code","source":"# Plot confusion matrix\ndef conf_mat(figsize,class_names=None):\n    plt.figure(figsize)\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n                xticklabels=class_names, yticklabels=class_names)\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title('Confusion Matrix')\n    plt.show()","metadata":{"id":"gznqmB6aQbEf","trusted":true,"execution":{"iopub.status.busy":"2025-03-17T02:45:28.286245Z","iopub.execute_input":"2025-03-17T02:45:28.286463Z","iopub.status.idle":"2025-03-17T02:45:28.302396Z","shell.execute_reply.started":"2025-03-17T02:45:28.286434Z","shell.execute_reply":"2025-03-17T02:45:28.301663Z"}},"outputs":[],"execution_count":79},{"cell_type":"markdown","source":"# Ensembling\nThis approach is expected to give a robust ensemble model that leverages the diversity introduced by different seeds, potentially improving the overall accuracy on the test set.","metadata":{"id":"KemJG62D7EJC"}},{"cell_type":"markdown","source":"## Create Dataset and Data Loaders","metadata":{"id":"7d0C987gzzlW"}},{"cell_type":"markdown","source":"Initialization of the dataset, the dataloader, and the training module","metadata":{"id":"tQmBPmYH21V9"}},{"cell_type":"code","source":"data_module = CIFAR10DataModule(hparams)","metadata":{"id":"jrjw6mU-z36-","colab":{"base_uri":"https://localhost:8080/"},"outputId":"dfdba151-b01b-455b-ebd6-1905c2d753dd","trusted":true,"execution":{"iopub.status.busy":"2025-03-17T02:45:28.303182Z","iopub.execute_input":"2025-03-17T02:45:28.303437Z","iopub.status.idle":"2025-03-17T02:45:28.315644Z","shell.execute_reply.started":"2025-03-17T02:45:28.303417Z","shell.execute_reply":"2025-03-17T02:45:28.315014Z"}},"outputs":[],"execution_count":80},{"cell_type":"markdown","source":"## Train the Ensemble","metadata":{"id":"oBfy6DZL0tii"}},{"cell_type":"markdown","source":"Loop over different seeds","metadata":{"id":"sjxsAXHbrGC2"}},{"cell_type":"code","source":"# List to store predictions from each model\nall_predictions = []","metadata":{"id":"4qZzt5w4smrt","trusted":true,"execution":{"iopub.status.busy":"2025-03-17T02:45:28.318365Z","iopub.execute_input":"2025-03-17T02:45:28.318554Z","iopub.status.idle":"2025-03-17T02:45:28.328544Z","shell.execute_reply.started":"2025-03-17T02:45:28.318538Z","shell.execute_reply":"2025-03-17T02:45:28.327827Z"}},"outputs":[],"execution_count":81},{"cell_type":"code","source":"for seed in SEEDS:\n    # Set seed for reproducibility at the VERY BEGINNING\n    pl.seed_everything(seed)\n\n    # Reinitialize the model architecture for each seed\n    arch, loss_fn = get_arch_and_loss(hparams)\n\n    checkpoint_callback_img = ModelCheckpoint(\n        monitor='val_loss',       # Monitor validation loss\n        dirpath=CHECKPOINT_PATH,  # Directory to save checkpoints\n        filename=f'best_model_{ARCHITECTURE}_{LOSS_FUN}_{seed}_{LS}_{NOISE_TYPE}',  # Checkpoint filename\n        save_top_k=1,             # Save only the best model\n        mode='min',               # Minimize validation loss\n    )\n\n    task = Task.init(\n        project_name=\"ICML-2025\",\n        task_name=f'arch_{ARCHITECTURE}_loss_{LOSS_FUN}_seed_{seed}_LS_{LS}_noise_{NOISE_TYPE}',\n        tags=[\n            str(ARCHITECTURE),\n            str(LOSS_FUN),\n            str(seed),\n            str(NOISE_TYPE),\n        ]\n    )\n\n    # Initialize the model with the reinitialized architecture\n    model = train_model(model=arch, loss=loss_fn)\n\n    # Log hyperparameters to ClearML\n    task.connect(model.hparams)\n\n    trainer = Trainer(max_epochs=hparams['num_epochs'],\n                      callbacks=[checkpoint_callback_img],\n                      accelerator=\"auto\", devices=\"auto\")\n    trainer.fit(model, data_module)\n\n    best_model_path = checkpoint_callback_img.best_model_path\n    task.update_output_model(model_path=best_model_path, auto_delete_file=False)\n    best_model = train_model.load_from_checkpoint(best_model_path,\n                                                  model=arch,\n                                                  loss=loss_fn)\n\n    # Test set\n    test_dataloader = data_module.test_dataloader()\n    # Move the model to the correct device\n    best_model = best_model.to(device)\n    predictions = []\n    with torch.no_grad():\n        for batch in test_dataloader:\n            x, _, _, = batch  # We only need the input data, not the labels\n            logits = best_model(x.to(device))\n            preds = torch.argmax(logits[:, :NUM_CLASSES], dim=1)\n            predictions.append(preds.cpu().numpy())\n    predictions = np.concatenate(predictions)  # Combine all batch predictions\n    all_predictions.append(predictions)\n\n    if seed != SEEDS[-1]:\n        task.close()\n        del[model, best_model, task, arch, loss_fn]","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"QisO7wDarFVS","outputId":"cddaed3c-b467-4579-91b2-63beed43f6b9","trusted":true,"execution":{"iopub.status.busy":"2025-03-17T02:45:28.329491Z","iopub.execute_input":"2025-03-17T02:45:28.329714Z"}},"outputs":[{"name":"stderr","text":"Jupyter Notebook auto-logging failed, could not access: /kaggle/working/__notebook_source__.ipynb\n","output_type":"stream"},{"name":"stdout","text":"ClearML Task: created new task id=4bc7de7b86594710b941e1061276edb4\nClearML results page: https://app.clear.ml/projects/243e8e810a5b494f9691fc43f3a5a833/experiments/4bc7de7b86594710b941e1061276edb4/output/log\n","output_type":"stream"},{"name":"stderr","text":"Parameters must be of builtin type (General/mean[ndarray], General/std[ndarray])\n","output_type":"stream"},{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\nLoaded clean_label from ./data/CIFAR-10_human_kaggle.pt.\nThe overall noise rate is 0.0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2940a284c1ae4798b32ac8ed8dfb2bc8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"███████████████████████████████ 100% | 90.23/90.23 MB [00:06<00:00, 13.35MB/s]: \nJupyter Notebook auto-logging failed, could not access: /kaggle/working/__notebook_source__.ipynb\n","output_type":"stream"},{"name":"stdout","text":"ClearML Task: created new task id=1157ce9b7d964b9d8096324f0e26c96f\nClearML results page: https://app.clear.ml/projects/243e8e810a5b494f9691fc43f3a5a833/experiments/1157ce9b7d964b9d8096324f0e26c96f/output/log\n","output_type":"stream"},{"name":"stderr","text":"Parameters must be of builtin type (General/mean[ndarray], General/std[ndarray])\n","output_type":"stream"},{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\nLoaded clean_label from ./data/CIFAR-10_human_kaggle.pt.\nThe overall noise rate is 0.0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"669caf950fc9482abef70195cc858265"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stderr","text":"███████████████████████████████ 100% | 90.23/90.23 MB [00:06<00:00, 13.39MB/s]: \nJupyter Notebook auto-logging failed, could not access: /kaggle/working/__notebook_source__.ipynb\n","output_type":"stream"},{"name":"stdout","text":"ClearML Task: created new task id=7a79d2542939488aa9ec145b10993bb3\nClearML results page: https://app.clear.ml/projects/243e8e810a5b494f9691fc43f3a5a833/experiments/7a79d2542939488aa9ec145b10993bb3/output/log\n","output_type":"stream"},{"name":"stderr","text":"Parameters must be of builtin type (General/mean[ndarray], General/std[ndarray])\n","output_type":"stream"},{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\nLoaded clean_label from ./data/CIFAR-10_human_kaggle.pt.\nThe overall noise rate is 0.0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9885409f5a374ecc92fb303e4f0fa3fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}}],"execution_count":null},{"cell_type":"markdown","source":"## Test the models and the ensemble of the models","metadata":{"id":"NYbuTthVuCDo"}},{"cell_type":"code","source":"all_predictions","metadata":{"id":"zOYyF657_kOY","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e5ee8b1a-5408-4616-9312-287dc6d9a961","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Individual models","metadata":{"id":"yRxEnWceGYxn"}},{"cell_type":"code","source":"# List to store individual model accuracies\nindividual_accuracies = []\n\n# Compute accuracy for each model\nfor i, predictions in enumerate(all_predictions):\n    # Get predictions for the current model\n    model_predictions = predictions  # Shape: (num_samples,)\n\n    # Get true labels (already collected earlier)\n    true_labels = np.array(data_module.cifar10_test.targets)\n\n    # Calculate accuracy for the current model\n    accuracy = accuracy_score(true_labels, model_predictions)\n    individual_accuracies.append(accuracy)\n    print(f'Model {i+1} Accuracy: {accuracy:.4f}')\n\n# Convert to numpy array for easier calculations\nindividual_accuracies = np.array(individual_accuracies)\n\n# Compute mean accuracy\nmean_accuracy = np.mean(individual_accuracies)\n\n# Compute standard deviation of accuracy\nstd_accuracy = np.std(individual_accuracies)\n\n# Compute max standard deviation of accuracy\nmax_std_accuracy = np.sqrt(np.power(individual_accuracies - mean_accuracy, 2)).max()\n\nprint(f'Mean Accuracy: {mean_accuracy:.4f}')\nprint(f'Standard Deviation of Accuracy: {std_accuracy:.4f}')\nprint(f'Max Standard Deviation of Accuracy: {max_std_accuracy:.4f}')","metadata":{"id":"WSr0zvfIGeSd","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b1209a8d-97c3-46f4-8ba0-2c409ca36e18","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Ensemble","metadata":{"id":"iop73XibGhUv"}},{"cell_type":"code","source":"# Stack predictions from all models\nall_predictions = np.stack(all_predictions)  # Shape: (num_models, num_samples, num_classes)\n\n# Ensemble predictions (e.g., by averaging)\nensemble_predictions = np.mean(all_predictions, axis=0)  # Shape: (num_samples, num_classes)\nfinal_predictions, _ = mode(all_predictions, axis=0)  # Majority voting\nfinal_predictions = final_predictions.flatten()  # Flatten to 1D array\n\n# Get true labels from the CIFAR-10 data set\ntest_labels = np.array(data_module.cifar10_test.targets)\n# test_labels = data_module.test_dataset.labels  # Adjust this based on your dataset\n\n# Calculate accuracy\naccuracy = accuracy_score(test_labels, final_predictions)\nprint(f'Ensemble Accuracy: {accuracy:.4f}')\n\n# Compute confusion matrix\ncm = confusion_matrix(test_labels, final_predictions)","metadata":{"id":"xyUFGexws8QK","colab":{"base_uri":"https://localhost:8080/"},"outputId":"119d4b88-8c59-40e3-cf20-b043f1bd9797","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Simulated test metrics\ntest_metrics = {\n    \"Mean Accuracy (individual)\": mean_accuracy,\n    \"Standard Deviation of Accuracy (individual)\": std_accuracy,\n    \"Ensemble Accuracy\": accuracy,\n    \"Max Standard Deviation of Accuracy\": max_std_accuracy\n}\n\ntask.connect(test_metrics)","metadata":{"id":"VbEGs97IgtRD","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f1e0d8ed-b65a-4c4d-f6e4-3306b96f55e9","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"task.close()","metadata":{"id":"nIqc-cspappI","trusted":true},"outputs":[],"execution_count":null}]}