{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mechanics-Mechatronics-and-Robotics/CV-2025/blob/main/Assignment_01/UQ_CIFAR-10N_Ensembling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dviRg5xn5mza"
      },
      "source": [
        "#Uncertainty Quantification with CIFAR-10N and Ensembling\n",
        "By *First name* *Second name*.\n",
        "\n",
        "*Month, Day, 2025.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fS8QkXU47uNl"
      },
      "source": [
        "## Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvP6IWSB5s_c"
      },
      "source": [
        "Re-annotated versions of the CIFAR-10 and CIFAR-100 data which contains real-world human annotation errors. We show how these noise patterns deviate from the classically assumed ones and what the new challenges are. The website of CIFAR-N is available at [cifar-10-100n\n",
        "](https://github.com/UCSC-REAL/cifar-10-100n/tree/main) project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kN9yU_U6766c"
      },
      "source": [
        "# Preparation of simulation models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mpwlpoX5TI3"
      },
      "source": [
        "## Import and Install Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xMPnV0nV4_-I",
        "outputId": "8ee3f1de-e8eb-4f85-f998-b2579f7dddcc"
      },
      "outputs": [],
      "source": [
        "# !pip install pytorch-lightning clearml\n",
        "# !pip install nbconvert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fDHrafErmo43"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/damirnurtdinov/miniconda3/envs/py39/lib/python3.9/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: 'dlopen(/Users/damirnurtdinov/miniconda3/envs/py39/lib/python3.9/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib\n",
            "  Referenced from: <FB2FD416-6C4D-3621-B677-61F07C02A3C5> /Users/damirnurtdinov/miniconda3/envs/py39/lib/python3.9/site-packages/torchvision/image.so\n",
            "  Reason: tried: '/Users/damirnurtdinov/miniconda3/envs/py39/lib/python3.9/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/Users/damirnurtdinov/miniconda3/envs/py39/lib/python3.9/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/Users/damirnurtdinov/miniconda3/envs/py39/lib/python3.9/lib-dynload/../../libjpeg.9.dylib' (no such file), '/Users/damirnurtdinov/miniconda3/envs/py39/bin/../lib/libjpeg.9.dylib' (no such file)'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
            "  warn(\n",
            "/Users/damirnurtdinov/miniconda3/envs/py39/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "#Pytorch modules\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import datasets, transforms, models\n",
        "#scipy\n",
        "from scipy.stats import mode\n",
        "#sklearn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "#Numpy\n",
        "import numpy as np\n",
        "#Pandas\n",
        "import pandas as pd\n",
        "#Lightning & logging\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import Trainer\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "#Data observation\n",
        "import os\n",
        "import sys\n",
        "import pickle\n",
        "import requests\n",
        "from pathlib import Path\n",
        "#Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "#Logging\n",
        "from clearml import Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ealb85K93wDT"
      },
      "source": [
        "## Set the Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHIKBWI93-zD"
      },
      "source": [
        "### Simulation Settings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiYPAzh54gjM"
      },
      "source": [
        "Check the current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "phE7U1vu31BR",
        "outputId": "84b2985c-8bf8-45b2-a36f-a5980ab41f3e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/Users/damirnurtdinov/Desktop/My Courses/Classical CV/assignments/Assignment_01'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.getcwd() #returns the current working directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7EVwTLDiNYyc",
        "outputId": "6c96530f-b316-4a34-c715-6600e2ddf8be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CHECKPOINT_PATH: saved_models/\n"
          ]
        }
      ],
      "source": [
        "# Path to the folder where the pretrained models are saved\n",
        "CHECKPOINT_PATH = os.environ.get(\"PATH_CHECKPOINT\", \"saved_models/\")\n",
        "print(f'CHECKPOINT_PATH: {CHECKPOINT_PATH}')\n",
        "\n",
        "os.makedirs(CHECKPOINT_PATH, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WK77wcO6sfb"
      },
      "source": [
        "Set the reproducibility options"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YX7JeP93-TZ",
        "outputId": "d31f01f8-7a08-4a91-a0ed-0ec58fd0d60b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Seed set to 42\n"
          ]
        }
      ],
      "source": [
        "# Function for setting the seed to implement parallel tests\n",
        "SEEDS = [42, 0, 17, 9, 3, 16, 2]\n",
        "SEED = 42 # random seed by default\n",
        "pl.seed_everything(SEED)\n",
        "\n",
        "# Determine the device (GPU if available, otherwise CPU)\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device = torch.device('mps') # I have M1 chip\n",
        "\n",
        "# Prioritizes speed but may reduce precision\n",
        "torch.set_float32_matmul_precision('high')\n",
        "\n",
        "# # Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.use_deterministic_algorithms(True)\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7ULmzow4jSg"
      },
      "source": [
        "### Logging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C97DLT0gK37A"
      },
      "source": [
        "To configure ClearML in your Colab environment, follow these steps:\n",
        "\n",
        "---\n",
        "\n",
        "*Step 1: Create a ClearML Account*\n",
        "1. Go to the [ClearML website](https://clear.ml/).\n",
        "2. Sign up for a free account if you donâ€™t already have one.\n",
        "3. Once registered, log in to your ClearML account.\n",
        "\n",
        "---\n",
        "\n",
        "*Step 2: Get Your ClearML Credentials*\n",
        "1. After logging in, navigate to the **Settings** page (click on your profile icon in the top-right corner and select **Settings**).\n",
        "2. Under the **Workspace** section, find your **+ Create new credentials**.\n",
        "3. Copy these credentials for a Jupiter notebook into the code cell below.\n",
        "\n",
        "---\n",
        "\n",
        "*Step 3: Accessing the ClearML Dashboard*\n",
        "1. Go to your ClearML dashboard (https://app.clear.ml).\n",
        "2. Navigate to the **Projects** section to see your experiments.\n",
        "3. Click on the experiment (e.g., `Lab_1`) to view detailed metrics, logs, and artifacts.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lTXMGNya32_3",
        "outputId": "0f971c8e-0b4f-4ac9-c093-67f93be52c67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: CLEARML_WEB_HOST=https://app.clear.ml/\n",
            "env: CLEARML_API_HOST=https://api.clear.ml\n",
            "env: CLEARML_FILES_HOST=https://files.clear.ml\n",
            "env: CLEARML_API_ACCESS_KEY=TE4F21KJIPICL6GUUCTSQ7K1OC3C48\n",
            "env: CLEARML_API_SECRET_KEY=RqUK21J4VhHSpRyf5MTF6LBMnj6-C1V6pE-vfJFvZ7QFuGtz_MbojHgorRIEmrJHawA\n"
          ]
        }
      ],
      "source": [
        "#Enter your code here to implement Step 2 of the logging instruction as it is shown below\n",
        "%env CLEARML_WEB_HOST=https://app.clear.ml/\n",
        "%env CLEARML_API_HOST=https://api.clear.ml\n",
        "%env CLEARML_FILES_HOST=https://files.clear.ml\n",
        "%env CLEARML_API_ACCESS_KEY=TE4F21KJIPICL6GUUCTSQ7K1OC3C48\n",
        "%env CLEARML_API_SECRET_KEY=RqUK21J4VhHSpRyf5MTF6LBMnj6-C1V6pE-vfJFvZ7QFuGtz_MbojHgorRIEmrJHawA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BujHK4sw7cA7"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wb0uJtxz-E--"
      },
      "source": [
        "Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hWRDBJbO7k_u"
      },
      "outputs": [],
      "source": [
        "DATASET = 'CIFAR10N' # dataset with the real-world noise\n",
        "# Can be 'clean_label', 'worse_label', 'aggre_label', 'random_label1', 'random_label2', 'random_label3'\n",
        "NOISE_TYPE = 'worse_label'\n",
        "\n",
        "NS = {\n",
        "    'train': 45000,\n",
        "    'val': 5000,\n",
        "    'test': 10000\n",
        "} # for MNIST\n",
        "\n",
        "SIZE = 32 #image size\n",
        "NUM_CLASSES = 10\n",
        "CLASS_NAMES = ['plane', 'car', 'bird', 'cat',\n",
        "               'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qP6TSQ-Z-Hxd"
      },
      "source": [
        "Normalization parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Oh-UxEQ3-Le3"
      },
      "outputs": [],
      "source": [
        "#For the MNIST dataset\n",
        "MEAN = np.array([0.491,0.482,0.447])\n",
        "STD  = np.array([0.247,0.243,0.261])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StCJNi9PDVZK"
      },
      "source": [
        "Transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwaBDKEvD5ya"
      },
      "source": [
        "### Collect parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NSyUzYCSD0v3"
      },
      "outputs": [],
      "source": [
        "#Model parameters\n",
        "LOSS_FUN = 'N' # 'CE','CELoss'(custom), 'N', 'B', etc.\n",
        "ARCHITECTURE = 'CNN' # 'CNN, 'ResNet50', 'ViT', etc.\n",
        "\n",
        "#Collect the parameters (hyperparams and others)\n",
        "hparams = {\n",
        "    \"seed\": SEED,\n",
        "    \"lr\": 0.001,\n",
        "    'weight_decay': 0.0,\n",
        "    \"dropout\": 0.0,\n",
        "    \"bs\": 128,\n",
        "    \"num_workers\": 0, #set 2 in Colab, or 0 in InnoDataHub\n",
        "    \"num_epochs\": 20,\n",
        "    \"criterion\": LOSS_FUN,\n",
        "    \"architecture\": ARCHITECTURE,\n",
        "    \"num_samples\": NS,\n",
        "    \"im_size\": SIZE,\n",
        "    \"mean\": np.array([0.4914, 0.4822, 0.4465]),\n",
        "    \"std\": np.array([0.2470, 0.2435, 0.2616]),\n",
        "    'randResCrop': {'size': (SIZE, SIZE), 'scale': (0.8, 1.0), 'ratio': (0.9, 1.1)},\n",
        "    \"n_classes\": NUM_CLASSES,\n",
        "    \"noise_path\": './data/CIFAR-10_human.pt',\n",
        "    \"noise_type\": NOISE_TYPE  # Can be 'clean_label', 'worse_label', 'aggre_label', etc.\n",
        "}\n",
        "\n",
        "#Visualization\n",
        "vis_params = {\n",
        "    'fig_size': 5,\n",
        "    'num_samples': 5,\n",
        "    'num_bins': 50,\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQsu5FcbFfwx"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAOMnXlqFofC"
      },
      "source": [
        "### Lightning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2N2vslXcUvGT"
      },
      "source": [
        "Data module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "l4LT-NyRgAWZ"
      },
      "outputs": [],
      "source": [
        "def download_file(url, save_path):\n",
        "    \"\"\"Download a file from a URL and save it to the specified path.\"\"\"\n",
        "    response = requests.get(url, stream=True)\n",
        "    if response.status_code == 200:\n",
        "        os.makedirs(os.path.dirname(save_path), exist_ok=True)  # Ensure directory exists\n",
        "        with open(save_path, 'wb') as f:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "        print(f\"File downloaded and saved to {save_path}\")\n",
        "    else:\n",
        "        raise Exception(f\"Failed to download file from {url}. Status code: {response.status_code}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_3lxFLivgJIn"
      },
      "outputs": [],
      "source": [
        "class CIFAR10(datasets.CIFAR10):\n",
        "    \"\"\"CIFAR10 dataset with noisy labels.\"\"\"\n",
        "    def __init__(self, root, train=True, transform=None, target_transform=None,\n",
        "                 download=False, noise_type=None, noise_path=None, is_human=True):\n",
        "        super().__init__(root, train=train, transform=transform,\n",
        "                         target_transform=target_transform, download=download)\n",
        "        self.noise_type = noise_type\n",
        "        self.noise_path = noise_path\n",
        "        self.is_human = is_human\n",
        "\n",
        "        if self.train and self.noise_type is not None:\n",
        "            self.load_noisy_labels()\n",
        "\n",
        "    def load_noisy_labels(self):\n",
        "        noise_file = torch.load(self.noise_path)\n",
        "        if isinstance(noise_file, dict):\n",
        "            if \"clean_label\" in noise_file.keys():\n",
        "                clean_label = torch.tensor(noise_file['clean_label'])\n",
        "                assert torch.sum(torch.tensor(self.targets) - clean_label) == 0\n",
        "                print(f'Loaded {self.noise_type} from {self.noise_path}.')\n",
        "                print(f'The overall noise rate is {1 - np.mean(clean_label.numpy() == noise_file[self.noise_type])}')\n",
        "            self.noisy_labels = noise_file[self.noise_type].reshape(-1)\n",
        "        else:\n",
        "            raise Exception('Input Error')\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img, target = super().__getitem__(index)\n",
        "        if self.train and self.noise_type is not None:\n",
        "            target = self.noisy_labels[index]\n",
        "        return img, target, index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "7WcQVIXnfiX3"
      },
      "outputs": [],
      "source": [
        "class CIFAR10DataModule(pl.LightningDataModule):\n",
        "    def __init__(self, params):\n",
        "        super().__init__()\n",
        "        self.seed = params['seed']\n",
        "        self.batch_size = params['bs']\n",
        "        self.num_workers = params['num_workers']\n",
        "        self.mean = params['mean']\n",
        "        self.std = params['std']\n",
        "        self.ns = params['num_samples']\n",
        "        self.rand_res_crop = params['randResCrop']\n",
        "        self.noise_path = params.get('noise_path', './data/CIFAR-10_human.pt')\n",
        "        self.noise_type = params.get('noise_type', 'worse_label')  # Default to 'worse_label'\n",
        "\n",
        "        # Ensure the data directory exists\n",
        "        os.makedirs(os.path.dirname(self.noise_path), exist_ok=True)\n",
        "\n",
        "        # Download the CIFAR-10_human.pt file if it doesn't exist\n",
        "        if not os.path.exists(self.noise_path):\n",
        "            print(f\"Downloading CIFAR-10_human.pt from GitHub...\")\n",
        "            download_file(\n",
        "                url=\"https://github.com/UCSC-REAL/cifar-10-100n/raw/main/data/CIFAR-10_human.pt\",\n",
        "                save_path=self.noise_path\n",
        "            )\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.RandomResizedCrop(size=self.rand_res_crop['size'],\n",
        "                                         scale=self.rand_res_crop['scale'],\n",
        "                                         ratio=self.rand_res_crop['ratio']),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(self.mean, self.std)\n",
        "        ])\n",
        "\n",
        "    def prepare_data(self):\n",
        "        # Download CIFAR-10 dataset\n",
        "        datasets.CIFAR10(root='./data', train=True, download=True)\n",
        "        datasets.CIFAR10(root='./data', train=False, download=True)\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        # Load noisy labels\n",
        "        noise_file = torch.load(self.noise_path)\n",
        "        clean_label = noise_file['clean_label']\n",
        "        noisy_label = noise_file[self.noise_type]\n",
        "\n",
        "        # Split dataset into train and validation sets\n",
        "        cifar10_full = CIFAR10(root='./data', train=True, transform=self.transform,\n",
        "                               noise_type=self.noise_type, noise_path=self.noise_path, is_human=True)\n",
        "        pl.seed_everything(self.seed)\n",
        "        self.cifar10_train, self.cifar10_val = random_split(cifar10_full,\n",
        "                                                            [self.ns['train'],\n",
        "                                                             self.ns['val']])\n",
        "        self.cifar10_test = CIFAR10(root='./data', train=False, transform=self.transform)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.cifar10_train, batch_size=self.batch_size,\n",
        "                          num_workers=self.num_workers, shuffle=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.cifar10_val, batch_size=self.batch_size,\n",
        "                          num_workers=self.num_workers)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.cifar10_test, batch_size=self.batch_size,\n",
        "                          shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBWSuYApFu7X"
      },
      "source": [
        "Training module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "g-uYzVgj2f-6"
      },
      "outputs": [],
      "source": [
        "class train_model(pl.LightningModule):\n",
        "    def __init__(self, model=None, loss=None, hparams=hparams):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters(hparams)\n",
        "        self.model = model\n",
        "        self.loss_fn = loss\n",
        "        self.nc = hparams['n_classes']\n",
        "        self.lr = hparams['lr']\n",
        "        self.wd = hparams['weight_decay']\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y, _ = batch  # Unpack batch (ignore indices for now)\n",
        "        logits = self(x)\n",
        "        loss = self.loss_fn(logits, y)\n",
        "\n",
        "        # Log training loss and accuracy\n",
        "        # preds = torch.argmax(logits[:, :self.nc], dim=1)\n",
        "        # acc = (preds == y).float().mean()\n",
        "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
        "        # self.log('train_acc', acc, on_step=True, on_epoch=True, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y, _ = batch  # Unpack batch (ignore indices for now)\n",
        "        logits = self(x)\n",
        "        loss = self.loss_fn(logits, y)\n",
        "\n",
        "        # Log validation loss and accuracy\n",
        "        # preds = torch.argmax(logits[:, :self.nc], dim=1)\n",
        "        # acc = (preds == y).float().mean()\n",
        "        self.log('val_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
        "        # self.log('val_acc', acc, on_step=True, on_epoch=True, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y, _ = batch  # Unpack batch (ignore indices for now)\n",
        "        logits = self(x)\n",
        "        loss = self.loss_fn(logits, y)\n",
        "\n",
        "        # Log test loss and accuracy\n",
        "        preds = torch.argmax(logits[:, :self.nc], dim=1)\n",
        "        acc = (preds == y).float().mean()\n",
        "        self.log('test_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
        "        self.log('test_acc', acc, on_step=True, on_epoch=True, prog_bar=True)\n",
        "        return {'loss': loss, 'preds': preds, 'y': y}\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.wd)\n",
        "\n",
        "        # Optionally, add a learning rate scheduler\n",
        "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=1.0)\n",
        "        return [optimizer], [scheduler]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpGtoJicGCJC"
      },
      "source": [
        "### Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aA10MARCuTL_"
      },
      "source": [
        "CNN from paper by [Xia](https://arxiv.org/abs/2106.00445)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "oA84H5z_t4oY"
      },
      "outputs": [],
      "source": [
        "# #Copy the code from the paper\n",
        "# class CNN(nn.Module):\n",
        "#     def __init__(self, input_size, n_outputs=10):\n",
        "#         super(CNN, self).__init__()\n",
        "        \n",
        "#         # First block\n",
        "#         self.conv1 = nn.Conv2d(3, 128, kernel_size=3, padding=1)\n",
        "#         self.conv2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "#         self.conv3 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "#         self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "#         self.dropout1 = nn.Dropout(0.25)\n",
        "        \n",
        "#         # Second block\n",
        "#         self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "#         self.conv5 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "#         self.conv6 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "#         self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "#         self.dropout2 = nn.Dropout(0.25)\n",
        "        \n",
        "#         # Third block\n",
        "#         self.conv7 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
        "#         self.conv8 = nn.Conv2d(512, 256, kernel_size=3, padding=1)\n",
        "#         self.conv9 = nn.Conv2d(256, 128, kernel_size=3, padding=1)\n",
        "#         self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        \n",
        "#         # Fully connected layer\n",
        "#         self.fc = nn.Linear(128, n_outputs)\n",
        "        \n",
        "#     def forward(self, x):\n",
        "#         # First block\n",
        "#         x = F.leaky_relu(self.conv1(x))\n",
        "#         x = F.leaky_relu(self.conv2(x))\n",
        "#         x = F.leaky_relu(self.conv3(x))\n",
        "#         x = self.pool1(x)\n",
        "#         x = self.dropout1(x)\n",
        "        \n",
        "#         # Second block\n",
        "#         x = F.leaky_relu(self.conv4(x))\n",
        "#         x = F.leaky_relu(self.conv5(x))\n",
        "#         x = F.leaky_relu(self.conv6(x))\n",
        "#         x = self.pool2(x)\n",
        "#         x = self.dropout2(x)\n",
        "        \n",
        "#         # Third block\n",
        "#         x = F.leaky_relu(self.conv7(x))\n",
        "#         x = F.leaky_relu(self.conv8(x))\n",
        "#         x = F.leaky_relu(self.conv9(x))\n",
        "#         x = self.avgpool(x)\n",
        "#         x = x.view(x.size(0), -1)\n",
        "        \n",
        "#         # Fully connected layer\n",
        "#         x = self.fc(x)\n",
        "#         return x\n",
        "\n",
        "def call_bn(bn, x):\n",
        "    return bn(x)\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, input_channel=3, n_outputs=10, dropout_rate=0.25, top_bn=False):\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.top_bn = top_bn\n",
        "        super(CNN, self).__init__()\n",
        "        self.c1=nn.Conv2d(input_channel,128,kernel_size=3,stride=1, padding=1)\n",
        "        self.c2=nn.Conv2d(128,128,kernel_size=3,stride=1, padding=1)\n",
        "        self.c3=nn.Conv2d(128,128,kernel_size=3,stride=1, padding=1)\n",
        "        self.c4=nn.Conv2d(128,256,kernel_size=3,stride=1, padding=1)\n",
        "        self.c5=nn.Conv2d(256,256,kernel_size=3,stride=1, padding=1)\n",
        "        self.c6=nn.Conv2d(256,256,kernel_size=3,stride=1, padding=1)\n",
        "        self.c7=nn.Conv2d(256,512,kernel_size=3,stride=1, padding=0)\n",
        "        self.c8=nn.Conv2d(512,256,kernel_size=3,stride=1, padding=0)\n",
        "        self.c9=nn.Conv2d(256,128,kernel_size=3,stride=1, padding=0)\n",
        "        self.l_c1=nn.Linear(128,n_outputs)\n",
        "        self.bn1=nn.BatchNorm2d(128)\n",
        "        self.bn2=nn.BatchNorm2d(128)\n",
        "        self.bn3=nn.BatchNorm2d(128)\n",
        "        self.bn4=nn.BatchNorm2d(256)\n",
        "        self.bn5=nn.BatchNorm2d(256)\n",
        "        self.bn6=nn.BatchNorm2d(256)\n",
        "        self.bn7=nn.BatchNorm2d(512)\n",
        "        self.bn8=nn.BatchNorm2d(256)\n",
        "        self.bn9=nn.BatchNorm2d(128)\n",
        "\n",
        "    def forward(self, x,):\n",
        "        h=x\n",
        "        h=self.c1(h)\n",
        "        h=F.leaky_relu(call_bn(self.bn1, h), negative_slope=0.01)\n",
        "        h=self.c2(h)\n",
        "        h=F.leaky_relu(call_bn(self.bn2, h), negative_slope=0.01)\n",
        "        h=self.c3(h)\n",
        "        h=F.leaky_relu(call_bn(self.bn3, h), negative_slope=0.01)\n",
        "        h=F.max_pool2d(h, kernel_size=2, stride=2)\n",
        "        h=F.dropout2d(h, p=self.dropout_rate)\n",
        "\n",
        "        h=self.c4(h)\n",
        "        h=F.leaky_relu(call_bn(self.bn4, h), negative_slope=0.01)\n",
        "        h=self.c5(h)\n",
        "        h=F.leaky_relu(call_bn(self.bn5, h), negative_slope=0.01)\n",
        "        h=self.c6(h)\n",
        "        h=F.leaky_relu(call_bn(self.bn6, h), negative_slope=0.01)\n",
        "        h=F.max_pool2d(h, kernel_size=2, stride=2)\n",
        "        h=F.dropout2d(h, p=self.dropout_rate)\n",
        "\n",
        "        h=self.c7(h)\n",
        "        h=F.leaky_relu(call_bn(self.bn7, h), negative_slope=0.01)\n",
        "        h=self.c8(h)\n",
        "        h=F.leaky_relu(call_bn(self.bn8, h), negative_slope=0.01)\n",
        "        h=self.c9(h)\n",
        "        h=F.leaky_relu(call_bn(self.bn9, h), negative_slope=0.01)\n",
        "        h=F.avg_pool2d(h, kernel_size=h.data.shape[2])\n",
        "\n",
        "        h = h.view(h.size(0), h.size(1))\n",
        "        logit=self.l_c1(h)\n",
        "        if self.top_bn:\n",
        "            logit=call_bn(self.bn_c1, logit)\n",
        "        return logit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOCLuzMRdgrK"
      },
      "source": [
        "ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ResNet50(nn.Module):\n",
        "    def __init__(self, n_outputs, freeze=False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            n_outputs (int): Number of output classes.\n",
        "            freeze (bool): If True, freeze all layers except the head.\n",
        "        \"\"\"\n",
        "        super(ResNet50, self).__init__()\n",
        "        self.n_outputs = n_outputs\n",
        "        self.freeze = freeze\n",
        "\n",
        "        # Load the pre-trained ResNet50 model\n",
        "        self.resnet50 = models.resnet50(pretrained=True)\n",
        "\n",
        "        # Modify the final layer to match the number of outputs\n",
        "        self.resnet50.fc = nn.Linear(self.resnet50.fc.in_features, n_outputs)\n",
        "\n",
        "        # Freeze all layers except the head if freeze=True\n",
        "        if self.freeze:\n",
        "            self._freeze_layers()\n",
        "\n",
        "    def _freeze_layers(self):\n",
        "        \"\"\"\n",
        "        Freeze all layers except the head.\n",
        "        \"\"\"\n",
        "        # Freeze all parameters in the model\n",
        "        for param in self.resnet50.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Unfreeze the final classification layer (head)\n",
        "        for param in self.resnet50.fc.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet50(x)\n",
        "\n",
        "def count_trainable_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "jzeV5ga6df-q"
      },
      "outputs": [],
      "source": [
        "# class Bottleneck(nn.Module):\n",
        "#     expansion = 4\n",
        "\n",
        "#     def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "#         super(Bottleneck, self).__init__()\n",
        "#         self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
        "#         self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "#         self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "#         self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "#         self.conv3 = nn.Conv2d(out_channels, out_channels * self.expansion, kernel_size=1, bias=False)\n",
        "#         self.bn3 = nn.BatchNorm2d(out_channels * self.expansion)\n",
        "#         self.relu = nn.ReLU(inplace=True)\n",
        "#         self.downsample = downsample\n",
        "#         self.stride = stride\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         identity = x\n",
        "\n",
        "#         out = self.conv1(x)\n",
        "#         out = self.bn1(out)\n",
        "#         out = self.relu(out)\n",
        "\n",
        "#         out = self.conv2(out)\n",
        "#         out = self.bn2(out)\n",
        "#         out = self.relu(out)\n",
        "\n",
        "#         out = self.conv3(out)\n",
        "#         out = self.bn3(out)\n",
        "\n",
        "#         if self.downsample is not None:\n",
        "#             identity = self.downsample(x)\n",
        "\n",
        "#         out += identity\n",
        "#         out = self.relu(out)\n",
        "\n",
        "#         return out\n",
        "\n",
        "# class ResNet50(nn.Module):\n",
        "#     def __init__(self, n_outputs):\n",
        "#         super(ResNet50, self).__init__()\n",
        "#         self.in_channels = 64\n",
        "\n",
        "#         self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "#         self.bn1 = nn.BatchNorm2d(64)\n",
        "#         self.relu = nn.ReLU(inplace=True)\n",
        "#         self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "#         self.layer1 = self._make_layer(64, 3)\n",
        "#         self.layer2 = self._make_layer(128, 4, stride=2)\n",
        "#         self.layer3 = self._make_layer(256, 6, stride=2)\n",
        "#         self.layer4 = self._make_layer(512, 3, stride=2)\n",
        "\n",
        "#         self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "#         self.fc = nn.Linear(512 * Bottleneck.expansion, n_outputs)\n",
        "\n",
        "#     def _make_layer(self, out_channels, blocks, stride=1):\n",
        "#         downsample = None\n",
        "#         if stride != 1 or self.in_channels != out_channels * Bottleneck.expansion:\n",
        "#             downsample = nn.Sequential(\n",
        "#                 nn.Conv2d(self.in_channels, out_channels * Bottleneck.expansion, kernel_size=1, stride=stride, bias=False),\n",
        "#                 nn.BatchNorm2d(out_channels * Bottleneck.expansion),\n",
        "#             )\n",
        "\n",
        "#         layers = []\n",
        "#         layers.append(Bottleneck(self.in_channels, out_channels, stride, downsample))\n",
        "#         self.in_channels = out_channels * Bottleneck.expansion\n",
        "\n",
        "#         for _ in range(1, blocks):\n",
        "#             layers.append(Bottleneck(self.in_channels, out_channels))\n",
        "\n",
        "#         return nn.Sequential(*layers)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.conv1(x)\n",
        "#         x = self.bn1(x)\n",
        "#         x = self.relu(x)\n",
        "#         x = self.maxpool(x)\n",
        "\n",
        "#         x = self.layer1(x)\n",
        "#         x = self.layer2(x)\n",
        "#         x = self.layer3(x)\n",
        "#         x = self.layer4(x)\n",
        "\n",
        "#         x = self.avgpool(x)\n",
        "#         x = torch.flatten(x, 1)\n",
        "#         x = self.fc(x)\n",
        "\n",
        "#         return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAY6gv8RdffZ"
      },
      "source": [
        "ViT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ViT(nn.Module):\n",
        "    def __init__(self, n_outputs, freeze=False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            n_outputs (int): Number of output classes.\n",
        "            freeze (bool): If True, freeze all layers except the head.\n",
        "        \"\"\"\n",
        "        super(ViT, self).__init__()\n",
        "        self.n_outputs = n_outputs\n",
        "        self.freeze = freeze\n",
        "\n",
        "        # Load the pre-trained ViT model\n",
        "        self.vit = models.vit_b_16(pretrained=True)\n",
        "\n",
        "        # Modify the final layer to match the number of outputs\n",
        "        self.vit.heads.head = nn.Linear(self.vit.heads.head.in_features, n_outputs)\n",
        "\n",
        "        # Freeze all layers except the head if freeze=True\n",
        "        if self.freeze:\n",
        "            self._freeze_layers()\n",
        "\n",
        "    def _freeze_layers(self):\n",
        "        \"\"\"\n",
        "        Freeze all layers except the head.\n",
        "        \"\"\"\n",
        "        # Freeze all parameters in the model\n",
        "        for param in self.vit.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Unfreeze the head (final classification layer)\n",
        "        for param in self.vit.heads.head.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.vit(x)\n",
        "\n",
        "def count_trainable_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "EC11nnWZdfF4"
      },
      "outputs": [],
      "source": [
        "# import torch.nn.functional as F\n",
        "\n",
        "# class PatchEmbedding(nn.Module):\n",
        "#     def __init__(self, img_size=224, patch_size=16, in_channels=3, embed_dim=768):\n",
        "#         super(PatchEmbedding, self).__init__()\n",
        "#         self.img_size = img_size\n",
        "#         self.patch_size = patch_size\n",
        "#         self.n_patches = (img_size // patch_size) ** 2\n",
        "\n",
        "#         self.proj = nn.Conv2d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.proj(x)  # (B, E, H, W)\n",
        "#         x = x.flatten(2)  # (B, E, N)\n",
        "#         x = x.transpose(1, 2)  # (B, N, E)\n",
        "#         return x\n",
        "\n",
        "# class MultiHeadAttention(nn.Module):\n",
        "#     def __init__(self, embed_dim, num_heads):\n",
        "#         super(MultiHeadAttention, self).__init__()\n",
        "#         self.embed_dim = embed_dim\n",
        "#         self.num_heads = num_heads\n",
        "#         self.head_dim = embed_dim // num_heads\n",
        "\n",
        "#         self.qkv = nn.Linear(embed_dim, embed_dim * 3)\n",
        "#         self.proj = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         B, N, E = x.shape\n",
        "#         qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, self.head_dim).permute(2, 0, 3, 1, 4)\n",
        "#         q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "\n",
        "#         attn = (q @ k.transpose(-2, -1)) * (self.head_dim ** -0.5)\n",
        "#         attn = F.softmax(attn, dim=-1)\n",
        "\n",
        "#         x = (attn @ v).transpose(1, 2).reshape(B, N, E)\n",
        "#         x = self.proj(x)\n",
        "#         return x\n",
        "\n",
        "# class MLP(nn.Module):\n",
        "#     def __init__(self, embed_dim, hidden_dim):\n",
        "#         super(MLP, self).__init__()\n",
        "#         self.fc1 = nn.Linear(embed_dim, hidden_dim)\n",
        "#         self.fc2 = nn.Linear(hidden_dim, embed_dim)\n",
        "#         self.act = nn.GELU()\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.fc1(x)\n",
        "#         x = self.act(x)\n",
        "#         x = self.fc2(x)\n",
        "#         return x\n",
        "\n",
        "# class TransformerBlock(nn.Module):\n",
        "#     def __init__(self, embed_dim, num_heads, hidden_dim):\n",
        "#         super(TransformerBlock, self).__init__()\n",
        "#         self.attn = MultiHeadAttention(embed_dim, num_heads)\n",
        "#         self.mlp = MLP(embed_dim, hidden_dim)\n",
        "#         self.norm1 = nn.LayerNorm(embed_dim)\n",
        "#         self.norm2 = nn.LayerNorm(embed_dim)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = x + self.attn(self.norm1(x))\n",
        "#         x = x + self.mlp(self.norm2(x))\n",
        "#         return x\n",
        "\n",
        "# class ViT(nn.Module):\n",
        "#     def __init__(self, img_size=224, patch_size=16, in_channels=3, embed_dim=768, num_heads=12, num_layers=12, hidden_dim=3072, n_outputs=10):\n",
        "#         super(ViT, self).__init__()\n",
        "#         self.patch_embed = PatchEmbedding(img_size, patch_size, in_channels, embed_dim)\n",
        "#         self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n",
        "#         self.pos_embed = nn.Parameter(torch.zeros(1, self.patch_embed.n_patches + 1, embed_dim))\n",
        "#         self.blocks = nn.ModuleList([TransformerBlock(embed_dim, num_heads, hidden_dim) for _ in range(num_layers)])\n",
        "#         self.norm = nn.LayerNorm(embed_dim)\n",
        "#         self.fc = nn.Linear(embed_dim, n_outputs)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         B = x.shape[0]\n",
        "#         x = self.patch_embed(x)\n",
        "\n",
        "#         cls_tokens = self.cls_token.expand(B, -1, -1)\n",
        "#         x = torch.cat((cls_tokens, x), dim=1)\n",
        "\n",
        "#         x = x + self.pos_embed\n",
        "\n",
        "#         for block in self.blocks:\n",
        "#             x = block(x)\n",
        "\n",
        "#         x = self.norm(x)\n",
        "#         x = x[:, 0]\n",
        "#         x = self.fc(x)\n",
        "#         return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHm8wnbnGEnA"
      },
      "source": [
        "### Loss functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8z05aQ7cQTm0"
      },
      "source": [
        "Create a loss function class, or use a standart one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "8auVRUCKGEG2"
      },
      "outputs": [],
      "source": [
        "# Cross entropy loss maden from scratch (just in case)\n",
        "class CELoss(nn.Module):\n",
        "    def __init__(self, reduction='mean'):\n",
        "        super(CELoss, self).__init__()\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        # Compute softmax probabilities\n",
        "        prob = nn.functional.softmax(x, 1)\n",
        "        # Compute log probabilities\n",
        "        log_prob = -1.0 * torch.log(prob)\n",
        "        # Gather the log probabilities for the true labels\n",
        "        loss = log_prob.gather(1, y.unsqueeze(1))\n",
        "        # Apply reduction\n",
        "        if self.reduction == 'mean':\n",
        "            loss = loss.mean()\n",
        "        elif self.reduction == 'sum':\n",
        "            loss = loss.sum()\n",
        "        elif self.reduction == 'none':\n",
        "            loss = loss.squeeze()  # Remove extra dimension for consistency\n",
        "        else:\n",
        "            raise ValueError(\"Invalid reduction option.\")\n",
        "\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "An6Q9DUNK3SE"
      },
      "outputs": [],
      "source": [
        "class NLoss(nn.Module):\n",
        "    def __init__(self, params=hparams):\n",
        "        super(NLoss, self).__init__()\n",
        "        self.smoothing =   params.get('label_smoothing', 0.0)\n",
        "        self.num_classes = params.get('n_classes', 10)\n",
        "        self.inv_smoothing = 1.0 - self.smoothing  # Probability for the correct class\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        \"\"\"\n",
        "        x: Model output (logits + log variance)\n",
        "            - x[:, :self.num_classes]: Logits for class probabilities (h)\n",
        "            - x[:, self.num_classes:]: Logarithmic variance (s)\n",
        "        y: Labels\n",
        "        \"\"\"\n",
        "        # Split the model output into predictions (h) and log variance (s)\n",
        "        logits = x[:, :self.num_classes]  # Predictions (h)\n",
        "        log_var = x[:, self.num_classes:]  # Logarithmic variance (s)\n",
        "\n",
        "        # Apply label smoothing to the one-hot encoded labels\n",
        "        with torch.no_grad():\n",
        "            yoh = torch.zeros_like(logits)\n",
        "            yoh.fill_(self.smoothing / (self.num_classes - 1))\n",
        "            yoh.scatter_(1, y.data.unsqueeze(1), self.inv_smoothing)\n",
        "\n",
        "        # Compute the squared differences between predictions and smoothed labels\n",
        "        # logits = torch.softmax(logits, dim=1)  # Convert logits to probabilities\n",
        "        squared_diff = torch.pow(yoh - logits, 2)  # (y_k - h_k)^2\n",
        "\n",
        "        # Compute the exponential of the negative log variance (e^{-s})\n",
        "        # log_var = torch.clamp(log_var, min=-10, max=10)  # Clamp log_var to a reasonable range\n",
        "        exp_neg_log_var = torch.exp(-log_var)\n",
        "\n",
        "        # Compute the first term of the loss: e^{-s} * sum((y_k - h_k)^2)\n",
        "        term1 = exp_neg_log_var * squared_diff.sum(dim=1)\n",
        "\n",
        "        # Compute the second term of the loss: N * s\n",
        "        term2 = self.num_classes * log_var\n",
        "\n",
        "        # Combine the terms and compute the mean over the batch\n",
        "        loss = (term1 + term2).mean()\n",
        "\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "99a0Eh3AK5wT"
      },
      "outputs": [],
      "source": [
        "class BLoss(nn.Module):\n",
        "    def __init__(self, params=hparams):\n",
        "        super(BLoss, self).__init__()\n",
        "        self.smoothing = params.get('label_smoothing', 0.0)\n",
        "        self.num_classes = params.get('n_classes', 10)\n",
        "        self.inv_smoothing = 1.0 - self.smoothing  # Probability for the correct class\n",
        "        self.eps = 1e-10  # Small epsilon for numerical stability\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        \"\"\"\n",
        "        x: Model output (logits + certainty)\n",
        "            - x[:, :self.num_classes]: Logits for class probabilities\n",
        "            - x[:, self.num_classes:]: Certainty values\n",
        "        y: Ground truth labels (class indices)\n",
        "        \"\"\"\n",
        "        # Ensure y is a tensor of class indices\n",
        "        if y.dtype != torch.long:\n",
        "            y = y.long()\n",
        "\n",
        "        # Extract certainty and probabilities from the model output\n",
        "        certainty = torch.sigmoid(x[:, self.num_classes:])  # Certainty values (batch_size, 1)\n",
        "        logits = x[:, :self.num_classes]  # Logits for class probabilities (batch_size, num_classes)\n",
        "        prob = F.softmax(logits, dim=1)  # Softmax probabilities (batch_size, num_classes)\n",
        "\n",
        "        # Apply label smoothing to the one-hot encoded labels\n",
        "        with torch.no_grad():\n",
        "            yoh = torch.zeros_like(logits)\n",
        "            yoh.fill_(self.smoothing / (self.num_classes - 1))\n",
        "            yoh.scatter_(1, y.unsqueeze(1), self.inv_smoothing)\n",
        "\n",
        "        # Compute cosine similarity between predictions and labels\n",
        "        cos = nn.CosineSimilarity(dim=1)\n",
        "        cosyh = cos(yoh, prob)  # Cosine similarity (batch_size,)\n",
        "\n",
        "        # Compute the terms of the loss\n",
        "        delta = yoh * prob  # Element-wise product of one-hot labels and probabilities\n",
        "        entropy_term = delta * torch.log(delta + self.eps)  # Entropy term (avoid log(0))\n",
        "\n",
        "        # Loss terms\n",
        "        loss0 = -cosyh * torch.log(certainty.squeeze() / self.num_classes + self.eps)  # First term\n",
        "        loss1 = -(self.num_classes - 1) * (1 - cosyh) * torch.log((1 - certainty.squeeze()) / self.num_classes + self.eps)  # Second term\n",
        "\n",
        "        # Combine the terms and compute the mean over the batch\n",
        "        loss = (entropy_term.sum(dim=1) + loss0 + loss1).mean()\n",
        "\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHSuQd99s_Ou"
      },
      "source": [
        "### Models zoo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0QP_le1tPL1"
      },
      "source": [
        "Architectures and loss functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "WfLgyavidUcW"
      },
      "outputs": [],
      "source": [
        "def get_arch_and_loss(hparams):\n",
        "    \"\"\"\n",
        "    Returns the architecture and loss function based on the provided hparams.\n",
        "\n",
        "    Args:\n",
        "        hparams (dict): Hyperparameters dictionary, including 'ARCHITECTURE' and 'criterion'.\n",
        "\n",
        "    Returns:\n",
        "        arch: The model architecture.\n",
        "        loss: The loss function.\n",
        "    \"\"\"\n",
        "    # Determine the number of outputs based on the loss function\n",
        "    if hparams['criterion'] in ['B', 'N']:\n",
        "        n_outputs = hparams['n_classes'] + 1  # Add 1 output neuron for BLoss or NLoss\n",
        "    else:\n",
        "        n_outputs = hparams['n_classes']  # Default number of outputs\n",
        "\n",
        "    # Define the architectures\n",
        "    architectures = {\n",
        "        'CNN': CNN(n_outputs=n_outputs),\n",
        "        'ResNet50': ResNet50(n_outputs=n_outputs, freeze=hparams.get('freeze', False)),\n",
        "        'ViT': ViT(n_outputs=n_outputs, freeze=hparams.get('freeze', False)),\n",
        "    }\n",
        "\n",
        "    # Define the loss functions\n",
        "    losses = {\n",
        "        'CE': nn.CrossEntropyLoss(),\n",
        "        'B': BLoss(),\n",
        "        'N': NLoss(),\n",
        "    }\n",
        "\n",
        "    # Get the architecture and loss based on hparams\n",
        "    arch = architectures.get(hparams['architecture'])\n",
        "    loss = losses.get(hparams['criterion'])\n",
        "\n",
        "    if arch is None:\n",
        "        raise ValueError(f\"Architecture '{hparams['ARCHITECTURE']}' is not supported.\")\n",
        "    if loss is None:\n",
        "        raise ValueError(f\"Loss function '{hparams['criterion']}' is not supported.\")\n",
        "\n",
        "    return arch, loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWrc-f3sWDDm"
      },
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "7793mMFKWFYS"
      },
      "outputs": [],
      "source": [
        "def metrics(dataloader,model,hparams=hparams,loss_fn_red=None):\n",
        "    # Collect images, predictions, and losses\n",
        "    # images = []\n",
        "    preds  = []\n",
        "    labels = []\n",
        "    losses = []\n",
        "    correct= 0\n",
        "    total  = 0\n",
        "    for batch in dataloader:\n",
        "        x, y, _ = batch\n",
        "        with torch.no_grad():\n",
        "            logits = model(x)\n",
        "            # loss = loss_fn_red(h,y)\n",
        "            pred = torch.argmax(logits[:,:hparams['n_classes']], dim=1)\n",
        "        correct += (pred == y).sum().item()  # Number of correct predictions\n",
        "        total += y.size(0)  # Total number of samples\n",
        "\n",
        "        # images.extend(x.cpu())\n",
        "        preds.extend(pred.cpu().numpy())\n",
        "        labels.extend(y.cpu().numpy())\n",
        "        # losses.extend(loss.cpu().numpy())\n",
        "    acc = correct / total\n",
        "    return preds, labels, acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KemJG62D7EJC"
      },
      "source": [
        "# Ensembling\n",
        "This approach is expected to give a robust ensemble model that leverages the diversity introduced by different seeds, potentially improving the overall accuracy on the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7d0C987gzzlW"
      },
      "source": [
        "## Create Dataset and Data Loaders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQmBPmYH21V9"
      },
      "source": [
        "Initialization of the dataset, the dataloader, and the training module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/6j/s19nhfjj4pv14vny7nrq8lf00000gn/T/ipykernel_45186/2242261024.py:40: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  noise_file = torch.load(self.noise_path)\n",
            "/var/folders/6j/s19nhfjj4pv14vny7nrq8lf00000gn/T/ipykernel_45186/892821158.py:15: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  noise_file = torch.load(self.noise_path)\n",
            "Seed set to 42\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded worse_label from ./data/CIFAR-10_human.pt.\n",
            "The overall noise rate is 0.40208\n"
          ]
        }
      ],
      "source": [
        "data_module = CIFAR10DataModule(hparams)\n",
        "data_module.prepare_data()\n",
        "data_module.setup()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBfy6DZL0tii"
      },
      "source": [
        "## Train the Ensemble"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjxsAXHbrGC2"
      },
      "source": [
        "Loop over different seeds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "4qZzt5w4smrt"
      },
      "outputs": [],
      "source": [
        "# List to store predictions from each model\n",
        "all_predictions = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "QisO7wDarFVS"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Seed set to 42\n",
            "/Users/damirnurtdinov/miniconda3/envs/py39/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/Users/damirnurtdinov/miniconda3/envs/py39/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/Users/damirnurtdinov/miniconda3/envs/py39/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ClearML Task: created new task id=d054b9b5958e4e6db53b92338ef4c202\n",
            "2025-03-01 21:23:11,580 - clearml.Task - INFO - Storing jupyter notebook directly as code\n",
            "ClearML results page: https://app.clear.ml/projects/edae844b1820483eb0d3e3030b2a943d/experiments/d054b9b5958e4e6db53b92338ef4c202/output/log\n",
            "2025-03-01 21:23:12,720 - clearml.Task - WARNING - Parameters must be of builtin type (General/mean[ndarray], General/std[ndarray])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: True (mps), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "HPU available: False, using: 0 HPUs\n",
            "/Users/damirnurtdinov/miniconda3/envs/py39/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:76: UserWarning:\n",
            "\n",
            "Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ClearML Monitor: GPU monitoring failed getting GPU reading, switching off GPU monitoring\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/damirnurtdinov/miniconda3/envs/py39/lib/python3.9/site-packages/clearml/binding/frameworks/pytorch_bind.py:277: FutureWarning:\n",
            "\n",
            "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-03-01 21:23:17,638 - clearml.model - INFO - Selected model id: 1c572eccb1704c7aa0d671c090d9c8d9\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/damirnurtdinov/miniconda3/envs/py39/lib/python3.9/site-packages/clearml/binding/frameworks/pytorch_bind.py:277: FutureWarning:\n",
            "\n",
            "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-03-01 21:23:23,411 - clearml.model - WARNING - Connecting multiple input models with the same name: `CIFAR-10_human`. This might result in the wrong model being used when executing remotely\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Seed set to 42\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded worse_label from ./data/CIFAR-10_human.pt.\n",
            "The overall noise rate is 0.40208\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/damirnurtdinov/miniconda3/envs/py39/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: UserWarning:\n",
            "\n",
            "Checkpoint directory /Users/damirnurtdinov/Desktop/My Courses/Classical CV/assignments/Assignment_01/checkpoints exists and is not empty.\n",
            "\n",
            "\n",
            "  | Name    | Type  | Params | Mode \n",
            "------------------------------------------\n",
            "0 | model   | CNN   | 4.4 M  | train\n",
            "1 | loss_fn | NLoss | 0      | train\n",
            "------------------------------------------\n",
            "4.4 M     Trainable params\n",
            "0         Non-trainable params\n",
            "4.4 M     Total params\n",
            "17.739    Total estimated model params size (MB)\n",
            "21        Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/damirnurtdinov/miniconda3/envs/py39/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: PossibleUserWarning:\n",
            "\n",
            "The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                           "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/damirnurtdinov/miniconda3/envs/py39/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: PossibleUserWarning:\n",
            "\n",
            "The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 238/352 [01:03<00:30,  3.74it/s, v_num=46, train_loss_step=-15.4, val_loss_step=-17.1, val_loss_epoch=-14.9, train_loss_epoch=-14.1]ClearML Monitor: Could not detect iteration reporting, falling back to iterations as seconds-from-start\n",
            "Epoch 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 352/352 [01:38<00:00,  3.59it/s, v_num=46, train_loss_step=-19.7, val_loss_step=-17.5, val_loss_epoch=-16.9, train_loss_epoch=-18.9]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 352/352 [01:38<00:00,  3.59it/s, v_num=46, train_loss_step=-19.7, val_loss_step=-17.5, val_loss_epoch=-16.9, train_loss_epoch=-18.9]\n",
            "2025-03-01 21:57:05,970 - clearml.storage - INFO - Uploading: 50.82MB to /Users/damirnurtdinov/Desktop/My Courses/Classical CV/assignments/Assignment_01/checkpoints/model-CNN-N-seed-42-epoch=13-val_loss=-17.20.ckpt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       30% | 15.00/50.82 MB [00:01<00:03, 11.13MB/s]: /Users/damirnurtdinov/miniconda3/envs/py39/lib/python3.9/site-packages/pytorch_lightning/utilities/parsing.py:209: UserWarning:\n",
            "\n",
            "Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n",
            "\n",
            "/Users/damirnurtdinov/miniconda3/envs/py39/lib/python3.9/site-packages/pytorch_lightning/utilities/parsing.py:209: UserWarning:\n",
            "\n",
            "Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
            "\n",
            "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                 49% | 25.00/50.82 MB [00:02<00:02, 10.17MB/s]: "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž              59% | 30.00/50.82 MB [00:02<00:02,  9.99MB/s]: "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/damirnurtdinov/miniconda3/envs/py39/lib/python3.9/site-packages/clearml/binding/frameworks/pytorch_bind.py:277: FutureWarning:\n",
            "\n",
            "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "\n",
            "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  98% | 50.00/50.82 MB [00:04<00:00, 10.15MB/s]: /Users/damirnurtdinov/miniconda3/envs/py39/lib/python3.9/site-packages/tqdm/std.py:636: TqdmWarning:\n",
            "\n",
            "clamping frac to range [0, 1]\n",
            "\n",
            "â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100% | 50.82/50.82 MB [00:05<00:00,  9.36MB/s]: "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-03-01 21:57:11,412 - clearml.Task - INFO - Completed model upload to https://files.clear.ml/CV-2025/Assignment1%3Dmodel-CNN-N-seed-42-%7Bepoch%7D_img.d054b9b5958e4e6db53b92338ef4c202/models/model-CNN-N-seed-42-epoch%3D13-val_loss%3D-17.20.ckpt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "/Users/damirnurtdinov/miniconda3/envs/py39/lib/python3.9/site-packages/clearml/binding/frameworks/pytorch_bind.py:277: FutureWarning:\n",
            "\n",
            "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "\n",
            "Seed set to 42\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded worse_label from ./data/CIFAR-10_human.pt.\n",
            "The overall noise rate is 0.40208\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/damirnurtdinov/miniconda3/envs/py39/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: PossibleUserWarning:\n",
            "\n",
            "The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79/79 [30:31<00:00,  0.04it/s]\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "       Test metric             DataLoader 0\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "     test_acc_epoch         0.7394999861717224\n",
            "     test_loss_epoch        -20.603679656982422\n",
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[26], line 57\u001b[0m\n\u001b[1;32m     55\u001b[0m x, y, _ \u001b[38;5;241m=\u001b[39m batch  \u001b[38;5;66;03m# Unpack batch (ignore indices for now)\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 57\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[43mbest_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(logits[:, :best_model\u001b[38;5;241m.\u001b[39mnc], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     59\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mextend(preds\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())  \u001b[38;5;66;03m# Store predictions as numpy array\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[0;32mIn[13], line 12\u001b[0m, in \u001b[0;36mtrain_model.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[0;32mIn[14], line 89\u001b[0m, in \u001b[0;36mCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     87\u001b[0m h\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc2(h)\n\u001b[1;32m     88\u001b[0m h\u001b[38;5;241m=\u001b[39mF\u001b[38;5;241m.\u001b[39mleaky_relu(call_bn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2, h), negative_slope\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m---> 89\u001b[0m h\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m h\u001b[38;5;241m=\u001b[39mF\u001b[38;5;241m.\u001b[39mleaky_relu(call_bn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn3, h), negative_slope\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m     91\u001b[0m h\u001b[38;5;241m=\u001b[39mF\u001b[38;5;241m.\u001b[39mmax_pool2d(h, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
            "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/torch/nn/modules/conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    548\u001b[0m     )\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/miniconda3/envs/py39/lib/python3.9/site-packages/clearml/utilities/process/exit_hooks.py:157\u001b[0m, in \u001b[0;36mExitHooks.signal_handler\u001b[0;34m(self, sig, frame)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# if this is a sig term, we wait until __at_exit is called (basically do nothing)\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sig \u001b[38;5;241m==\u001b[39m signal\u001b[38;5;241m.\u001b[39mSIGINT:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;66;03m# return original handler result\u001b[39;00m\n\u001b[0;32m--> 157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m org_handler \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(org_handler) \u001b[38;5;28;01melse\u001b[39;00m \u001b[43morg_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43msig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_recursion_protection_flag:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# call original\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     os\u001b[38;5;241m.\u001b[39mkill(os\u001b[38;5;241m.\u001b[39mgetpid(), sig)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "for seed in SEEDS:\n",
        "    # Set seed for reproducibility at the VERY BEGINNING\n",
        "    pl.seed_everything(seed)\n",
        "\n",
        "    # Reinitialize the model architecture for each seed\n",
        "    # arch, loss_fn = CNN(SIZE*SIZE), nn.CrossEntropyLoss()\n",
        "    arch, loss_fn = get_arch_and_loss(hparams)\n",
        "\n",
        "    #checkpoint_callback_img = #Enter your code here\n",
        "    checkpoint_callback_img = ModelCheckpoint(\n",
        "        monitor='val_loss',\n",
        "        dirpath='checkpoints/',\n",
        "        filename=f'model-{hparams[\"architecture\"]}-{hparams[\"criterion\"]}-seed-{seed}-{{epoch}}-{{val_loss:.2f}}',\n",
        "        save_top_k=1,\n",
        "        mode='min'\n",
        "    )\n",
        "\n",
        "    task = Task.init(project_name=\"CV-2025\", task_name=f'Assignment1=model-{hparams[\"architecture\"]}-{hparams[\"criterion\"]}-seed-{seed}-{{epoch}}_img')\n",
        "\n",
        "    # Initialize the model with the reinitialized architecture\n",
        "    model = train_model(model=arch,loss=loss_fn)\n",
        "\n",
        "    # Log hyperparameters to ClearML\n",
        "    task.connect(model.hparams)\n",
        "\n",
        "    trainer = Trainer(max_epochs=hparams['num_epochs'],\n",
        "                  callbacks=[checkpoint_callback_img],\n",
        "                  accelerator=\"auto\", devices=\"auto\")\n",
        "    # Train the model\n",
        "    trainer.fit(model, data_module)\n",
        "\n",
        "    # Get the path to the best model\n",
        "    best_model_path = checkpoint_callback_img.best_model_path\n",
        "\n",
        "    # Update the output model in the task\n",
        "    task.update_output_model(model_path=best_model_path, auto_delete_file=False)\n",
        "\n",
        "    # Test set\n",
        "    test_dataloader = data_module.test_dataloader()\n",
        "\n",
        "    # Move the model to the correct device\n",
        "    # best_model = model.model.load_state_dict(torch.load(best_model_path))\n",
        "    # state_dict = torch.load(best_model_path)['state_dict']\n",
        "    # new_state_dict = {key.replace(\"model.\", \"\"): value for key, value in state_dict.items()}\n",
        "    # best_model = train_model(model=arch,loss=loss_fn)\n",
        "    # best_model.model.load_state_dict(new_state_dict)\n",
        "    # best_model = best_model.to(device)\n",
        "    best_model = train_model.load_from_checkpoint(best_model_path, model=arch, loss=loss_fn)\n",
        "    best_model = best_model.to(device)\n",
        "    test_results = trainer.test(best_model, dataloaders=test_dataloader)\n",
        "    \n",
        "    # predictions = trainer.predict(best_model, dataloaders=test_dataloader)\n",
        "    predictions = []\n",
        "    for batch in test_dataloader:\n",
        "        x, y, _ = batch  # Unpack batch (ignore indices for now)\n",
        "        with torch.no_grad():\n",
        "            logits = best_model(x)\n",
        "            preds = torch.argmax(logits[:, :best_model.nc], dim=1)\n",
        "            predictions.extend(preds.cpu().numpy())  # Store predictions as numpy array\n",
        "    # Store predictions\n",
        "    all_predictions.append(predictions)\n",
        "    # predictions = trainer.predict(best_model, test_dataloader)\n",
        "\n",
        "    if seed != SEEDS[-1]:\n",
        "        task.close()\n",
        "        del[model, best_model, task, arch, loss_fn]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions = []\n",
        "for batch in test_dataloader:\n",
        "        x, y, _ = batch  # Unpack batch (ignore indices for now)\n",
        "        with torch.no_grad():\n",
        "            logits = best_model(x)\n",
        "            preds = torch.argmax(logits[:, :best_model.nc], dim=1)\n",
        "            predictions.extend(preds.cpu().numpy())  # Store predictions as numpy array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[np.int64(3),\n",
              " np.int64(1),\n",
              " np.int64(1),\n",
              " np.int64(8),\n",
              " np.int64(6),\n",
              " np.int64(6),\n",
              " np.int64(1),\n",
              " np.int64(6),\n",
              " np.int64(3),\n",
              " np.int64(1),\n",
              " np.int64(0),\n",
              " np.int64(9),\n",
              " np.int64(5),\n",
              " np.int64(7),\n",
              " np.int64(9),\n",
              " np.int64(6),\n",
              " np.int64(5),\n",
              " np.int64(7),\n",
              " np.int64(8),\n",
              " np.int64(6),\n",
              " np.int64(7),\n",
              " np.int64(2),\n",
              " np.int64(2),\n",
              " np.int64(1),\n",
              " np.int64(4),\n",
              " np.int64(2),\n",
              " np.int64(6),\n",
              " np.int64(0),\n",
              " np.int64(9),\n",
              " np.int64(2),\n",
              " np.int64(6),\n",
              " np.int64(5),\n",
              " np.int64(2),\n",
              " np.int64(5),\n",
              " np.int64(9),\n",
              " np.int64(3),\n",
              " np.int64(4),\n",
              " np.int64(1),\n",
              " np.int64(9),\n",
              " np.int64(5),\n",
              " np.int64(4),\n",
              " np.int64(6),\n",
              " np.int64(2),\n",
              " np.int64(6),\n",
              " np.int64(8),\n",
              " np.int64(1),\n",
              " np.int64(3),\n",
              " np.int64(9),\n",
              " np.int64(7),\n",
              " np.int64(2),\n",
              " np.int64(8),\n",
              " np.int64(8),\n",
              " np.int64(7),\n",
              " np.int64(6),\n",
              " np.int64(8),\n",
              " np.int64(8),\n",
              " np.int64(7),\n",
              " np.int64(5),\n",
              " np.int64(3),\n",
              " np.int64(5),\n",
              " np.int64(7),\n",
              " np.int64(5),\n",
              " np.int64(6),\n",
              " np.int64(5),\n",
              " np.int64(5),\n",
              " np.int64(2),\n",
              " np.int64(1),\n",
              " np.int64(2),\n",
              " np.int64(5),\n",
              " np.int64(7),\n",
              " np.int64(0),\n",
              " np.int64(3),\n",
              " np.int64(8),\n",
              " np.int64(8),\n",
              " np.int64(0),\n",
              " np.int64(2),\n",
              " np.int64(9),\n",
              " np.int64(5),\n",
              " np.int64(7),\n",
              " np.int64(8),\n",
              " np.int64(8),\n",
              " np.int64(1),\n",
              " np.int64(1),\n",
              " np.int64(7),\n",
              " np.int64(2),\n",
              " np.int64(7),\n",
              " np.int64(2),\n",
              " np.int64(7),\n",
              " np.int64(8),\n",
              " np.int64(1),\n",
              " np.int64(8),\n",
              " np.int64(6),\n",
              " np.int64(8),\n",
              " np.int64(6),\n",
              " np.int64(4),\n",
              " np.int64(6),\n",
              " np.int64(6),\n",
              " np.int64(0),\n",
              " np.int64(0),\n",
              " np.int64(7),\n",
              " np.int64(4),\n",
              " np.int64(5),\n",
              " np.int64(6),\n",
              " np.int64(3),\n",
              " np.int64(1),\n",
              " np.int64(1),\n",
              " np.int64(0),\n",
              " np.int64(6),\n",
              " np.int64(8),\n",
              " np.int64(7),\n",
              " np.int64(7),\n",
              " np.int64(2),\n",
              " np.int64(2),\n",
              " np.int64(2),\n",
              " np.int64(1),\n",
              " np.int64(3),\n",
              " np.int64(2),\n",
              " np.int64(4),\n",
              " np.int64(6),\n",
              " np.int64(5),\n",
              " np.int64(8),\n",
              " np.int64(5),\n",
              " np.int64(1),\n",
              " np.int64(2),\n",
              " np.int64(8),\n",
              " np.int64(8),\n",
              " np.int64(8),\n",
              " np.int64(3),\n",
              " np.int64(5),\n",
              " np.int64(2),\n",
              " np.int64(4),\n",
              " np.int64(1),\n",
              " np.int64(8),\n",
              " np.int64(1),\n",
              " np.int64(1),\n",
              " np.int64(2),\n",
              " np.int64(9),\n",
              " np.int64(7),\n",
              " np.int64(4),\n",
              " np.int64(8),\n",
              " np.int64(6),\n",
              " np.int64(5),\n",
              " np.int64(6),\n",
              " np.int64(3),\n",
              " np.int64(8),\n",
              " np.int64(5),\n",
              " np.int64(3),\n",
              " np.int64(5),\n",
              " np.int64(5),\n",
              " np.int64(2),\n",
              " np.int64(0),\n",
              " np.int64(1),\n",
              " np.int64(3),\n",
              " np.int64(0),\n",
              " np.int64(2),\n",
              " np.int64(6),\n",
              " np.int64(6),\n",
              " np.int64(9),\n",
              " np.int64(3),\n",
              " np.int64(4),\n",
              " np.int64(2),\n",
              " np.int64(1),\n",
              " np.int64(5),\n",
              " np.int64(6),\n",
              " np.int64(0),\n",
              " np.int64(4),\n",
              " np.int64(8),\n",
              " np.int64(6),\n",
              " np.int64(5),\n",
              " np.int64(8),\n",
              " np.int64(9),\n",
              " np.int64(6),\n",
              " np.int64(9),\n",
              " np.int64(5),\n",
              " np.int64(1),\n",
              " np.int64(1),\n",
              " np.int64(3),\n",
              " np.int64(7),\n",
              " np.int64(5),\n",
              " np.int64(0),\n",
              " np.int64(0),\n",
              " np.int64(5),\n",
              " np.int64(2),\n",
              " np.int64(2),\n",
              " np.int64(5),\n",
              " np.int64(8),\n",
              " np.int64(5),\n",
              " np.int64(5),\n",
              " np.int64(5),\n",
              " np.int64(8),\n",
              " np.int64(5),\n",
              " np.int64(8),\n",
              " np.int64(2),\n",
              " np.int64(1),\n",
              " np.int64(7),\n",
              " np.int64(2),\n",
              " np.int64(8),\n",
              " np.int64(4),\n",
              " np.int64(7),\n",
              " np.int64(8),\n",
              " np.int64(5),\n",
              " np.int64(1),\n",
              " np.int64(8),\n",
              " np.int64(7),\n",
              " np.int64(1),\n",
              " np.int64(3),\n",
              " np.int64(0),\n",
              " np.int64(5),\n",
              " np.int64(7),\n",
              " np.int64(9),\n",
              " np.int64(5),\n",
              " np.int64(9),\n",
              " np.int64(5),\n",
              " np.int64(9),\n",
              " np.int64(8),\n",
              " np.int64(2),\n",
              " np.int64(7),\n",
              " np.int64(9),\n",
              " np.int64(0),\n",
              " np.int64(2),\n",
              " np.int64(7),\n",
              " np.int64(5),\n",
              " np.int64(9),\n",
              " np.int64(5),\n",
              " np.int64(5),\n",
              " np.int64(9),\n",
              " np.int64(5),\n",
              " np.int64(2),\n",
              " np.int64(5),\n",
              " np.int64(5),\n",
              " np.int64(5),\n",
              " np.int64(1),\n",
              " np.int64(5),\n",
              " np.int64(8),\n",
              " np.int64(8),\n",
              " np.int64(0),\n",
              " np.int64(4),\n",
              " np.int64(7),\n",
              " np.int64(5),\n",
              " np.int64(5),\n",
              " np.int64(1),\n",
              " np.int64(1),\n",
              " np.int64(0),\n",
              " np.int64(9),\n",
              " np.int64(0),\n",
              " np.int64(3),\n",
              " np.int64(1),\n",
              " np.int64(8),\n",
              " np.int64(2),\n",
              " np.int64(2),\n",
              " np.int64(5),\n",
              " np.int64(5),\n",
              " np.int64(9),\n",
              " np.int64(9),\n",
              " np.int64(4),\n",
              " np.int64(0),\n",
              " np.int64(3),\n",
              " np.int64(0),\n",
              " np.int64(8),\n",
              " np.int64(1),\n",
              " np.int64(1),\n",
              " np.int64(1),\n",
              " np.int64(5),\n",
              " np.int64(5),\n",
              " np.int64(8),\n",
              " np.int64(8),\n",
              " np.int64(2),\n",
              " np.int64(4),\n",
              " np.int64(7),\n",
              " np.int64(2),\n",
              " np.int64(2),\n",
              " np.int64(3),\n",
              " np.int64(6),\n",
              " np.int64(3),\n",
              " np.int64(8),\n",
              " np.int64(5),\n",
              " np.int64(0),\n",
              " np.int64(5),\n",
              " np.int64(7),\n",
              " np.int64(3),\n",
              " np.int64(9),\n",
              " np.int64(0),\n",
              " np.int64(6),\n",
              " np.int64(1),\n",
              " np.int64(1),\n",
              " np.int64(9),\n",
              " np.int64(1),\n",
              " np.int64(0),\n",
              " np.int64(7),\n",
              " np.int64(9),\n",
              " np.int64(1),\n",
              " np.int64(2),\n",
              " np.int64(6),\n",
              " np.int64(1),\n",
              " np.int64(5),\n",
              " np.int64(4),\n",
              " np.int64(6),\n",
              " np.int64(2),\n",
              " np.int64(8),\n",
              " np.int64(6),\n",
              " np.int64(6),\n",
              " np.int64(6),\n",
              " np.int64(5),\n",
              " np.int64(1),\n",
              " np.int64(6),\n",
              " np.int64(8),\n",
              " np.int64(1),\n",
              " np.int64(2),\n",
              " np.int64(1),\n",
              " np.int64(4),\n",
              " np.int64(8),\n",
              " np.int64(6),\n",
              " np.int64(8),\n",
              " np.int64(2),\n",
              " np.int64(7),\n",
              " np.int64(0),\n",
              " np.int64(7),\n",
              " np.int64(7),\n",
              " np.int64(5),\n",
              " np.int64(5),\n",
              " np.int64(3),\n",
              " np.int64(3),\n",
              " np.int64(2),\n",
              " np.int64(2),\n",
              " np.int64(7),\n",
              " np.int64(1),\n",
              " np.int64(7),\n",
              " np.int64(5),\n",
              " np.int64(4),\n",
              " np.int64(6),\n",
              " np.int64(1),\n",
              " np.int64(1),\n",
              " np.int64(5),\n",
              " np.int64(6),\n",
              " np.int64(6),\n",
              " np.int64(1),\n",
              " np.int64(3),\n",
              " np.int64(8),\n",
              " np.int64(0),\n",
              " np.int64(7),\n",
              " np.int64(6),\n",
              " np.int64(6),\n",
              " np.int64(2),\n",
              " np.int64(5),\n",
              " np.int64(8),\n",
              " np.int64(5),\n",
              " np.int64(4),\n",
              " np.int64(6),\n",
              " np.int64(8),\n",
              " np.int64(1),\n",
              " np.int64(1),\n",
              " np.int64(1),\n",
              " np.int64(0),\n",
              " np.int64(2),\n",
              " np.int64(3),\n",
              " np.int64(5),\n",
              " np.int64(6),\n",
              " np.int64(2),\n",
              " np.int64(8),\n",
              " np.int64(0),\n",
              " np.int64(9),\n",
              " np.int64(5),\n",
              " np.int64(8),\n",
              " np.int64(1),\n",
              " np.int64(9),\n",
              " np.int64(4),\n",
              " np.int64(1),\n",
              " np.int64(3),\n",
              " np.int64(8),\n",
              " np.int64(1),\n",
              " np.int64(4),\n",
              " np.int64(7),\n",
              " np.int64(9),\n",
              " np.int64(4),\n",
              " np.int64(2),\n",
              " np.int64(7),\n",
              " np.int64(9),\n",
              " np.int64(7),\n",
              " np.int64(2),\n",
              " np.int64(6),\n",
              " np.int64(6),\n",
              " np.int64(1),\n",
              " np.int64(0),\n",
              " np.int64(1),\n",
              " np.int64(5),\n",
              " np.int64(0),\n",
              " np.int64(7),\n",
              " np.int64(2),\n",
              " np.int64(5),\n",
              " np.int64(7),\n",
              " np.int64(1),\n",
              " np.int64(2),\n",
              " np.int64(6),\n",
              " np.int64(2),\n",
              " np.int64(9),\n",
              " np.int64(6),\n",
              " np.int64(5),\n",
              " np.int64(7),\n",
              " np.int64(0),\n",
              " np.int64(3),\n",
              " np.int64(9),\n",
              " np.int64(8),\n",
              " np.int64(7),\n",
              " np.int64(8),\n",
              " np.int64(8),\n",
              " np.int64(4),\n",
              " np.int64(0),\n",
              " np.int64(1),\n",
              " np.int64(8),\n",
              " np.int64(5),\n",
              " np.int64(7),\n",
              " np.int64(8),\n",
              " np.int64(5),\n",
              " np.int64(6),\n",
              " np.int64(1),\n",
              " np.int64(9),\n",
              " np.int64(7),\n",
              " np.int64(7),\n",
              " np.int64(5),\n",
              " np.int64(7),\n",
              " np.int64(2),\n",
              " np.int64(5),\n",
              " np.int64(8),\n",
              " np.int64(0),\n",
              " np.int64(2),\n",
              " np.int64(9),\n",
              " np.int64(5),\n",
              " np.int64(7),\n",
              " np.int64(1),\n",
              " np.int64(6),\n",
              " np.int64(2),\n",
              " np.int64(5),\n",
              " np.int64(3),\n",
              " np.int64(7),\n",
              " np.int64(5),\n",
              " np.int64(7),\n",
              " np.int64(5),\n",
              " np.int64(5),\n",
              " np.int64(5),\n",
              " np.int64(9),\n",
              " np.int64(1),\n",
              " np.int64(2),\n",
              " np.int64(9),\n",
              " np.int64(1),\n",
              " np.int64(5),\n",
              " np.int64(7),\n",
              " np.int64(5),\n",
              " np.int64(2),\n",
              " np.int64(2),\n",
              " np.int64(2),\n",
              " np.int64(6),\n",
              " np.int64(9),\n",
              " np.int64(7),\n",
              " np.int64(5),\n",
              " np.int64(1),\n",
              " np.int64(5),\n",
              " np.int64(4),\n",
              " np.int64(5),\n",
              " np.int64(6),\n",
              " np.int64(5),\n",
              " np.int64(5),\n",
              " np.int64(5),\n",
              " np.int64(1),\n",
              " np.int64(7),\n",
              " np.int64(3),\n",
              " np.int64(4),\n",
              " np.int64(4),\n",
              " np.int64(6),\n",
              " np.int64(7),\n",
              " np.int64(8),\n",
              " np.int64(5),\n",
              " np.int64(7),\n",
              " np.int64(8),\n",
              " np.int64(8),\n",
              " np.int64(2),\n",
              " np.int64(7),\n",
              " np.int64(5),\n",
              " np.int64(8),\n",
              " np.int64(5),\n",
              " np.int64(4),\n",
              " np.int64(9),\n",
              " np.int64(6),\n",
              " np.int64(8),\n",
              " np.int64(5),\n",
              " np.int64(5),\n",
              " np.int64(9),\n",
              " np.int64(9),\n",
              " np.int64(9),\n",
              " np.int64(5),\n",
              " np.int64(0),\n",
              " np.int64(1),\n",
              " np.int64(7),\n",
              " np.int64(8),\n",
              " np.int64(1),\n",
              " np.int64(1),\n",
              " np.int64(8),\n",
              " np.int64(8),\n",
              " np.int64(2),\n",
              " np.int64(2),\n",
              " np.int64(2),\n",
              " np.int64(2),\n",
              " np.int64(6),\n",
              " np.int64(5),\n",
              " np.int64(4),\n",
              " np.int64(9),\n",
              " np.int64(4),\n",
              " np.int64(7),\n",
              " np.int64(1),\n",
              " np.int64(1),\n",
              " np.int64(2),\n",
              " np.int64(5),\n",
              " np.int64(6),\n",
              " np.int64(6),\n",
              " np.int64(1),\n",
              " np.int64(5),\n",
              " np.int64(3),\n",
              " np.int64(8),\n",
              " np.int64(1),\n",
              " np.int64(5),\n",
              " np.int64(8),\n",
              " np.int64(5),\n",
              " np.int64(7),\n",
              " np.int64(0),\n",
              " np.int64(7),\n",
              " np.int64(0),\n",
              " np.int64(5),\n",
              " np.int64(4),\n",
              " np.int64(0),\n",
              " np.int64(0),\n",
              " np.int64(6),\n",
              " np.int64(9),\n",
              " np.int64(0),\n",
              " np.int64(1),\n",
              " np.int64(5),\n",
              " np.int64(6),\n",
              " np.int64(6),\n",
              " np.int64(6),\n",
              " np.int64(2),\n",
              " np.int64(1),\n",
              " np.int64(9),\n",
              " np.int64(1),\n",
              " np.int64(7),\n",
              " np.int64(6),\n",
              " np.int64(7),\n",
              " np.int64(5),\n",
              " np.int64(9),\n",
              " np.int64(1),\n",
              " np.int64(6),\n",
              " np.int64(5),\n",
              " np.int64(5),\n",
              " np.int64(5),\n",
              " np.int64(7),\n",
              " np.int64(8),\n",
              " np.int64(5),\n",
              " np.int64(9),\n",
              " np.int64(4),\n",
              " np.int64(6),\n",
              " np.int64(4),\n",
              " np.int64(3),\n",
              " np.int64(2),\n",
              " np.int64(0),\n",
              " np.int64(7),\n",
              " np.int64(5),\n",
              " np.int64(2),\n",
              " np.int64(2),\n",
              " np.int64(5),\n",
              " np.int64(1),\n",
              " np.int64(5),\n",
              " np.int64(8),\n",
              " np.int64(6),\n",
              " np.int64(2),\n",
              " np.int64(7),\n",
              " np.int64(1),\n",
              " np.int64(3),\n",
              " np.int64(6),\n",
              " np.int64(6),\n",
              " np.int64(8),\n",
              " np.int64(9),\n",
              " np.int64(7),\n",
              " np.int64(5),\n",
              " np.int64(4),\n",
              " np.int64(0),\n",
              " np.int64(8),\n",
              " np.int64(4),\n",
              " np.int64(0),\n",
              " np.int64(1),\n",
              " np.int64(5),\n",
              " np.int64(4),\n",
              " np.int64(8),\n",
              " np.int64(9),\n",
              " np.int64(6),\n",
              " np.int64(9),\n",
              " np.int64(2),\n",
              " np.int64(6),\n",
              " np.int64(1),\n",
              " np.int64(4),\n",
              " np.int64(7),\n",
              " np.int64(5),\n",
              " np.int64(2),\n",
              " np.int64(3),\n",
              " np.int64(8),\n",
              " np.int64(5),\n",
              " np.int64(0),\n",
              " np.int64(2),\n",
              " np.int64(1),\n",
              " np.int64(6),\n",
              " np.int64(5),\n",
              " np.int64(5),\n",
              " np.int64(3),\n",
              " np.int64(9),\n",
              " np.int64(6),\n",
              " np.int64(1),\n",
              " np.int64(8),\n",
              " np.int64(8),\n",
              " np.int64(5),\n",
              " np.int64(8),\n",
              " np.int64(6),\n",
              " np.int64(6),\n",
              " np.int64(2),\n",
              " np.int64(1),\n",
              " np.int64(7),\n",
              " np.int64(1),\n",
              " np.int64(1),\n",
              " np.int64(2),\n",
              " np.int64(4),\n",
              " np.int64(9),\n",
              " np.int64(1),\n",
              " np.int64(4),\n",
              " np.int64(4),\n",
              " np.int64(1),\n",
              " np.int64(6),\n",
              " np.int64(2),\n",
              " np.int64(6),\n",
              " np.int64(0),\n",
              " np.int64(7),\n",
              " np.int64(6),\n",
              " np.int64(8),\n",
              " np.int64(5),\n",
              " np.int64(0),\n",
              " np.int64(5),\n",
              " np.int64(5),\n",
              " np.int64(6),\n",
              " np.int64(8),\n",
              " np.int64(7),\n",
              " np.int64(9),\n",
              " np.int64(1),\n",
              " np.int64(3),\n",
              " np.int64(7),\n",
              " np.int64(4),\n",
              " np.int64(7),\n",
              " np.int64(3),\n",
              " np.int64(1),\n",
              " np.int64(5),\n",
              " np.int64(6),\n",
              " np.int64(9),\n",
              " np.int64(4),\n",
              " np.int64(1),\n",
              " np.int64(1),\n",
              " np.int64(4),\n",
              " np.int64(1),\n",
              " np.int64(9),\n",
              " np.int64(7),\n",
              " np.int64(7),\n",
              " np.int64(6),\n",
              " np.int64(3),\n",
              " np.int64(2),\n",
              " np.int64(1),\n",
              " np.int64(0),\n",
              " np.int64(1),\n",
              " np.int64(2),\n",
              " np.int64(6),\n",
              " np.int64(5),\n",
              " np.int64(6),\n",
              " np.int64(3),\n",
              " np.int64(2),\n",
              " np.int64(8),\n",
              " np.int64(4),\n",
              " np.int64(1),\n",
              " np.int64(0),\n",
              " np.int64(5),\n",
              " np.int64(1),\n",
              " np.int64(6),\n",
              " np.int64(4),\n",
              " np.int64(0),\n",
              " np.int64(9),\n",
              " np.int64(2),\n",
              " np.int64(9),\n",
              " np.int64(2),\n",
              " np.int64(3),\n",
              " np.int64(3),\n",
              " np.int64(3),\n",
              " np.int64(2),\n",
              " np.int64(2),\n",
              " np.int64(7),\n",
              " np.int64(8),\n",
              " np.int64(3),\n",
              " np.int64(8),\n",
              " np.int64(2),\n",
              " np.int64(7),\n",
              " np.int64(5),\n",
              " np.int64(7),\n",
              " np.int64(2),\n",
              " np.int64(4),\n",
              " np.int64(8),\n",
              " np.int64(7),\n",
              " np.int64(6),\n",
              " np.int64(0),\n",
              " np.int64(9),\n",
              " np.int64(0),\n",
              " np.int64(8),\n",
              " np.int64(6),\n",
              " np.int64(8),\n",
              " np.int64(8),\n",
              " np.int64(7),\n",
              " np.int64(4),\n",
              " np.int64(5),\n",
              " np.int64(3),\n",
              " np.int64(8),\n",
              " np.int64(2),\n",
              " np.int64(9),\n",
              " np.int64(4),\n",
              " np.int64(8),\n",
              " np.int64(8),\n",
              " np.int64(1),\n",
              " np.int64(8),\n",
              " np.int64(2),\n",
              " np.int64(1),\n",
              " np.int64(5),\n",
              " np.int64(6),\n",
              " np.int64(2),\n",
              " np.int64(4),\n",
              " np.int64(0),\n",
              " np.int64(7),\n",
              " np.int64(9),\n",
              " np.int64(1),\n",
              " np.int64(6),\n",
              " np.int64(1),\n",
              " np.int64(4),\n",
              " np.int64(1),\n",
              " np.int64(5),\n",
              " np.int64(5),\n",
              " np.int64(7),\n",
              " np.int64(0),\n",
              " np.int64(7),\n",
              " np.int64(9),\n",
              " np.int64(7),\n",
              " np.int64(5),\n",
              " np.int64(6),\n",
              " np.int64(2),\n",
              " np.int64(3),\n",
              " np.int64(1),\n",
              " np.int64(2),\n",
              " np.int64(9),\n",
              " np.int64(1),\n",
              " np.int64(2),\n",
              " np.int64(5),\n",
              " np.int64(6),\n",
              " np.int64(8),\n",
              " np.int64(2),\n",
              " np.int64(1),\n",
              " np.int64(4),\n",
              " np.int64(5),\n",
              " np.int64(5),\n",
              " np.int64(7),\n",
              " np.int64(1),\n",
              " np.int64(2),\n",
              " np.int64(4),\n",
              " np.int64(1),\n",
              " np.int64(5),\n",
              " np.int64(2),\n",
              " np.int64(5),\n",
              " np.int64(1),\n",
              " np.int64(6),\n",
              " np.int64(6),\n",
              " np.int64(2),\n",
              " np.int64(2),\n",
              " np.int64(7),\n",
              " np.int64(6),\n",
              " np.int64(0),\n",
              " np.int64(5),\n",
              " np.int64(9),\n",
              " np.int64(0),\n",
              " np.int64(5),\n",
              " np.int64(6),\n",
              " np.int64(4),\n",
              " np.int64(0),\n",
              " np.int64(3),\n",
              " np.int64(1),\n",
              " np.int64(5),\n",
              " np.int64(8),\n",
              " np.int64(3),\n",
              " np.int64(0),\n",
              " np.int64(5),\n",
              " np.int64(5),\n",
              " np.int64(7),\n",
              " np.int64(7),\n",
              " np.int64(9),\n",
              " np.int64(5),\n",
              " np.int64(2),\n",
              " np.int64(4),\n",
              " np.int64(7),\n",
              " np.int64(1),\n",
              " np.int64(2),\n",
              " np.int64(7),\n",
              " np.int64(4),\n",
              " np.int64(4),\n",
              " np.int64(8),\n",
              " np.int64(4),\n",
              " np.int64(2),\n",
              " np.int64(5),\n",
              " np.int64(5),\n",
              " np.int64(5),\n",
              " np.int64(7),\n",
              " np.int64(2),\n",
              " np.int64(8),\n",
              " np.int64(8),\n",
              " np.int64(1),\n",
              " np.int64(5),\n",
              " np.int64(8),\n",
              " np.int64(5),\n",
              " np.int64(2),\n",
              " np.int64(2),\n",
              " np.int64(0),\n",
              " np.int64(8),\n",
              " np.int64(7),\n",
              " np.int64(5),\n",
              " np.int64(7),\n",
              " np.int64(6),\n",
              " np.int64(5),\n",
              " np.int64(4),\n",
              " np.int64(1),\n",
              " np.int64(3),\n",
              " np.int64(2),\n",
              " np.int64(5),\n",
              " np.int64(5),\n",
              " np.int64(5),\n",
              " np.int64(1),\n",
              " np.int64(2),\n",
              " np.int64(1),\n",
              " np.int64(2),\n",
              " np.int64(7),\n",
              " np.int64(0),\n",
              " np.int64(7),\n",
              " np.int64(2),\n",
              " np.int64(1),\n",
              " np.int64(5),\n",
              " np.int64(2),\n",
              " np.int64(0),\n",
              " np.int64(2),\n",
              " np.int64(4),\n",
              " np.int64(3),\n",
              " np.int64(9),\n",
              " np.int64(8),\n",
              " np.int64(1),\n",
              " np.int64(0),\n",
              " np.int64(7),\n",
              " np.int64(7),\n",
              " np.int64(2),\n",
              " np.int64(7),\n",
              " np.int64(8),\n",
              " np.int64(4),\n",
              " np.int64(6),\n",
              " np.int64(6),\n",
              " np.int64(5),\n",
              " np.int64(0),\n",
              " np.int64(1),\n",
              " np.int64(5),\n",
              " np.int64(7),\n",
              " np.int64(0),\n",
              " np.int64(1),\n",
              " np.int64(3),\n",
              " np.int64(1),\n",
              " np.int64(5),\n",
              " np.int64(2),\n",
              " np.int64(3),\n",
              " np.int64(8),\n",
              " np.int64(4),\n",
              " np.int64(2),\n",
              " np.int64(4),\n",
              " np.int64(7),\n",
              " np.int64(8),\n",
              " np.int64(4),\n",
              " np.int64(2),\n",
              " np.int64(0),\n",
              " np.int64(9),\n",
              " np.int64(8),\n",
              " np.int64(8),\n",
              " np.int64(1),\n",
              " np.int64(1),\n",
              " np.int64(4),\n",
              " np.int64(5),\n",
              " np.int64(6),\n",
              " np.int64(5),\n",
              " np.int64(7),\n",
              " np.int64(1),\n",
              " np.int64(1),\n",
              " np.int64(5),\n",
              " np.int64(7),\n",
              " np.int64(7),\n",
              " np.int64(5),\n",
              " np.int64(5),\n",
              " np.int64(6),\n",
              " np.int64(6),\n",
              " np.int64(5),\n",
              " np.int64(8),\n",
              " np.int64(7),\n",
              " np.int64(1),\n",
              " np.int64(6),\n",
              " np.int64(8),\n",
              " np.int64(8),\n",
              " np.int64(5),\n",
              " np.int64(3),\n",
              " np.int64(5),\n",
              " np.int64(4),\n",
              " np.int64(0),\n",
              " np.int64(1),\n",
              " np.int64(4),\n",
              " np.int64(8),\n",
              " np.int64(8),\n",
              " np.int64(2),\n",
              " np.int64(6),\n",
              " np.int64(9),\n",
              " np.int64(1),\n",
              " np.int64(5),\n",
              " np.int64(5),\n",
              " np.int64(5),\n",
              " np.int64(8),\n",
              " np.int64(6),\n",
              " np.int64(0),\n",
              " np.int64(0),\n",
              " np.int64(4),\n",
              " np.int64(2),\n",
              " np.int64(5),\n",
              " np.int64(5),\n",
              " np.int64(7),\n",
              " np.int64(2),\n",
              " np.int64(2),\n",
              " np.int64(5),\n",
              " np.int64(1),\n",
              " np.int64(8),\n",
              " np.int64(1),\n",
              " np.int64(1),\n",
              " np.int64(7),\n",
              " np.int64(6),\n",
              " np.int64(0),\n",
              " np.int64(5),\n",
              " np.int64(0),\n",
              " np.int64(1),\n",
              " np.int64(5),\n",
              " np.int64(8),\n",
              " np.int64(3),\n",
              " np.int64(9),\n",
              " np.int64(6),\n",
              " np.int64(1),\n",
              " np.int64(5),\n",
              " np.int64(7),\n",
              " np.int64(0),\n",
              " np.int64(3),\n",
              " np.int64(7),\n",
              " np.int64(8),\n",
              " np.int64(9),\n",
              " np.int64(1),\n",
              " np.int64(1),\n",
              " np.int64(6),\n",
              " np.int64(6),\n",
              " np.int64(5),\n",
              " np.int64(5),\n",
              " np.int64(9),\n",
              " np.int64(1),\n",
              " np.int64(1),\n",
              " np.int64(1),\n",
              " np.int64(5),\n",
              " np.int64(2),\n",
              " np.int64(1),\n",
              " np.int64(2),\n",
              " np.int64(0),\n",
              " np.int64(5),\n",
              " np.int64(8),\n",
              " np.int64(1),\n",
              " np.int64(9),\n",
              " np.int64(2),\n",
              " np.int64(5),\n",
              " np.int64(5),\n",
              " np.int64(4),\n",
              " np.int64(7),\n",
              " np.int64(8),\n",
              " np.int64(5),\n",
              " np.int64(1),\n",
              " np.int64(2),\n",
              " np.int64(0),\n",
              " np.int64(1),\n",
              " np.int64(5),\n",
              " np.int64(8),\n",
              " np.int64(7),\n",
              " np.int64(6),\n",
              " np.int64(5),\n",
              " np.int64(8),\n",
              " np.int64(1),\n",
              " np.int64(3),\n",
              " np.int64(8),\n",
              " ...]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYbuTthVuCDo"
      },
      "source": [
        "## Test the models and the ensemble of the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOYyF657_kOY",
        "outputId": "b4a11b84-d51d-4ac1-814d-baf0c83f3f32"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[np.int64(3),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(6),\n",
              "  np.int64(6),\n",
              "  np.int64(1),\n",
              "  np.int64(2),\n",
              "  np.int64(3),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(9),\n",
              "  np.int64(5),\n",
              "  np.int64(7),\n",
              "  np.int64(9),\n",
              "  np.int64(8),\n",
              "  np.int64(5),\n",
              "  np.int64(7),\n",
              "  np.int64(8),\n",
              "  np.int64(6),\n",
              "  np.int64(7),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(9),\n",
              "  np.int64(4),\n",
              "  np.int64(2),\n",
              "  np.int64(3),\n",
              "  np.int64(0),\n",
              "  np.int64(9),\n",
              "  np.int64(6),\n",
              "  np.int64(6),\n",
              "  np.int64(5),\n",
              "  np.int64(2),\n",
              "  np.int64(3),\n",
              "  np.int64(9),\n",
              "  np.int64(3),\n",
              "  np.int64(7),\n",
              "  np.int64(1),\n",
              "  np.int64(9),\n",
              "  np.int64(5),\n",
              "  np.int64(0),\n",
              "  np.int64(6),\n",
              "  np.int64(5),\n",
              "  np.int64(6),\n",
              "  np.int64(0),\n",
              "  np.int64(9),\n",
              "  np.int64(3),\n",
              "  np.int64(9),\n",
              "  np.int64(7),\n",
              "  np.int64(2),\n",
              "  np.int64(9),\n",
              "  np.int64(8),\n",
              "  np.int64(7),\n",
              "  np.int64(3),\n",
              "  np.int64(8),\n",
              "  np.int64(8),\n",
              "  np.int64(5),\n",
              "  np.int64(3),\n",
              "  np.int64(3),\n",
              "  np.int64(2),\n",
              "  np.int64(7),\n",
              "  np.int64(5),\n",
              "  np.int64(6),\n",
              "  np.int64(9),\n",
              "  np.int64(6),\n",
              "  np.int64(7),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(5),\n",
              "  np.int64(9),\n",
              "  np.int64(2),\n",
              "  np.int64(3),\n",
              "  np.int64(8),\n",
              "  np.int64(8),\n",
              "  np.int64(1),\n",
              "  np.int64(2),\n",
              "  np.int64(0),\n",
              "  np.int64(3),\n",
              "  np.int64(5),\n",
              "  np.int64(8),\n",
              "  np.int64(8),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(7),\n",
              "  np.int64(2),\n",
              "  np.int64(5),\n",
              "  np.int64(0),\n",
              "  np.int64(7),\n",
              "  np.int64(8),\n",
              "  np.int64(9),\n",
              "  np.int64(8),\n",
              "  np.int64(2),\n",
              "  np.int64(8),\n",
              "  np.int64(6),\n",
              "  np.int64(4),\n",
              "  np.int64(3),\n",
              "  np.int64(6),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(7),\n",
              "  np.int64(7),\n",
              "  np.int64(5),\n",
              "  np.int64(3),\n",
              "  np.int64(3),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(2),\n",
              "  np.int64(6),\n",
              "  np.int64(8),\n",
              "  np.int64(7),\n",
              "  np.int64(5),\n",
              "  np.int64(0),\n",
              "  np.int64(2),\n",
              "  np.int64(2),\n",
              "  np.int64(1),\n",
              "  np.int64(3),\n",
              "  np.int64(0),\n",
              "  np.int64(4),\n",
              "  np.int64(2),\n",
              "  np.int64(7),\n",
              "  np.int64(8),\n",
              "  np.int64(5),\n",
              "  np.int64(1),\n",
              "  np.int64(2),\n",
              "  np.int64(8),\n",
              "  np.int64(0),\n",
              "  np.int64(8),\n",
              "  np.int64(3),\n",
              "  np.int64(5),\n",
              "  np.int64(2),\n",
              "  np.int64(4),\n",
              "  np.int64(1),\n",
              "  np.int64(8),\n",
              "  np.int64(9),\n",
              "  np.int64(1),\n",
              "  np.int64(2),\n",
              "  np.int64(9),\n",
              "  np.int64(7),\n",
              "  np.int64(2),\n",
              "  np.int64(9),\n",
              "  np.int64(6),\n",
              "  np.int64(5),\n",
              "  np.int64(6),\n",
              "  np.int64(7),\n",
              "  np.int64(8),\n",
              "  np.int64(5),\n",
              "  np.int64(6),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(2),\n",
              "  np.int64(8),\n",
              "  np.int64(9),\n",
              "  np.int64(1),\n",
              "  np.int64(5),\n",
              "  np.int64(0),\n",
              "  np.int64(5),\n",
              "  np.int64(2),\n",
              "  np.int64(9),\n",
              "  np.int64(3),\n",
              "  np.int64(4),\n",
              "  np.int64(2),\n",
              "  np.int64(1),\n",
              "  np.int64(2),\n",
              "  np.int64(6),\n",
              "  np.int64(0),\n",
              "  np.int64(7),\n",
              "  np.int64(8),\n",
              "  np.int64(6),\n",
              "  np.int64(9),\n",
              "  np.int64(0),\n",
              "  np.int64(9),\n",
              "  np.int64(7),\n",
              "  np.int64(9),\n",
              "  np.int64(8),\n",
              "  np.int64(1),\n",
              "  np.int64(9),\n",
              "  np.int64(3),\n",
              "  np.int64(7),\n",
              "  np.int64(2),\n",
              "  np.int64(9),\n",
              "  np.int64(0),\n",
              "  np.int64(5),\n",
              "  np.int64(2),\n",
              "  np.int64(2),\n",
              "  np.int64(5),\n",
              "  np.int64(8),\n",
              "  np.int64(6),\n",
              "  np.int64(3),\n",
              "  np.int64(7),\n",
              "  np.int64(0),\n",
              "  np.int64(5),\n",
              "  np.int64(8),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(5),\n",
              "  np.int64(2),\n",
              "  np.int64(8),\n",
              "  np.int64(8),\n",
              "  np.int64(7),\n",
              "  np.int64(8),\n",
              "  np.int64(5),\n",
              "  np.int64(1),\n",
              "  np.int64(8),\n",
              "  np.int64(7),\n",
              "  np.int64(1),\n",
              "  np.int64(3),\n",
              "  np.int64(8),\n",
              "  np.int64(5),\n",
              "  np.int64(7),\n",
              "  np.int64(9),\n",
              "  np.int64(5),\n",
              "  np.int64(9),\n",
              "  np.int64(5),\n",
              "  np.int64(9),\n",
              "  np.int64(1),\n",
              "  np.int64(7),\n",
              "  np.int64(7),\n",
              "  np.int64(9),\n",
              "  np.int64(8),\n",
              "  np.int64(7),\n",
              "  np.int64(7),\n",
              "  np.int64(5),\n",
              "  np.int64(9),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(9),\n",
              "  np.int64(7),\n",
              "  np.int64(4),\n",
              "  np.int64(3),\n",
              "  np.int64(7),\n",
              "  np.int64(5),\n",
              "  np.int64(1),\n",
              "  np.int64(5),\n",
              "  np.int64(8),\n",
              "  np.int64(8),\n",
              "  np.int64(0),\n",
              "  np.int64(4),\n",
              "  np.int64(9),\n",
              "  np.int64(3),\n",
              "  np.int64(3),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(8),\n",
              "  np.int64(9),\n",
              "  np.int64(0),\n",
              "  np.int64(3),\n",
              "  np.int64(1),\n",
              "  np.int64(8),\n",
              "  np.int64(2),\n",
              "  np.int64(0),\n",
              "  np.int64(5),\n",
              "  np.int64(3),\n",
              "  np.int64(9),\n",
              "  np.int64(9),\n",
              "  np.int64(7),\n",
              "  np.int64(0),\n",
              "  np.int64(3),\n",
              "  np.int64(0),\n",
              "  np.int64(8),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(3),\n",
              "  np.int64(3),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(2),\n",
              "  np.int64(4),\n",
              "  np.int64(7),\n",
              "  np.int64(2),\n",
              "  np.int64(5),\n",
              "  np.int64(3),\n",
              "  np.int64(6),\n",
              "  np.int64(3),\n",
              "  np.int64(8),\n",
              "  np.int64(7),\n",
              "  np.int64(8),\n",
              "  np.int64(9),\n",
              "  np.int64(7),\n",
              "  np.int64(3),\n",
              "  np.int64(9),\n",
              "  np.int64(1),\n",
              "  np.int64(6),\n",
              "  np.int64(1),\n",
              "  np.int64(9),\n",
              "  np.int64(9),\n",
              "  np.int64(8),\n",
              "  np.int64(8),\n",
              "  np.int64(7),\n",
              "  np.int64(9),\n",
              "  np.int64(1),\n",
              "  np.int64(2),\n",
              "  np.int64(6),\n",
              "  np.int64(1),\n",
              "  np.int64(3),\n",
              "  np.int64(2),\n",
              "  np.int64(6),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(3),\n",
              "  np.int64(6),\n",
              "  np.int64(6),\n",
              "  np.int64(3),\n",
              "  np.int64(3),\n",
              "  np.int64(6),\n",
              "  np.int64(9),\n",
              "  np.int64(9),\n",
              "  np.int64(2),\n",
              "  np.int64(1),\n",
              "  np.int64(2),\n",
              "  np.int64(8),\n",
              "  np.int64(6),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(5),\n",
              "  np.int64(0),\n",
              "  np.int64(7),\n",
              "  np.int64(7),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(3),\n",
              "  np.int64(3),\n",
              "  np.int64(2),\n",
              "  np.int64(4),\n",
              "  np.int64(7),\n",
              "  np.int64(1),\n",
              "  np.int64(7),\n",
              "  np.int64(5),\n",
              "  np.int64(4),\n",
              "  np.int64(6),\n",
              "  np.int64(1),\n",
              "  np.int64(9),\n",
              "  np.int64(5),\n",
              "  np.int64(6),\n",
              "  np.int64(6),\n",
              "  np.int64(1),\n",
              "  np.int64(3),\n",
              "  np.int64(8),\n",
              "  np.int64(0),\n",
              "  np.int64(7),\n",
              "  np.int64(6),\n",
              "  np.int64(6),\n",
              "  np.int64(2),\n",
              "  np.int64(5),\n",
              "  np.int64(8),\n",
              "  np.int64(5),\n",
              "  np.int64(2),\n",
              "  np.int64(6),\n",
              "  np.int64(8),\n",
              "  np.int64(1),\n",
              "  np.int64(9),\n",
              "  np.int64(1),\n",
              "  np.int64(8),\n",
              "  np.int64(2),\n",
              "  np.int64(6),\n",
              "  np.int64(7),\n",
              "  np.int64(5),\n",
              "  np.int64(2),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(9),\n",
              "  np.int64(5),\n",
              "  np.int64(8),\n",
              "  np.int64(1),\n",
              "  np.int64(9),\n",
              "  np.int64(7),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(2),\n",
              "  np.int64(7),\n",
              "  np.int64(9),\n",
              "  np.int64(4),\n",
              "  np.int64(2),\n",
              "  np.int64(7),\n",
              "  np.int64(9),\n",
              "  np.int64(2),\n",
              "  np.int64(2),\n",
              "  np.int64(6),\n",
              "  np.int64(6),\n",
              "  np.int64(9),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(5),\n",
              "  np.int64(0),\n",
              "  np.int64(7),\n",
              "  np.int64(2),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(6),\n",
              "  np.int64(2),\n",
              "  np.int64(9),\n",
              "  np.int64(6),\n",
              "  np.int64(2),\n",
              "  np.int64(3),\n",
              "  np.int64(9),\n",
              "  np.int64(1),\n",
              "  np.int64(9),\n",
              "  np.int64(8),\n",
              "  np.int64(7),\n",
              "  np.int64(8),\n",
              "  np.int64(8),\n",
              "  np.int64(6),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(8),\n",
              "  np.int64(5),\n",
              "  np.int64(7),\n",
              "  np.int64(8),\n",
              "  np.int64(5),\n",
              "  np.int64(6),\n",
              "  np.int64(1),\n",
              "  np.int64(9),\n",
              "  np.int64(0),\n",
              "  np.int64(7),\n",
              "  np.int64(5),\n",
              "  np.int64(7),\n",
              "  np.int64(4),\n",
              "  np.int64(5),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(2),\n",
              "  np.int64(9),\n",
              "  np.int64(3),\n",
              "  np.int64(7),\n",
              "  np.int64(1),\n",
              "  np.int64(6),\n",
              "  np.int64(4),\n",
              "  np.int64(3),\n",
              "  np.int64(3),\n",
              "  np.int64(7),\n",
              "  np.int64(3),\n",
              "  np.int64(7),\n",
              "  np.int64(3),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(9),\n",
              "  np.int64(9),\n",
              "  np.int64(4),\n",
              "  np.int64(9),\n",
              "  np.int64(9),\n",
              "  np.int64(3),\n",
              "  np.int64(7),\n",
              "  np.int64(5),\n",
              "  np.int64(0),\n",
              "  np.int64(2),\n",
              "  np.int64(0),\n",
              "  np.int64(2),\n",
              "  np.int64(9),\n",
              "  np.int64(7),\n",
              "  np.int64(3),\n",
              "  np.int64(9),\n",
              "  np.int64(2),\n",
              "  np.int64(4),\n",
              "  np.int64(5),\n",
              "  np.int64(2),\n",
              "  np.int64(7),\n",
              "  np.int64(5),\n",
              "  np.int64(3),\n",
              "  np.int64(1),\n",
              "  np.int64(7),\n",
              "  np.int64(5),\n",
              "  np.int64(4),\n",
              "  np.int64(7),\n",
              "  np.int64(3),\n",
              "  np.int64(7),\n",
              "  np.int64(8),\n",
              "  np.int64(3),\n",
              "  np.int64(7),\n",
              "  np.int64(8),\n",
              "  np.int64(0),\n",
              "  np.int64(7),\n",
              "  np.int64(7),\n",
              "  np.int64(2),\n",
              "  np.int64(8),\n",
              "  np.int64(5),\n",
              "  np.int64(7),\n",
              "  np.int64(9),\n",
              "  np.int64(6),\n",
              "  np.int64(8),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(0),\n",
              "  np.int64(9),\n",
              "  np.int64(9),\n",
              "  np.int64(3),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(2),\n",
              "  np.int64(8),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(8),\n",
              "  np.int64(0),\n",
              "  np.int64(5),\n",
              "  np.int64(2),\n",
              "  np.int64(0),\n",
              "  np.int64(4),\n",
              "  np.int64(6),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(9),\n",
              "  np.int64(4),\n",
              "  np.int64(7),\n",
              "  np.int64(9),\n",
              "  np.int64(1),\n",
              "  np.int64(4),\n",
              "  np.int64(5),\n",
              "  np.int64(6),\n",
              "  np.int64(6),\n",
              "  np.int64(1),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(8),\n",
              "  np.int64(9),\n",
              "  np.int64(7),\n",
              "  np.int64(8),\n",
              "  np.int64(5),\n",
              "  np.int64(7),\n",
              "  np.int64(0),\n",
              "  np.int64(7),\n",
              "  np.int64(0),\n",
              "  np.int64(3),\n",
              "  np.int64(8),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(6),\n",
              "  np.int64(9),\n",
              "  np.int64(3),\n",
              "  np.int64(9),\n",
              "  np.int64(5),\n",
              "  np.int64(6),\n",
              "  np.int64(2),\n",
              "  np.int64(6),\n",
              "  np.int64(2),\n",
              "  np.int64(8),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(3),\n",
              "  np.int64(6),\n",
              "  np.int64(7),\n",
              "  np.int64(5),\n",
              "  np.int64(9),\n",
              "  np.int64(1),\n",
              "  np.int64(6),\n",
              "  np.int64(2),\n",
              "  np.int64(5),\n",
              "  np.int64(2),\n",
              "  np.int64(3),\n",
              "  np.int64(8),\n",
              "  np.int64(5),\n",
              "  np.int64(9),\n",
              "  np.int64(4),\n",
              "  np.int64(6),\n",
              "  np.int64(3),\n",
              "  np.int64(3),\n",
              "  np.int64(2),\n",
              "  np.int64(0),\n",
              "  np.int64(7),\n",
              "  np.int64(6),\n",
              "  np.int64(4),\n",
              "  np.int64(4),\n",
              "  np.int64(3),\n",
              "  np.int64(9),\n",
              "  np.int64(3),\n",
              "  np.int64(9),\n",
              "  np.int64(0),\n",
              "  np.int64(2),\n",
              "  np.int64(7),\n",
              "  np.int64(1),\n",
              "  np.int64(3),\n",
              "  np.int64(3),\n",
              "  np.int64(3),\n",
              "  np.int64(8),\n",
              "  np.int64(1),\n",
              "  np.int64(7),\n",
              "  np.int64(5),\n",
              "  np.int64(2),\n",
              "  np.int64(0),\n",
              "  np.int64(8),\n",
              "  np.int64(7),\n",
              "  np.int64(0),\n",
              "  np.int64(9),\n",
              "  np.int64(3),\n",
              "  np.int64(4),\n",
              "  np.int64(8),\n",
              "  np.int64(9),\n",
              "  np.int64(6),\n",
              "  np.int64(9),\n",
              "  np.int64(2),\n",
              "  np.int64(6),\n",
              "  np.int64(9),\n",
              "  np.int64(4),\n",
              "  np.int64(7),\n",
              "  np.int64(5),\n",
              "  np.int64(2),\n",
              "  np.int64(3),\n",
              "  np.int64(8),\n",
              "  np.int64(5),\n",
              "  np.int64(0),\n",
              "  np.int64(2),\n",
              "  np.int64(1),\n",
              "  np.int64(6),\n",
              "  np.int64(4),\n",
              "  np.int64(5),\n",
              "  np.int64(3),\n",
              "  np.int64(9),\n",
              "  np.int64(6),\n",
              "  np.int64(9),\n",
              "  np.int64(8),\n",
              "  np.int64(8),\n",
              "  np.int64(5),\n",
              "  np.int64(9),\n",
              "  np.int64(6),\n",
              "  np.int64(6),\n",
              "  np.int64(2),\n",
              "  np.int64(1),\n",
              "  np.int64(7),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(2),\n",
              "  np.int64(7),\n",
              "  np.int64(9),\n",
              "  np.int64(1),\n",
              "  np.int64(4),\n",
              "  np.int64(4),\n",
              "  np.int64(1),\n",
              "  np.int64(8),\n",
              "  np.int64(2),\n",
              "  np.int64(6),\n",
              "  np.int64(8),\n",
              "  np.int64(7),\n",
              "  np.int64(6),\n",
              "  np.int64(8),\n",
              "  np.int64(8),\n",
              "  np.int64(0),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(3),\n",
              "  np.int64(0),\n",
              "  np.int64(7),\n",
              "  np.int64(9),\n",
              "  np.int64(9),\n",
              "  np.int64(3),\n",
              "  np.int64(4),\n",
              "  np.int64(7),\n",
              "  np.int64(7),\n",
              "  np.int64(3),\n",
              "  np.int64(9),\n",
              "  np.int64(3),\n",
              "  np.int64(6),\n",
              "  np.int64(9),\n",
              "  np.int64(2),\n",
              "  np.int64(1),\n",
              "  np.int64(5),\n",
              "  np.int64(4),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(7),\n",
              "  np.int64(7),\n",
              "  np.int64(6),\n",
              "  np.int64(3),\n",
              "  np.int64(0),\n",
              "  np.int64(9),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(2),\n",
              "  np.int64(6),\n",
              "  np.int64(5),\n",
              "  np.int64(2),\n",
              "  np.int64(3),\n",
              "  np.int64(2),\n",
              "  np.int64(8),\n",
              "  np.int64(3),\n",
              "  np.int64(9),\n",
              "  np.int64(0),\n",
              "  np.int64(5),\n",
              "  np.int64(9),\n",
              "  np.int64(6),\n",
              "  np.int64(7),\n",
              "  np.int64(0),\n",
              "  np.int64(9),\n",
              "  np.int64(2),\n",
              "  np.int64(9),\n",
              "  np.int64(7),\n",
              "  np.int64(3),\n",
              "  np.int64(0),\n",
              "  np.int64(3),\n",
              "  np.int64(2),\n",
              "  np.int64(2),\n",
              "  np.int64(7),\n",
              "  np.int64(8),\n",
              "  np.int64(3),\n",
              "  np.int64(8),\n",
              "  np.int64(2),\n",
              "  np.int64(7),\n",
              "  np.int64(5),\n",
              "  np.int64(7),\n",
              "  np.int64(0),\n",
              "  np.int64(4),\n",
              "  np.int64(8),\n",
              "  np.int64(7),\n",
              "  np.int64(2),\n",
              "  np.int64(0),\n",
              "  np.int64(9),\n",
              "  np.int64(8),\n",
              "  np.int64(8),\n",
              "  np.int64(7),\n",
              "  np.int64(0),\n",
              "  np.int64(8),\n",
              "  np.int64(7),\n",
              "  np.int64(4),\n",
              "  np.int64(2),\n",
              "  np.int64(3),\n",
              "  np.int64(8),\n",
              "  np.int64(2),\n",
              "  np.int64(9),\n",
              "  np.int64(7),\n",
              "  np.int64(8),\n",
              "  np.int64(8),\n",
              "  np.int64(1),\n",
              "  np.int64(8),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(3),\n",
              "  np.int64(6),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(0),\n",
              "  np.int64(7),\n",
              "  np.int64(9),\n",
              "  np.int64(1),\n",
              "  np.int64(4),\n",
              "  np.int64(9),\n",
              "  np.int64(4),\n",
              "  np.int64(1),\n",
              "  np.int64(7),\n",
              "  np.int64(5),\n",
              "  np.int64(7),\n",
              "  np.int64(0),\n",
              "  np.int64(7),\n",
              "  np.int64(9),\n",
              "  np.int64(7),\n",
              "  np.int64(5),\n",
              "  np.int64(6),\n",
              "  np.int64(2),\n",
              "  np.int64(3),\n",
              "  np.int64(9),\n",
              "  np.int64(0),\n",
              "  np.int64(9),\n",
              "  np.int64(1),\n",
              "  np.int64(2),\n",
              "  np.int64(2),\n",
              "  np.int64(6),\n",
              "  np.int64(8),\n",
              "  np.int64(2),\n",
              "  np.int64(1),\n",
              "  np.int64(3),\n",
              "  np.int64(2),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(2),\n",
              "  np.int64(7),\n",
              "  np.int64(9),\n",
              "  np.int64(5),\n",
              "  np.int64(2),\n",
              "  np.int64(5),\n",
              "  np.int64(9),\n",
              "  np.int64(6),\n",
              "  np.int64(6),\n",
              "  np.int64(0),\n",
              "  np.int64(7),\n",
              "  np.int64(7),\n",
              "  np.int64(6),\n",
              "  np.int64(0),\n",
              "  np.int64(6),\n",
              "  np.int64(9),\n",
              "  np.int64(1),\n",
              "  np.int64(7),\n",
              "  np.int64(6),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(3),\n",
              "  np.int64(0),\n",
              "  np.int64(2),\n",
              "  np.int64(8),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(5),\n",
              "  np.int64(7),\n",
              "  np.int64(7),\n",
              "  np.int64(4),\n",
              "  np.int64(4),\n",
              "  np.int64(7),\n",
              "  np.int64(6),\n",
              "  np.int64(7),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(7),\n",
              "  np.int64(4),\n",
              "  np.int64(4),\n",
              "  np.int64(8),\n",
              "  np.int64(2),\n",
              "  np.int64(7),\n",
              "  np.int64(0),\n",
              "  np.int64(2),\n",
              "  np.int64(2),\n",
              "  np.int64(7),\n",
              "  np.int64(2),\n",
              "  np.int64(1),\n",
              "  np.int64(8),\n",
              "  np.int64(9),\n",
              "  np.int64(5),\n",
              "  np.int64(9),\n",
              "  np.int64(2),\n",
              "  np.int64(9),\n",
              "  np.int64(2),\n",
              "  np.int64(1),\n",
              "  np.int64(8),\n",
              "  np.int64(7),\n",
              "  np.int64(3),\n",
              "  np.int64(7),\n",
              "  np.int64(6),\n",
              "  np.int64(5),\n",
              "  np.int64(3),\n",
              "  np.int64(1),\n",
              "  np.int64(3),\n",
              "  np.int64(2),\n",
              "  np.int64(5),\n",
              "  np.int64(4),\n",
              "  np.int64(5),\n",
              "  np.int64(0),\n",
              "  np.int64(2),\n",
              "  np.int64(9),\n",
              "  np.int64(2),\n",
              "  np.int64(7),\n",
              "  np.int64(0),\n",
              "  np.int64(7),\n",
              "  np.int64(2),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(2),\n",
              "  np.int64(0),\n",
              "  np.int64(2),\n",
              "  np.int64(4),\n",
              "  np.int64(5),\n",
              "  np.int64(9),\n",
              "  np.int64(8),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(7),\n",
              "  np.int64(7),\n",
              "  np.int64(0),\n",
              "  np.int64(7),\n",
              "  np.int64(8),\n",
              "  np.int64(4),\n",
              "  np.int64(6),\n",
              "  np.int64(6),\n",
              "  np.int64(5),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(7),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(2),\n",
              "  np.int64(1),\n",
              "  np.int64(5),\n",
              "  np.int64(2),\n",
              "  np.int64(3),\n",
              "  np.int64(8),\n",
              "  np.int64(4),\n",
              "  np.int64(2),\n",
              "  np.int64(2),\n",
              "  np.int64(7),\n",
              "  np.int64(8),\n",
              "  np.int64(3),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(9),\n",
              "  np.int64(0),\n",
              "  np.int64(8),\n",
              "  np.int64(1),\n",
              "  np.int64(8),\n",
              "  np.int64(6),\n",
              "  np.int64(3),\n",
              "  np.int64(6),\n",
              "  np.int64(5),\n",
              "  np.int64(7),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(3),\n",
              "  np.int64(7),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(2),\n",
              "  np.int64(6),\n",
              "  np.int64(6),\n",
              "  np.int64(3),\n",
              "  np.int64(0),\n",
              "  np.int64(7),\n",
              "  np.int64(1),\n",
              "  np.int64(3),\n",
              "  np.int64(8),\n",
              "  np.int64(8),\n",
              "  np.int64(5),\n",
              "  np.int64(3),\n",
              "  np.int64(0),\n",
              "  np.int64(4),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(4),\n",
              "  np.int64(8),\n",
              "  np.int64(8),\n",
              "  np.int64(0),\n",
              "  np.int64(6),\n",
              "  np.int64(9),\n",
              "  np.int64(9),\n",
              "  np.int64(3),\n",
              "  np.int64(0),\n",
              "  np.int64(3),\n",
              "  np.int64(8),\n",
              "  np.int64(5),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(4),\n",
              "  np.int64(2),\n",
              "  np.int64(5),\n",
              "  np.int64(3),\n",
              "  np.int64(7),\n",
              "  np.int64(2),\n",
              "  np.int64(4),\n",
              "  np.int64(5),\n",
              "  np.int64(1),\n",
              "  np.int64(8),\n",
              "  np.int64(9),\n",
              "  np.int64(9),\n",
              "  np.int64(7),\n",
              "  np.int64(2),\n",
              "  np.int64(0),\n",
              "  np.int64(5),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(3),\n",
              "  np.int64(8),\n",
              "  np.int64(7),\n",
              "  np.int64(9),\n",
              "  np.int64(6),\n",
              "  np.int64(1),\n",
              "  np.int64(5),\n",
              "  np.int64(7),\n",
              "  np.int64(0),\n",
              "  np.int64(6),\n",
              "  np.int64(7),\n",
              "  np.int64(8),\n",
              "  np.int64(9),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(6),\n",
              "  np.int64(6),\n",
              "  np.int64(2),\n",
              "  np.int64(5),\n",
              "  np.int64(9),\n",
              "  np.int64(1),\n",
              "  np.int64(9),\n",
              "  np.int64(9),\n",
              "  np.int64(4),\n",
              "  np.int64(2),\n",
              "  np.int64(1),\n",
              "  np.int64(7),\n",
              "  np.int64(0),\n",
              "  np.int64(6),\n",
              "  np.int64(8),\n",
              "  np.int64(8),\n",
              "  np.int64(9),\n",
              "  np.int64(6),\n",
              "  np.int64(9),\n",
              "  np.int64(2),\n",
              "  np.int64(4),\n",
              "  np.int64(7),\n",
              "  np.int64(8),\n",
              "  np.int64(5),\n",
              "  np.int64(1),\n",
              "  np.int64(2),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(5),\n",
              "  np.int64(8),\n",
              "  np.int64(7),\n",
              "  np.int64(6),\n",
              "  np.int64(2),\n",
              "  np.int64(8),\n",
              "  np.int64(1),\n",
              "  np.int64(3),\n",
              "  np.int64(8),\n",
              "  ...],\n",
              " [np.int64(3),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(8),\n",
              "  np.int64(6),\n",
              "  np.int64(6),\n",
              "  np.int64(1),\n",
              "  np.int64(2),\n",
              "  np.int64(3),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(5),\n",
              "  np.int64(7),\n",
              "  np.int64(9),\n",
              "  np.int64(1),\n",
              "  np.int64(5),\n",
              "  np.int64(7),\n",
              "  np.int64(8),\n",
              "  np.int64(6),\n",
              "  np.int64(7),\n",
              "  np.int64(2),\n",
              "  np.int64(2),\n",
              "  np.int64(1),\n",
              "  np.int64(4),\n",
              "  np.int64(2),\n",
              "  np.int64(5),\n",
              "  np.int64(0),\n",
              "  np.int64(9),\n",
              "  np.int64(2),\n",
              "  np.int64(6),\n",
              "  np.int64(5),\n",
              "  np.int64(2),\n",
              "  np.int64(5),\n",
              "  np.int64(9),\n",
              "  np.int64(3),\n",
              "  np.int64(7),\n",
              "  np.int64(1),\n",
              "  np.int64(9),\n",
              "  np.int64(5),\n",
              "  np.int64(4),\n",
              "  np.int64(6),\n",
              "  np.int64(2),\n",
              "  np.int64(6),\n",
              "  np.int64(8),\n",
              "  np.int64(9),\n",
              "  np.int64(3),\n",
              "  np.int64(1),\n",
              "  np.int64(7),\n",
              "  np.int64(2),\n",
              "  np.int64(1),\n",
              "  np.int64(8),\n",
              "  np.int64(7),\n",
              "  np.int64(5),\n",
              "  np.int64(8),\n",
              "  np.int64(8),\n",
              "  np.int64(7),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(7),\n",
              "  np.int64(5),\n",
              "  np.int64(6),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(2),\n",
              "  np.int64(1),\n",
              "  np.int64(2),\n",
              "  np.int64(5),\n",
              "  np.int64(7),\n",
              "  np.int64(2),\n",
              "  np.int64(3),\n",
              "  np.int64(8),\n",
              "  np.int64(8),\n",
              "  np.int64(0),\n",
              "  np.int64(2),\n",
              "  np.int64(9),\n",
              "  np.int64(5),\n",
              "  np.int64(7),\n",
              "  np.int64(8),\n",
              "  np.int64(8),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(7),\n",
              "  np.int64(2),\n",
              "  np.int64(7),\n",
              "  np.int64(2),\n",
              "  np.int64(7),\n",
              "  np.int64(8),\n",
              "  np.int64(9),\n",
              "  np.int64(1),\n",
              "  np.int64(3),\n",
              "  np.int64(8),\n",
              "  np.int64(6),\n",
              "  np.int64(4),\n",
              "  np.int64(6),\n",
              "  np.int64(6),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(7),\n",
              "  np.int64(4),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(5),\n",
              "  np.int64(6),\n",
              "  np.int64(1),\n",
              "  np.int64(7),\n",
              "  np.int64(4),\n",
              "  np.int64(0),\n",
              "  np.int64(2),\n",
              "  np.int64(2),\n",
              "  np.int64(1),\n",
              "  np.int64(5),\n",
              "  np.int64(0),\n",
              "  np.int64(4),\n",
              "  np.int64(6),\n",
              "  np.int64(7),\n",
              "  np.int64(8),\n",
              "  np.int64(5),\n",
              "  np.int64(1),\n",
              "  np.int64(2),\n",
              "  np.int64(8),\n",
              "  np.int64(8),\n",
              "  np.int64(8),\n",
              "  np.int64(3),\n",
              "  np.int64(3),\n",
              "  np.int64(2),\n",
              "  np.int64(2),\n",
              "  np.int64(1),\n",
              "  np.int64(8),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(2),\n",
              "  np.int64(9),\n",
              "  np.int64(2),\n",
              "  np.int64(4),\n",
              "  np.int64(8),\n",
              "  np.int64(6),\n",
              "  np.int64(5),\n",
              "  np.int64(6),\n",
              "  np.int64(5),\n",
              "  np.int64(1),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(2),\n",
              "  np.int64(8),\n",
              "  np.int64(0),\n",
              "  np.int64(6),\n",
              "  np.int64(2),\n",
              "  np.int64(2),\n",
              "  np.int64(6),\n",
              "  np.int64(5),\n",
              "  np.int64(9),\n",
              "  np.int64(3),\n",
              "  np.int64(4),\n",
              "  np.int64(2),\n",
              "  np.int64(1),\n",
              "  np.int64(5),\n",
              "  np.int64(6),\n",
              "  np.int64(0),\n",
              "  np.int64(4),\n",
              "  np.int64(8),\n",
              "  np.int64(6),\n",
              "  np.int64(5),\n",
              "  np.int64(8),\n",
              "  np.int64(9),\n",
              "  np.int64(1),\n",
              "  np.int64(9),\n",
              "  np.int64(8),\n",
              "  np.int64(1),\n",
              "  np.int64(9),\n",
              "  np.int64(3),\n",
              "  np.int64(7),\n",
              "  np.int64(5),\n",
              "  np.int64(8),\n",
              "  np.int64(0),\n",
              "  np.int64(7),\n",
              "  np.int64(2),\n",
              "  np.int64(2),\n",
              "  np.int64(5),\n",
              "  np.int64(8),\n",
              "  np.int64(6),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(0),\n",
              "  np.int64(5),\n",
              "  np.int64(8),\n",
              "  np.int64(2),\n",
              "  np.int64(1),\n",
              "  np.int64(5),\n",
              "  np.int64(2),\n",
              "  np.int64(8),\n",
              "  np.int64(8),\n",
              "  np.int64(5),\n",
              "  np.int64(8),\n",
              "  np.int64(5),\n",
              "  np.int64(1),\n",
              "  np.int64(8),\n",
              "  np.int64(7),\n",
              "  np.int64(1),\n",
              "  np.int64(3),\n",
              "  np.int64(0),\n",
              "  np.int64(5),\n",
              "  np.int64(7),\n",
              "  np.int64(1),\n",
              "  np.int64(5),\n",
              "  np.int64(9),\n",
              "  np.int64(5),\n",
              "  np.int64(9),\n",
              "  np.int64(8),\n",
              "  np.int64(2),\n",
              "  np.int64(7),\n",
              "  np.int64(9),\n",
              "  np.int64(8),\n",
              "  np.int64(2),\n",
              "  np.int64(7),\n",
              "  np.int64(5),\n",
              "  np.int64(9),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(1),\n",
              "  np.int64(5),\n",
              "  np.int64(4),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(1),\n",
              "  np.int64(5),\n",
              "  np.int64(8),\n",
              "  np.int64(8),\n",
              "  np.int64(0),\n",
              "  np.int64(4),\n",
              "  np.int64(7),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(9),\n",
              "  np.int64(0),\n",
              "  np.int64(3),\n",
              "  np.int64(1),\n",
              "  np.int64(8),\n",
              "  np.int64(2),\n",
              "  np.int64(2),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(4),\n",
              "  np.int64(8),\n",
              "  np.int64(7),\n",
              "  np.int64(0),\n",
              "  np.int64(8),\n",
              "  np.int64(1),\n",
              "  np.int64(9),\n",
              "  np.int64(1),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(8),\n",
              "  np.int64(8),\n",
              "  np.int64(6),\n",
              "  np.int64(4),\n",
              "  np.int64(7),\n",
              "  np.int64(2),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(6),\n",
              "  np.int64(3),\n",
              "  np.int64(8),\n",
              "  np.int64(5),\n",
              "  np.int64(0),\n",
              "  np.int64(5),\n",
              "  np.int64(7),\n",
              "  np.int64(5),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(6),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(9),\n",
              "  np.int64(1),\n",
              "  np.int64(8),\n",
              "  np.int64(7),\n",
              "  np.int64(9),\n",
              "  np.int64(1),\n",
              "  np.int64(2),\n",
              "  np.int64(6),\n",
              "  np.int64(1),\n",
              "  np.int64(5),\n",
              "  np.int64(4),\n",
              "  np.int64(6),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(6),\n",
              "  np.int64(6),\n",
              "  np.int64(6),\n",
              "  np.int64(5),\n",
              "  np.int64(1),\n",
              "  np.int64(6),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(2),\n",
              "  np.int64(1),\n",
              "  np.int64(5),\n",
              "  np.int64(8),\n",
              "  np.int64(6),\n",
              "  np.int64(8),\n",
              "  np.int64(2),\n",
              "  np.int64(5),\n",
              "  np.int64(0),\n",
              "  np.int64(7),\n",
              "  np.int64(7),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(3),\n",
              "  np.int64(2),\n",
              "  np.int64(2),\n",
              "  np.int64(7),\n",
              "  np.int64(1),\n",
              "  np.int64(7),\n",
              "  np.int64(5),\n",
              "  np.int64(4),\n",
              "  np.int64(6),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(6),\n",
              "  np.int64(6),\n",
              "  np.int64(6),\n",
              "  np.int64(9),\n",
              "  np.int64(3),\n",
              "  np.int64(8),\n",
              "  np.int64(0),\n",
              "  np.int64(7),\n",
              "  np.int64(2),\n",
              "  np.int64(6),\n",
              "  np.int64(2),\n",
              "  np.int64(5),\n",
              "  np.int64(8),\n",
              "  np.int64(5),\n",
              "  np.int64(4),\n",
              "  np.int64(6),\n",
              "  np.int64(8),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(8),\n",
              "  np.int64(2),\n",
              "  np.int64(3),\n",
              "  np.int64(7),\n",
              "  np.int64(5),\n",
              "  np.int64(2),\n",
              "  np.int64(8),\n",
              "  np.int64(0),\n",
              "  np.int64(9),\n",
              "  np.int64(5),\n",
              "  np.int64(8),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(4),\n",
              "  np.int64(1),\n",
              "  np.int64(3),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(4),\n",
              "  np.int64(7),\n",
              "  np.int64(9),\n",
              "  np.int64(4),\n",
              "  np.int64(2),\n",
              "  np.int64(7),\n",
              "  np.int64(7),\n",
              "  np.int64(4),\n",
              "  np.int64(2),\n",
              "  np.int64(6),\n",
              "  np.int64(6),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(5),\n",
              "  np.int64(0),\n",
              "  np.int64(7),\n",
              "  np.int64(2),\n",
              "  np.int64(5),\n",
              "  np.int64(7),\n",
              "  np.int64(1),\n",
              "  np.int64(2),\n",
              "  np.int64(6),\n",
              "  np.int64(2),\n",
              "  np.int64(9),\n",
              "  np.int64(6),\n",
              "  np.int64(5),\n",
              "  np.int64(3),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(9),\n",
              "  np.int64(1),\n",
              "  np.int64(7),\n",
              "  np.int64(8),\n",
              "  np.int64(8),\n",
              "  np.int64(6),\n",
              "  np.int64(0),\n",
              "  np.int64(9),\n",
              "  np.int64(8),\n",
              "  np.int64(5),\n",
              "  np.int64(7),\n",
              "  np.int64(8),\n",
              "  np.int64(5),\n",
              "  np.int64(6),\n",
              "  np.int64(1),\n",
              "  np.int64(9),\n",
              "  np.int64(5),\n",
              "  np.int64(7),\n",
              "  np.int64(5),\n",
              "  np.int64(7),\n",
              "  np.int64(2),\n",
              "  np.int64(5),\n",
              "  np.int64(8),\n",
              "  np.int64(0),\n",
              "  np.int64(2),\n",
              "  np.int64(9),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(2),\n",
              "  np.int64(6),\n",
              "  np.int64(2),\n",
              "  np.int64(5),\n",
              "  np.int64(3),\n",
              "  np.int64(7),\n",
              "  np.int64(5),\n",
              "  np.int64(7),\n",
              "  np.int64(2),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(9),\n",
              "  np.int64(1),\n",
              "  np.int64(2),\n",
              "  np.int64(9),\n",
              "  np.int64(1),\n",
              "  np.int64(5),\n",
              "  np.int64(7),\n",
              "  np.int64(5),\n",
              "  np.int64(0),\n",
              "  np.int64(2),\n",
              "  np.int64(2),\n",
              "  np.int64(6),\n",
              "  np.int64(9),\n",
              "  np.int64(7),\n",
              "  np.int64(4),\n",
              "  np.int64(1),\n",
              "  np.int64(5),\n",
              "  np.int64(4),\n",
              "  np.int64(5),\n",
              "  np.int64(4),\n",
              "  np.int64(2),\n",
              "  np.int64(5),\n",
              "  np.int64(6),\n",
              "  np.int64(1),\n",
              "  np.int64(7),\n",
              "  np.int64(5),\n",
              "  np.int64(4),\n",
              "  np.int64(4),\n",
              "  np.int64(3),\n",
              "  np.int64(7),\n",
              "  np.int64(8),\n",
              "  np.int64(5),\n",
              "  np.int64(7),\n",
              "  np.int64(8),\n",
              "  np.int64(8),\n",
              "  np.int64(5),\n",
              "  np.int64(7),\n",
              "  np.int64(5),\n",
              "  np.int64(8),\n",
              "  np.int64(5),\n",
              "  np.int64(4),\n",
              "  np.int64(1),\n",
              "  np.int64(6),\n",
              "  np.int64(8),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(9),\n",
              "  np.int64(9),\n",
              "  np.int64(9),\n",
              "  np.int64(5),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(8),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(8),\n",
              "  np.int64(0),\n",
              "  np.int64(2),\n",
              "  np.int64(2),\n",
              "  np.int64(2),\n",
              "  np.int64(4),\n",
              "  np.int64(6),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(9),\n",
              "  np.int64(4),\n",
              "  np.int64(7),\n",
              "  np.int64(9),\n",
              "  np.int64(1),\n",
              "  np.int64(4),\n",
              "  np.int64(5),\n",
              "  np.int64(6),\n",
              "  np.int64(6),\n",
              "  np.int64(1),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(8),\n",
              "  np.int64(1),\n",
              "  np.int64(5),\n",
              "  np.int64(8),\n",
              "  np.int64(5),\n",
              "  np.int64(7),\n",
              "  np.int64(0),\n",
              "  np.int64(7),\n",
              "  np.int64(0),\n",
              "  np.int64(5),\n",
              "  np.int64(4),\n",
              "  np.int64(0),\n",
              "  np.int64(0),\n",
              "  np.int64(6),\n",
              "  np.int64(9),\n",
              "  np.int64(5),\n",
              "  np.int64(1),\n",
              "  np.int64(5),\n",
              "  np.int64(6),\n",
              "  np.int64(6),\n",
              "  np.int64(6),\n",
              "  np.int64(6),\n",
              "  np.int64(8),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(7),\n",
              "  np.int64(6),\n",
              "  np.int64(7),\n",
              "  np.int64(5),\n",
              "  np.int64(9),\n",
              "  np.int64(1),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(7),\n",
              "  np.int64(8),\n",
              "  np.int64(5),\n",
              "  np.int64(9),\n",
              "  np.int64(4),\n",
              "  np.int64(6),\n",
              "  np.int64(4),\n",
              "  np.int64(5),\n",
              "  np.int64(2),\n",
              "  np.int64(0),\n",
              "  np.int64(7),\n",
              "  np.int64(5),\n",
              "  np.int64(6),\n",
              "  np.int64(2),\n",
              "  np.int64(5),\n",
              "  np.int64(9),\n",
              "  np.int64(7),\n",
              "  np.int64(6),\n",
              "  np.int64(6),\n",
              "  np.int64(6),\n",
              "  np.int64(7),\n",
              "  np.int64(1),\n",
              "  np.int64(3),\n",
              "  np.int64(6),\n",
              "  np.int64(6),\n",
              "  np.int64(8),\n",
              "  np.int64(9),\n",
              "  np.int64(7),\n",
              "  np.int64(5),\n",
              "  np.int64(4),\n",
              "  np.int64(0),\n",
              "  np.int64(8),\n",
              "  np.int64(4),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(5),\n",
              "  np.int64(4),\n",
              "  np.int64(8),\n",
              "  np.int64(9),\n",
              "  np.int64(6),\n",
              "  np.int64(9),\n",
              "  np.int64(2),\n",
              "  np.int64(6),\n",
              "  np.int64(1),\n",
              "  np.int64(4),\n",
              "  np.int64(7),\n",
              "  np.int64(7),\n",
              "  np.int64(5),\n",
              "  np.int64(3),\n",
              "  np.int64(8),\n",
              "  np.int64(5),\n",
              "  np.int64(2),\n",
              "  np.int64(2),\n",
              "  np.int64(1),\n",
              "  np.int64(6),\n",
              "  np.int64(5),\n",
              "  np.int64(2),\n",
              "  np.int64(3),\n",
              "  np.int64(9),\n",
              "  np.int64(6),\n",
              "  np.int64(1),\n",
              "  np.int64(8),\n",
              "  np.int64(8),\n",
              "  np.int64(5),\n",
              "  np.int64(8),\n",
              "  np.int64(6),\n",
              "  np.int64(6),\n",
              "  np.int64(2),\n",
              "  np.int64(1),\n",
              "  np.int64(7),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(2),\n",
              "  np.int64(4),\n",
              "  np.int64(9),\n",
              "  np.int64(1),\n",
              "  np.int64(4),\n",
              "  np.int64(7),\n",
              "  np.int64(1),\n",
              "  np.int64(8),\n",
              "  np.int64(2),\n",
              "  np.int64(6),\n",
              "  np.int64(0),\n",
              "  np.int64(7),\n",
              "  np.int64(6),\n",
              "  np.int64(8),\n",
              "  np.int64(2),\n",
              "  np.int64(0),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(3),\n",
              "  np.int64(8),\n",
              "  np.int64(7),\n",
              "  np.int64(9),\n",
              "  np.int64(1),\n",
              "  np.int64(3),\n",
              "  np.int64(7),\n",
              "  np.int64(4),\n",
              "  np.int64(7),\n",
              "  np.int64(3),\n",
              "  np.int64(1),\n",
              "  np.int64(5),\n",
              "  np.int64(2),\n",
              "  np.int64(9),\n",
              "  np.int64(2),\n",
              "  np.int64(1),\n",
              "  np.int64(5),\n",
              "  np.int64(4),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(7),\n",
              "  np.int64(7),\n",
              "  np.int64(6),\n",
              "  np.int64(3),\n",
              "  np.int64(8),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(2),\n",
              "  np.int64(6),\n",
              "  np.int64(3),\n",
              "  np.int64(6),\n",
              "  np.int64(3),\n",
              "  np.int64(2),\n",
              "  np.int64(8),\n",
              "  np.int64(4),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(5),\n",
              "  np.int64(1),\n",
              "  np.int64(6),\n",
              "  np.int64(4),\n",
              "  np.int64(0),\n",
              "  np.int64(9),\n",
              "  np.int64(2),\n",
              "  np.int64(9),\n",
              "  np.int64(2),\n",
              "  np.int64(3),\n",
              "  np.int64(6),\n",
              "  np.int64(5),\n",
              "  np.int64(2),\n",
              "  np.int64(2),\n",
              "  np.int64(7),\n",
              "  np.int64(8),\n",
              "  np.int64(3),\n",
              "  np.int64(8),\n",
              "  np.int64(2),\n",
              "  np.int64(4),\n",
              "  np.int64(5),\n",
              "  np.int64(7),\n",
              "  np.int64(2),\n",
              "  np.int64(4),\n",
              "  np.int64(8),\n",
              "  np.int64(7),\n",
              "  np.int64(4),\n",
              "  np.int64(2),\n",
              "  np.int64(9),\n",
              "  np.int64(4),\n",
              "  np.int64(8),\n",
              "  np.int64(6),\n",
              "  np.int64(8),\n",
              "  np.int64(8),\n",
              "  np.int64(7),\n",
              "  np.int64(4),\n",
              "  np.int64(5),\n",
              "  np.int64(3),\n",
              "  np.int64(8),\n",
              "  np.int64(7),\n",
              "  np.int64(7),\n",
              "  np.int64(4),\n",
              "  np.int64(8),\n",
              "  np.int64(8),\n",
              "  np.int64(1),\n",
              "  np.int64(8),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(2),\n",
              "  np.int64(6),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(0),\n",
              "  np.int64(7),\n",
              "  np.int64(9),\n",
              "  np.int64(1),\n",
              "  np.int64(2),\n",
              "  np.int64(1),\n",
              "  np.int64(2),\n",
              "  np.int64(1),\n",
              "  np.int64(7),\n",
              "  np.int64(5),\n",
              "  np.int64(7),\n",
              "  np.int64(0),\n",
              "  np.int64(7),\n",
              "  np.int64(1),\n",
              "  np.int64(7),\n",
              "  np.int64(5),\n",
              "  np.int64(6),\n",
              "  np.int64(2),\n",
              "  np.int64(3),\n",
              "  np.int64(9),\n",
              "  np.int64(2),\n",
              "  np.int64(9),\n",
              "  np.int64(1),\n",
              "  np.int64(2),\n",
              "  np.int64(2),\n",
              "  np.int64(6),\n",
              "  np.int64(8),\n",
              "  np.int64(2),\n",
              "  np.int64(1),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(6),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(2),\n",
              "  np.int64(4),\n",
              "  np.int64(9),\n",
              "  np.int64(5),\n",
              "  np.int64(4),\n",
              "  np.int64(5),\n",
              "  np.int64(1),\n",
              "  np.int64(6),\n",
              "  np.int64(6),\n",
              "  np.int64(2),\n",
              "  np.int64(4),\n",
              "  np.int64(5),\n",
              "  np.int64(6),\n",
              "  np.int64(0),\n",
              "  np.int64(5),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(5),\n",
              "  np.int64(6),\n",
              "  np.int64(7),\n",
              "  np.int64(0),\n",
              "  np.int64(3),\n",
              "  np.int64(0),\n",
              "  np.int64(2),\n",
              "  np.int64(8),\n",
              "  np.int64(3),\n",
              "  np.int64(0),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(7),\n",
              "  np.int64(7),\n",
              "  np.int64(4),\n",
              "  np.int64(4),\n",
              "  np.int64(2),\n",
              "  np.int64(2),\n",
              "  np.int64(7),\n",
              "  np.int64(1),\n",
              "  np.int64(2),\n",
              "  np.int64(7),\n",
              "  np.int64(4),\n",
              "  np.int64(4),\n",
              "  np.int64(8),\n",
              "  np.int64(4),\n",
              "  np.int64(2),\n",
              "  np.int64(7),\n",
              "  np.int64(2),\n",
              "  np.int64(2),\n",
              "  np.int64(7),\n",
              "  np.int64(2),\n",
              "  np.int64(0),\n",
              "  np.int64(8),\n",
              "  np.int64(9),\n",
              "  np.int64(5),\n",
              "  np.int64(8),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(2),\n",
              "  np.int64(8),\n",
              "  np.int64(8),\n",
              "  np.int64(7),\n",
              "  np.int64(5),\n",
              "  np.int64(7),\n",
              "  np.int64(6),\n",
              "  np.int64(5),\n",
              "  np.int64(4),\n",
              "  np.int64(1),\n",
              "  np.int64(6),\n",
              "  np.int64(2),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(1),\n",
              "  np.int64(2),\n",
              "  np.int64(1),\n",
              "  np.int64(2),\n",
              "  np.int64(7),\n",
              "  np.int64(0),\n",
              "  np.int64(7),\n",
              "  np.int64(2),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(7),\n",
              "  np.int64(0),\n",
              "  np.int64(2),\n",
              "  np.int64(4),\n",
              "  np.int64(5),\n",
              "  np.int64(9),\n",
              "  np.int64(8),\n",
              "  np.int64(1),\n",
              "  np.int64(0),\n",
              "  np.int64(7),\n",
              "  np.int64(7),\n",
              "  np.int64(0),\n",
              "  np.int64(7),\n",
              "  np.int64(5),\n",
              "  np.int64(4),\n",
              "  np.int64(6),\n",
              "  np.int64(6),\n",
              "  np.int64(5),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(5),\n",
              "  np.int64(7),\n",
              "  np.int64(8),\n",
              "  np.int64(0),\n",
              "  np.int64(3),\n",
              "  np.int64(1),\n",
              "  np.int64(4),\n",
              "  np.int64(6),\n",
              "  np.int64(3),\n",
              "  np.int64(8),\n",
              "  np.int64(4),\n",
              "  np.int64(2),\n",
              "  np.int64(2),\n",
              "  np.int64(7),\n",
              "  np.int64(8),\n",
              "  np.int64(2),\n",
              "  np.int64(2),\n",
              "  np.int64(0),\n",
              "  np.int64(8),\n",
              "  np.int64(4),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(8),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(6),\n",
              "  np.int64(5),\n",
              "  np.int64(7),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(5),\n",
              "  np.int64(7),\n",
              "  np.int64(7),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(6),\n",
              "  np.int64(6),\n",
              "  np.int64(5),\n",
              "  np.int64(8),\n",
              "  np.int64(5),\n",
              "  np.int64(1),\n",
              "  np.int64(6),\n",
              "  np.int64(8),\n",
              "  np.int64(8),\n",
              "  np.int64(5),\n",
              "  np.int64(3),\n",
              "  np.int64(2),\n",
              "  np.int64(4),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(4),\n",
              "  np.int64(8),\n",
              "  np.int64(8),\n",
              "  np.int64(2),\n",
              "  np.int64(6),\n",
              "  np.int64(9),\n",
              "  np.int64(9),\n",
              "  np.int64(5),\n",
              "  np.int64(2),\n",
              "  np.int64(5),\n",
              "  np.int64(8),\n",
              "  np.int64(2),\n",
              "  np.int64(0),\n",
              "  np.int64(8),\n",
              "  np.int64(4),\n",
              "  np.int64(2),\n",
              "  np.int64(3),\n",
              "  np.int64(5),\n",
              "  np.int64(7),\n",
              "  np.int64(2),\n",
              "  np.int64(2),\n",
              "  np.int64(5),\n",
              "  np.int64(1),\n",
              "  np.int64(8),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(7),\n",
              "  np.int64(7),\n",
              "  np.int64(0),\n",
              "  np.int64(5),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(3),\n",
              "  np.int64(8),\n",
              "  np.int64(3),\n",
              "  np.int64(9),\n",
              "  np.int64(6),\n",
              "  np.int64(1),\n",
              "  np.int64(4),\n",
              "  np.int64(7),\n",
              "  np.int64(0),\n",
              "  np.int64(5),\n",
              "  np.int64(7),\n",
              "  np.int64(8),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(1),\n",
              "  np.int64(6),\n",
              "  np.int64(6),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(9),\n",
              "  np.int64(1),\n",
              "  np.int64(9),\n",
              "  np.int64(1),\n",
              "  np.int64(5),\n",
              "  np.int64(5),\n",
              "  np.int64(1),\n",
              "  np.int64(7),\n",
              "  np.int64(0),\n",
              "  np.int64(5),\n",
              "  np.int64(8),\n",
              "  np.int64(1),\n",
              "  np.int64(9),\n",
              "  np.int64(2),\n",
              "  np.int64(1),\n",
              "  np.int64(5),\n",
              "  np.int64(4),\n",
              "  np.int64(7),\n",
              "  np.int64(8),\n",
              "  np.int64(5),\n",
              "  np.int64(1),\n",
              "  np.int64(2),\n",
              "  np.int64(0),\n",
              "  np.int64(1),\n",
              "  np.int64(5),\n",
              "  np.int64(8),\n",
              "  np.int64(7),\n",
              "  np.int64(6),\n",
              "  np.int64(5),\n",
              "  np.int64(8),\n",
              "  np.int64(1),\n",
              "  np.int64(3),\n",
              "  np.int64(8),\n",
              "  ...]]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRxEnWceGYxn"
      },
      "source": [
        "Individual models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSr0zvfIGeSd",
        "outputId": "3103f7dc-9d7a-4b41-f07c-948bbe0d3ac5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model 1 Accuracy: 0.6981\n",
            "Model 2 Accuracy: 0.6831\n",
            "Mean Accuracy: 0.6906\n",
            "Standard Deviation of Accuracy: 0.0075\n"
          ]
        }
      ],
      "source": [
        "# List to store individual model accuracies\n",
        "individual_accuracies = []\n",
        "\n",
        "# Compute accuracy for each model\n",
        "for i, predictions in enumerate(all_predictions):\n",
        "    # Get predictions for the current model\n",
        "    model_predictions = predictions  # Shape: (num_samples,)\n",
        "\n",
        "    # Get true labels (already collected earlier)\n",
        "    true_labels = np.array(data_module.cifar10_test.targets)\n",
        "\n",
        "    # Calculate accuracy for the current model\n",
        "    accuracy = accuracy_score(true_labels, model_predictions)\n",
        "    individual_accuracies.append(accuracy)\n",
        "    print(f'Model {i+1} Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Convert to numpy array for easier calculations\n",
        "individual_accuracies = np.array(individual_accuracies)\n",
        "\n",
        "# Compute mean accuracy\n",
        "mean_accuracy = np.mean(individual_accuracies)\n",
        "\n",
        "# Compute standard deviation of accuracy\n",
        "std_accuracy = np.std(individual_accuracies)\n",
        "\n",
        "print(f'Mean Accuracy: {mean_accuracy:.4f}')\n",
        "print(f'Standard Deviation of Accuracy: {std_accuracy:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iop73XibGhUv"
      },
      "source": [
        "Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyUFGexws8QK",
        "outputId": "68f320a5-18ce-4dca-ac40-7c8cbef4810c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ensemble Accuracy: 0.6844\n"
          ]
        }
      ],
      "source": [
        "# Stack predictions from all models\n",
        "all_predictions = np.stack(all_predictions)  # Shape: (num_models, num_samples, num_classes)\n",
        "\n",
        "# Ensemble predictions (e.g., by averaging)\n",
        "ensemble_predictions = np.mean(all_predictions, axis=0)  # Shape: (num_samples, num_classes)\n",
        "final_predictions, _ = mode(all_predictions, axis=0)  # Majority voting\n",
        "final_predictions = final_predictions.flatten()  # Flatten to 1D array\n",
        "\n",
        "# Get true labels from the CIFAR-10 data set\n",
        "test_labels = np.array(data_module.cifar10_test.targets)\n",
        "# test_labels = data_module.test_dataset.labels  # Adjust this based on your dataset\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(test_labels, final_predictions)\n",
        "print(f'Ensemble Accuracy: {accuracy:.4f}')\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(test_labels, final_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbEGs97IgtRD",
        "outputId": "d48caccb-bd1f-41dd-d558-a089ec725b25"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Mean Accuracy (individual)': np.float64(0.6906000000000001),\n",
              " 'Standard Deviation of Accuracy (individual)': np.float64(0.007500000000000007),\n",
              " 'Ensemble Accuracy': 0.6844}"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Simulated test metrics\n",
        "test_metrics = {\n",
        "    \"Mean Accuracy (individual)\": mean_accuracy,\n",
        "    \"Standard Deviation of Accuracy (individual)\": std_accuracy,\n",
        "    \"Ensemble Accuracy\": accuracy,\n",
        "}\n",
        "\n",
        "task.connect(test_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIqc-cspappI"
      },
      "outputs": [],
      "source": [
        "task.close()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyOA6jNUBNeu/n3Cms+yIwjX",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "py39",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
