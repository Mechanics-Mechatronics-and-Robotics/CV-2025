{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPahaWrASHz+OPIysc4J2xX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mechanics-Mechatronics-and-Robotics/CV-2025/blob/main/projects/Shapes_and_CAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Request to Deep Seek model\n",
        "Dear model, lets make a plan for coding. We need to check if a CAE can interpolate geometry accurate enough with a toy dataset.\n",
        "A raw plan is as follows (please be critical and feel free to correct it):\n",
        "- generate synthetic dataset of squares of different positions and areas (no rotations required so far);\n",
        "- split the dataset into training, validation, and test sets;\n",
        "- create a simple CAE model;\n",
        "- train the model to reconstruct squares, test the model, visualize the results, save the trained encoder;\n",
        "- use t-SNE to visualize the latent space as well, check if interpolation works and the squares of similar surface area are close in the latent space than the squares of dissimilar surface area;\n",
        "- use the pretrained encoder and train a classifier to predict surface area of the squares, check the accuracy.\n",
        "\n",
        "The code will be launched in Colab. Please use pytorch, lightning and clearML. Collect the model parameters in one dictionary param={}. Below you can find some fragments of the code for the initialization\n",
        "\n",
        "!pip install pytorch-lightning clearml\n",
        "\n",
        "%env CLEARML_WEB_HOST=https://app.clear.ml/\n",
        "%env CLEARML_API_HOST=https://api.clear.ml\n",
        "%env CLEARML_FILES_HOST=https://files.clear.ml\n",
        "%env CLEARML_API_ACCESS_KEY=ZP02U03C6V5ER4K9VWRNZT7EWA5ZTV\n",
        "%env CLEARML_API_SECRET_KEY=BtA5GXZufr6QGpaqhX1GSKPTvaCt56OLqaNqUGLNoxx2Ye8Ctwbui0Ln5OXVnzUgH4I"
      ],
      "metadata": {
        "id": "mY-jjAH6Ih8V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialization"
      ],
      "metadata": {
        "id": "pxyGBRe-JlN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-lightning clearml #scikit-learn matplotlib"
      ],
      "metadata": {
        "collapsed": true,
        "id": "NA77ZpNMHN0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAhyxyrZGWVR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import Trainer\n",
        "from clearml import Task\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env CLEARML_WEB_HOST=https://app.clear.ml/\n",
        "%env CLEARML_API_HOST=https://api.clear.ml\n",
        "%env CLEARML_FILES_HOST=https://files.clear.ml\n",
        "%env CLEARML_API_ACCESS_KEY=ZP02U03C6V5ER4K9VWRNZT7EWA5ZTV\n",
        "%env CLEARML_API_SECRET_KEY=BtA5GXZufr6QGpaqhX1GSKPTvaCt56OLqaNqUGLNoxx2Ye8Ctwbui0Ln5OXVnzUgH4I"
      ],
      "metadata": {
        "id": "trbtPEZJHht6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param = {\n",
        "    'image_size': 64,\n",
        "    'min_width': 4,\n",
        "    'max_width': 32,\n",
        "    'dataset_size': 10000,\n",
        "    'batch_size': 32,\n",
        "    'latent_dim': 32,\n",
        "    'num_workers':10,\n",
        "    'lr': 1e-3,\n",
        "    'max_epochs': 50,\n",
        "    'seed': 42,\n",
        "}\n",
        "# Set seeds for reproducibility\n",
        "pl.seed_everything(42)"
      ],
      "metadata": {
        "id": "vNDTyjZDHqoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data module"
      ],
      "metadata": {
        "id": "CiMFhTh5JrCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SyntheticSquareDataset(Dataset):\n",
        "    def __init__(self, param):\n",
        "        self.images = torch.zeros((param['dataset_size'], 1, param['image_size'], param['image_size']))\n",
        "        self.areas = torch.zeros(param['dataset_size'])\n",
        "        for i in range(param['dataset_size']):\n",
        "            w = torch.randint(param['min_width'], param['max_width'] + 1, (1,)).item()\n",
        "            x = torch.randint(0, param['image_size'] - w + 1, (1,)).item()\n",
        "            y = torch.randint(0, param['image_size'] - w + 1, (1,)).item()\n",
        "            self.images[i, 0, x:x+w, y:y+w] = 1.0\n",
        "            self.areas[i] = w ** 2\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.images[idx], self.areas[idx]\n",
        "\n",
        "dataset = SyntheticSquareDataset(param)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = int(0.1 * len(dataset))\n",
        "test_size = len(dataset) - train_size - val_size\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])"
      ],
      "metadata": {
        "id": "j-3MBxxbHqli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=param['batch_size'], shuffle=True, num_workers=param['num_workers'])\n",
        "val_loader = DataLoader(val_dataset, batch_size=param['batch_size'], num_workers=param['num_workers'])\n",
        "test_loader = DataLoader(test_dataset, batch_size=param['batch_size'], num_workers=param['num_workers'])"
      ],
      "metadata": {
        "id": "XRjjpraZHqiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "ieKfRa2aRLgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CAE(pl.LightningModule):\n",
        "    def __init__(self, latent_dim=32, lr=1e-3):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, 3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 32, 3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(64 * 8 * 8, latent_dim)\n",
        "        )\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 64 * 8 * 8),\n",
        "            nn.Unflatten(1, (64, 8, 8)),\n",
        "            nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.decoder(self.encoder(x))\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, _ = batch\n",
        "        x_hat = self(x)\n",
        "        loss = F.mse_loss(x_hat, x)\n",
        "        self.log('train_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, _ = batch\n",
        "        x_hat = self(x)\n",
        "        loss = F.mse_loss(x_hat, x)\n",
        "        self.log('val_loss', loss)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, _ = batch\n",
        "        x_hat = self(x)\n",
        "        loss = F.mse_loss(x_hat, x)\n",
        "        self.log('test_loss', loss)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)"
      ],
      "metadata": {
        "id": "IUceRDmyHqgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model"
      ],
      "metadata": {
        "id": "IlkJWQtkRTJJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize ClearML Task\n",
        "task = Task.init(project_name='CAE_Squares', task_name='CAE_Training')\n",
        "task.connect(param)"
      ],
      "metadata": {
        "id": "-Cu6CvxAHqeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CAE(latent_dim=param['latent_dim'], lr=param['lr'])\n",
        "trainer = pl.Trainer(max_epochs=param['max_epochs'], accelerator='auto')\n",
        "trainer.fit(model, train_loader, val_loader)\n",
        "trainer.test(model, test_loader)"
      ],
      "metadata": {
        "id": "11k3BmmgHqbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize the results"
      ],
      "metadata": {
        "id": "pavLBc3vRYhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "x, _ = next(iter(test_loader))\n",
        "x_hat = model(x).detach()\n",
        "\n",
        "fig, axes = plt.subplots(5, 2, figsize=(10, 20))\n",
        "for i in range(5):\n",
        "    axes[i,0].imshow(x[i].squeeze(), cmap='gray')\n",
        "    axes[i,0].set_title('Original')\n",
        "    axes[i,1].imshow(x_hat[i].squeeze(), cmap='gray')\n",
        "    axes[i,1].set_title('Reconstructed')\n",
        "plt.show()\n",
        "# Log images to ClearML\n",
        "task.get_logger().report_matplotlib_figure(title=\"Reconstructions\", series=\"Test Set\", figure=fig, iteration=0)"
      ],
      "metadata": {
        "id": "snAnfuVoHqYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract latent vectors\n",
        "latent_vectors = []\n",
        "areas = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for x, a in test_loader:\n",
        "        latent_vectors.append(model.encoder(x))\n",
        "        areas.append(a)\n",
        "latent_vectors = torch.cat(latent_vectors).cpu().numpy()\n",
        "areas = torch.cat(areas).cpu().numpy()\n",
        "\n",
        "# Apply t-SNE\n",
        "tsne = TSNE(n_components=2, random_state=42)\n",
        "latent_tsne = tsne.fit_transform(latent_vectors)\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.scatter(latent_tsne[:,0], latent_tsne[:,1], c=areas, cmap='viridis', alpha=0.6)\n",
        "plt.colorbar(label='Area')\n",
        "plt.title('t-SNE of Latent Space Colored by Area')\n",
        "plt.show()\n",
        "task.get_logger().report_matplotlib_figure(title=\"t-SNE\", series=\"Latent Space\", figure=plt.gcf(), iteration=0)"
      ],
      "metadata": {
        "id": "Zf9YW4G8IKwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z1 = latent_vectors[0]\n",
        "z2 = latent_vectors[1]\n",
        "alphas = np.linspace(0, 1, 10)\n",
        "interpolated_z = torch.tensor([a * z1 + (1 - a) * z2 for a in alphas], dtype=torch.float32)\n",
        "\n",
        "with torch.no_grad():\n",
        "    interpolated_images = model.decoder(interpolated_z).cpu()\n",
        "\n",
        "fig, axes = plt.subplots(1, 10, figsize=(20, 2))\n",
        "for i, img in enumerate(interpolated_images):\n",
        "    axes[i].imshow(img.squeeze(), cmap='gray')\n",
        "    axes[i].axis('off')\n",
        "plt.show()\n",
        "task.get_logger().report_matplotlib_figure(title=\"Interpolation\", series=\"Latent Space\", figure=plt.gcf(), iteration=0)"
      ],
      "metadata": {
        "id": "QGOKFalXINh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the auxilary area regressor model"
      ],
      "metadata": {
        "id": "g5GdIF1URg4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AreaRegressor(pl.LightningModule):\n",
        "    def __init__(self, encoder, latent_dim, lr=1e-3):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.encoder = encoder\n",
        "        for param in self.encoder.parameters():\n",
        "            param.requires_grad = False\n",
        "        self.regressor = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.regressor(self.encoder(x)).squeeze()\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = F.mse_loss(y_hat, y)\n",
        "        self.log('train_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = F.mse_loss(y_hat, y)\n",
        "        self.log('val_loss', loss)\n",
        "        mae = torch.mean(torch.abs(y_hat - y))\n",
        "        self.log('val_mae', mae)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        y_hat = self(x)\n",
        "        loss = F.mse_loss(y_hat, y)\n",
        "        self.log('test_loss', loss)\n",
        "        mae = torch.mean(torch.abs(y_hat - y))\n",
        "        self.log('test_mae', mae)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.regressor.parameters(), lr=self.hparams.lr)\n",
        "\n",
        "# Initialize and train regressor\n",
        "regressor = AreaRegressor(model.encoder, param['latent_dim'], lr=param['lr'])\n",
        "trainer_regressor = pl.Trainer(max_epochs=20, accelerator='auto')\n",
        "trainer_regressor.fit(regressor, train_loader, val_loader)\n",
        "trainer_regressor.test(regressor, test_loader)"
      ],
      "metadata": {
        "id": "xmKVrvPSINfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect all predictions\n",
        "regressor.eval()\n",
        "true_areas = []\n",
        "pred_areas = []\n",
        "with torch.no_grad():\n",
        "    for x, y in test_loader:\n",
        "        pred = regressor(x)\n",
        "        true_areas.extend(y.cpu().numpy())\n",
        "        pred_areas.extend(pred.cpu().numpy())\n",
        "\n",
        "# Scatter plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(true_areas, pred_areas, alpha=0.5, label='Predictions')\n",
        "plt.plot([min(true_areas), max(true_areas)], [min(true_areas), max(true_areas)],\n",
        "         'r--', label='Perfect Prediction')\n",
        "plt.xlabel('True Area')\n",
        "plt.ylabel('Predicted Area')\n",
        "plt.title('True vs Predicted Areas')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "task.get_logger().report_matplotlib_figure(\n",
        "    title=\"Regression Results\",\n",
        "    series=\"True vs Predicted\",\n",
        "    figure=plt.gcf(),\n",
        "    iteration=0\n",
        ")"
      ],
      "metadata": {
        "id": "6HGdmH3IINcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "errors = np.array(pred_areas) - np.array(true_areas)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.hist(errors, bins=30, edgecolor='black')\n",
        "plt.xlabel('Prediction Error (Predicted - True)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Prediction Errors')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "task.get_logger().report_matplotlib_figure(\n",
        "    title=\"Regression Errors\",\n",
        "    series=\"Error Distribution\",\n",
        "    figure=plt.gcf(),\n",
        "    iteration=0\n",
        ")"
      ],
      "metadata": {
        "id": "iEGGLmSFINY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a batch of test data\n",
        "x, y = next(iter(test_loader))\n",
        "regressor.eval()\n",
        "with torch.no_grad():\n",
        "    y_pred = regressor(x[:5])  # First 5 samples\n",
        "\n",
        "# Plot\n",
        "fig, axes = plt.subplots(5, 2, figsize=(10, 15))\n",
        "for i in range(5):\n",
        "    # Original image\n",
        "    axes[i, 0].imshow(x[i].squeeze().cpu(), cmap='gray')\n",
        "    axes[i, 0].set_title(f'True Area: {y[i].item():.1f}')\n",
        "    axes[i, 0].axis('off')\n",
        "\n",
        "    # Blank (for alignment, or overlay text)\n",
        "    axes[i, 1].imshow(x[i].squeeze().cpu(), cmap='gray')\n",
        "    axes[i, 1].set_title(f'Predicted Area: {y_pred[i].item():.1f}')\n",
        "    axes[i, 1].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "task.get_logger().report_matplotlib_figure(\n",
        "    title=\"Sample Predictions\",\n",
        "    series=\"Test Samples\",\n",
        "    figure=plt.gcf(),\n",
        "    iteration=0\n",
        ")"
      ],
      "metadata": {
        "id": "-cX0e5ziM151"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "\n",
        "r2 = r2_score(true_areas, pred_areas)\n",
        "mae = mean_absolute_error(true_areas, pred_areas)\n",
        "print(f\"R² Score: {r2:.4f}\")\n",
        "print(f\"MAE: {mae:.4f}\")\n",
        "\n",
        "# Log metrics to ClearML\n",
        "task.get_logger().report_scalar(\n",
        "    title=\"Regression Metrics\",\n",
        "    series=\"R² Score\",\n",
        "    value=r2,\n",
        "    iteration=0\n",
        ")\n",
        "task.get_logger().report_scalar(\n",
        "    title=\"Regression Metrics\",\n",
        "    series=\"MAE\",\n",
        "    value=mae,\n",
        "    iteration=0\n",
        ")"
      ],
      "metadata": {
        "id": "-PCwmOHwM13P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mpq_9tGyM10Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1Vald26fM1s6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}