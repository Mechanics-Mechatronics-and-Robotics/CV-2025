{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLaY0P+zb+mIgpQPRmiECa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mechanics-Mechatronics-and-Robotics/CV-2025/blob/main/Lab_1_Feature_Extraction_and_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab. \\#1. Feature Extraction and Machine Learning"
      ],
      "metadata": {
        "id": "dviRg5xn5mza"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem Statement"
      ],
      "metadata": {
        "id": "fS8QkXU47uNl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The lab deals with comparison of two approaches to machine learning (ML) and computer vision (CV). The first approach is processing of hand-designed features, e.g. geometric features of objects in images, with an ML classification model. The second approach is using of the ML model for both, the automatic feature extraction and the following classification.\n",
        "\n",
        "The MNIST database of handwritten digits has a training set of 60,000 examples, and a test set of 10,000 examples.\n",
        "\n",
        "The hand-designed features can be extracted with standart tools in [scikit-learn](https://scikit-learn.org/1.5/modules/feature_extraction.html)"
      ],
      "metadata": {
        "id": "EvP6IWSB5s_c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tasks and Requirements\n",
        "\n",
        "Bonus\n",
        "* apply a t-SNE model to visualize both, the original images dataset, and hand-extracted features of the dataset"
      ],
      "metadata": {
        "id": "fZWswAni70vg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2ULr1Z9V70oB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import and Install Libraries"
      ],
      "metadata": {
        "id": "9mpwlpoX5TI3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMPnV0nV4_-I",
        "outputId": "db602da9-ac4c-4bb3-8705-b70b2a6d1c24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-2.5.0.post0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: torch>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0.2)\n",
            "Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2024.10.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n",
            "  Downloading torchmetrics-1.6.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.12.2)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning)\n",
            "  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.11.10)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (75.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch-lightning) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.0->pytorch-lightning) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.1.0->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics>=0.7.0->pytorch-lightning) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (3.0.2)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.10)\n",
            "Downloading pytorch_lightning-2.5.0.post0-py3-none-any.whl (819 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.3/819.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
            "Downloading torchmetrics-1.6.1-py3-none-any.whl (927 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m927.3/927.3 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lightning-utilities, torchmetrics, pytorch-lightning\n",
            "Successfully installed lightning-utilities-0.11.9 pytorch-lightning-2.5.0.post0 torchmetrics-1.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-lightning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Pytorch modules\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "#Numpy\n",
        "import numpy as np\n",
        "\n",
        "#Pandas\n",
        "import pandas as pd\n",
        "\n",
        "#Lightning & logging\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "#Data observation\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "#Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ],
      "metadata": {
        "id": "fDHrafErmo43"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set the Model"
      ],
      "metadata": {
        "id": "ealb85K93wDT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simulation Settings"
      ],
      "metadata": {
        "id": "GHIKBWI93-zD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the current directory"
      ],
      "metadata": {
        "id": "kiYPAzh54gjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.getcwd() #returns the current working directory"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "phE7U1vu31BR",
        "outputId": "21091b53-d18c-445c-b47e-c2188b236512"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Paths and initializations of the weights"
      ],
      "metadata": {
        "id": "3WK77wcO6sfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the folder where the dataset is saved\n",
        "DATASET_PATH = os.environ.get(\"PATH_DATASET\", \"data/\")\n",
        "print(f'DATASET_PATH: {DATASET_PATH}')\n",
        "\n",
        "# Path to the folder where the trained or pretrained models are saved\n",
        "CHECKPOINT_PATH = os.environ.get(\"PATH_CHECKPOINT\", \"saved_models\")\n",
        "print(f'CHECKPOINT_PATH: {CHECKPOINT_PATH}')\n",
        "\n",
        "os.makedirs(DATASET_PATH, exist_ok=True) #create the directory\n",
        "os.makedirs(CHECKPOINT_PATH, exist_ok=True) #create the directory\n",
        "\n",
        "isINFERENCE = False # inference mode with downloading the saved weights\n",
        "isPretrained = False # use the pretrained weights when training\n",
        "\n",
        "# Function for setting the seed to implement parallel tests\n",
        "seed = 42 # random seeds are 42, 0, 17, 9, 3\n",
        "pl.seed_everything(seed)\n",
        "\n",
        "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YX7JeP93-TZ",
        "outputId": "7182047b-c3b4-4b99-d4d6-8d5e56a7cddf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Seed set to 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DATASET_PATH: data/\n",
            "CHECKPOINT_PATH: saved_models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logging"
      ],
      "metadata": {
        "id": "_7ULmzow4jSg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lTXMGNya32_3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "BujHK4sw7cA7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary"
      ],
      "metadata": {
        "id": "Wb0uJtxz-E--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET = 'MNIST'\n",
        "ns = {'train': 50000, 'val': 10000, 'test': 10000}\n",
        "\n",
        "SIZE = 28 #image size\n",
        "NUM_CLASSES = 10\n",
        "CLASS_NAMES = ['zero' ,'one', 'two', 'three', 'four',\n",
        "               'five', 'six', 'seven', 'eight', 'nine']"
      ],
      "metadata": {
        "id": "hWRDBJbO7k_u"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalization parameters"
      ],
      "metadata": {
        "id": "qP6TSQ-Z-Hxd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean = np.array([0.1307])\n",
        "std  = np.array([0.3081])"
      ],
      "metadata": {
        "id": "Oh-UxEQ3-Le3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transforms"
      ],
      "metadata": {
        "id": "StCJNi9PDVZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_transforms = transforms.Compose([transforms.ToTensor(),\n",
        "                              transforms.Normalize(mean, std)])"
      ],
      "metadata": {
        "id": "kY9zr3TjDXr2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Collect hyperparameters"
      ],
      "metadata": {
        "id": "GwaBDKEvD5ya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Model parameters\n",
        "LOSS_FUN = 'CE'\n",
        "ARCHITECTURE = 'MLP'\n",
        "lr = 0.0001 #\n",
        "n = 100 # number of epochs\n",
        "\n",
        "batch_size = 32\n",
        "num_workers = 8\n",
        "\n",
        "optimization_algorithm = 'Adam'# 'SGD','Adam'\n",
        "MOMENTUM = 0.9\n",
        "WD = 1e-1 # weight decay\n",
        "\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "roundRun = 5 #number of digits in the results performance\n",
        "\n",
        "#Visualization\n",
        "figSize = (8,8)\n",
        "nSamples = 4\n",
        "numBins = 50\n",
        "\n",
        "#Summary: hyperparameters\n",
        "hyperparameters = {\n",
        "    \"seed\": seed,\n",
        "    \"lr\": lr,\n",
        "    \"isINFERENCE\": isINFERENCE,\n",
        "    \"isPretrained\": isPretrained,\n",
        "    \"dataset\": DATASET,\n",
        "    \"n_classes\": NUM_CLASSES,\n",
        "    \"class_names\": CLASS_NAMES,\n",
        "    \"bs\": batch_size,\n",
        "    \"num_workers\": num_workers,\n",
        "    \"num_epochs\": n,\n",
        "    \"model_filename\": ARCHITECTURE,\n",
        "    \"optimization_algorithm\": optimization_algorithm,\n",
        "    \"momentum\": MOMENTUM,\n",
        "    \"criterion\": LOSS_FUN,\n",
        "    \"weight decay\": WD,\n",
        "    \"device\": DEVICE,\n",
        "    \"fig_size\": figSize,\n",
        "    \"num_samples\": nSamples,\n",
        "    \"num_bins\": numBins,\n",
        "}"
      ],
      "metadata": {
        "id": "NSyUzYCSD0v3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions"
      ],
      "metadata": {
        "id": "OQsu5FcbFfwx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lightning"
      ],
      "metadata": {
        "id": "ZAOMnXlqFofC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training module"
      ],
      "metadata": {
        "id": "JBWSuYApFu7X"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kQYHpiYnFNWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Callbacks"
      ],
      "metadata": {
        "id": "I0QXX3afFxzo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cqN3t87GF0C3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "SpGtoJicGCJC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP"
      ],
      "metadata": {
        "id": "W2bTStw6J_NE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(pl.LightningModule):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(MLP, self).__init__()\n",
        "\n",
        "    # mnist images are (1, 28, 28) (channels, width, height)\n",
        "    self.layer_1 = torch.nn.Linear(SIZE * SIZE, 128)\n",
        "    self.layer_2 = torch.nn.Linear(128, 256)\n",
        "    self.layer_3 = torch.nn.Linear(256, NUM_CLASSES)\n",
        "\n",
        "  def forward(self, x):\n",
        "    batch_size, channels, width, height = x.siz()\n",
        "\n",
        "    # (b, 1, SIZE, SIZE) -> (b, 1*SIZE*SIZE)\n",
        "    x = x.view(batch_size, -1)\n",
        "\n",
        "    # layer 1\n",
        "    x = self.layer_1(x)\n",
        "    x = torch.relu(x)\n",
        "\n",
        "    # layer 2\n",
        "    x = self.layer_2(x)\n",
        "    x = torch.relu(x)\n",
        "\n",
        "    # layer 3\n",
        "    x = self.layer_3(x)\n",
        "\n",
        "    # # probability distribution over labels\n",
        "    # x = torch.log_softmax(x, dim=1)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "4vmhXlcyGDRG"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss"
      ],
      "metadata": {
        "id": "rHm8wnbnGEnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross entropy loss\n",
        "class CEloss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CEloss, self).__init__()\n",
        "\n",
        "    def forward(self,x,y):\n",
        "        prob = nn.functional.softmax(x,1)\n",
        "        log_prob = -1.0 * torch.log(prob)\n",
        "        loss = log_prob.gather(1, y.unsqueeze(1))\n",
        "        loss = loss.mean()\n",
        "        return loss"
      ],
      "metadata": {
        "id": "8auVRUCKGEG2"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization"
      ],
      "metadata": {
        "id": "HAPUCxThGgsQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def imshow(inp, title):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    inp = ((std * inp) + mean)\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    #plt.grid(visible=None, which='major',axis='both')\n",
        "    plt.axis('off')\n",
        "    plt.imshow(inp)\n",
        "    plt.title(title)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "uP38vUhMGiFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hist(df, values, histSize):\n",
        "    sns.set(style=\"darkgrid\")\n",
        "    sns.set(rc={'figure.figsize': histSize})\n",
        "\n",
        "    n = hyperparameters['num_bins']\n",
        "\n",
        "    sns.histplot(data=df[df['True or false prediction'] == True], x = values, color=\"skyblue\",\n",
        "                 label='True predictions',  bins=n, kde=True)\n",
        "    sns.histplot(data=df[df['True or false prediction'] == False],x = values, color=\"red\",\n",
        "                 label='False predictions', bins=n, kde=True)\n",
        "    plt.legend()\n",
        "    return"
      ],
      "metadata": {
        "id": "9yquJLf4GnrO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}